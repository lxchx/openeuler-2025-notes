{
  "graph_data": {
    "nodes": [
      {
        "id": "p1",
        "label": "openEuler的AI战略与实践",
        "category": "Pillar",
        "references": {
          "section_ids": [
            "sec_1",
            "sec_4"
          ],
          "material_ids": [
            "chunk_00/slide_001",
            "chunk_00/slide_002",
            "chunk_00/slide_008",
            "chunk_00/slide_009"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_002",
            "primary_time_ts": "00:00:22,000",
            "primary_time_ms": 22000
          }
        },
        "parent": null,
        "summary": "openEuler致力于成为一个智能操作系统，通过AI赋能核心能力、扩展systemd、推出领域模型等举措，加速企业Agent的开发。现场通过一个AI洞察工具演示了其技术实践，该工具利用Dify编排，调用在昇腾和GPU上部署的多个大模型，高效完成信息分析任务。"
      },
      {
        "id": "p2",
        "label": "大模型智能调优方案",
        "category": "Pillar",
        "references": {
          "section_ids": [
            "sec_2"
          ],
          "material_ids": [
            "chunk_00/slide_003",
            "chunk_00/slide_004",
            "chunk_00/slide_005"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_003",
            "primary_time_ts": "00:03:12,000",
            "primary_time_ms": 192000
          }
        },
        "parent": null,
        "summary": "为解决传统系统调优的痛点，openEuler推出了基于大模型的智能调优方案。通过一个轻量化的领域模型，实现了在纯CPU环境下的高效部署和推理，其调优效果可与顶尖商用大模型媲美，并已在MySQL、Spark等多种应用上得到泛化能力验证。"
      },
      {
        "id": "p3",
        "label": "Intelligence BoM 开源AI解决方案",
        "category": "Pillar",
        "references": {
          "section_ids": [
            "sec_3",
            "sec_5"
          ],
          "material_ids": [
            "chunk_00/slide_006",
            "chunk_00/slide_007",
            "chunk_00/slide_010",
            "chunk_00/slide_011"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_007",
            "primary_time_ts": "00:05:49,000",
            "primary_time_ms": 349000
          }
        },
        "parent": null,
        "summary": "Intelligence BoM是openEuler联合伙伴打造的全栈开源AI解决方案，旨在打破技术壁垒，加速大模型技术普及。最新发布的2511“敲鱼面”版本在低成本、高效率、易落地方面取得进展。该方案未来将从云和服务器扩展到具身智能机器人等全场景，构建全新的AI机器人框架。"
      },
      {
        "id": "d1_1",
        "label": "AI赋能操作系统",
        "category": "Concept",
        "references": {
          "section_ids": [
            "sec_1"
          ],
          "material_ids": [
            "chunk_00/slide_002"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_002",
            "primary_time_ts": "00:01:25,000",
            "primary_time_ms": 85000
          }
        },
        "parent": "p1",
        "summary": "openEuler利用AI技术对操作系统的核心领域进行增强，主要体现在智能调优、智能运维和智能问答三个方面，旨在提升系统性能、简化管理并提供知识服务。"
      },
      {
        "id": "d1_2",
        "label": "AI洞察工具演示",
        "category": "Concept",
        "references": {
          "section_ids": [
            "sec_1",
            "sec_4"
          ],
          "material_ids": [
            "chunk_00/slide_009"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_009",
            "primary_time_ts": "00:10:02,000",
            "primary_time_ms": 602000
          }
        },
        "parent": "p1",
        "summary": "现场演示了一个基于Dify编排的AI洞察工具。该工具通过工作流调用在昇腾和GPU服务器上部署的Qwen系列大模型，自动化完成信息源定位、内容提取和深度分析总结的任务。"
      },
      {
        "id": "d1_3",
        "label": "多模型协同工作流",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_1",
            "sec_4"
          ],
          "material_ids": [
            "chunk_00/slide_002",
            "chunk_00/slide_009"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_002",
            "primary_time_ts": "00:02:20,000",
            "primary_time_ms": 140000
          }
        },
        "parent": "p1",
        "summary": "AI洞察工具的工作流按顺序调用了三个不同规模的大模型：Qwen2-7B用于定位链接，Qwen2-72B用于浅层内容提取，Qwen2-57B-A14B稀疏模型用于深度分析总结，展示了模型协同完成复杂任务的能力。"
      },
      {
        "id": "d2_1",
        "label": "调优方案演进",
        "category": "Concept",
        "references": {
          "section_ids": [
            "sec_2"
          ],
          "material_ids": [
            "chunk_00/slide_003"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_003",
            "primary_time_ts": "00:03:20,000",
            "primary_time_ms": 200000
          }
        },
        "parent": "p2",
        "summary": "系统调优经历了三个阶段：从高成本、依赖专家的人工调优，到解决部分自动化但仍依赖先验知识的A-Tune工具，最终发展到利用大模型自主分析和推荐参数的智能调优，显著提升了效率和适应性。"
      },
      {
        "id": "d2_2",
        "label": "轻量化领域模型",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_2"
          ],
          "material_ids": [
            "chunk_00/slide_004"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_004",
            "primary_time_ts": "00:04:10,000",
            "primary_time_ms": 250000
          }
        },
        "parent": "p2",
        "summary": "openEuler推出专为操作系统优化的领域模型，模型文件总大小约2.2GB，可在纯CPU环境（如鲲鹏920B）中部署和推理，极大地降低了AI调优方案的硬件门槛。"
      },
      {
        "id": "d2_3",
        "label": "调优效果与泛化能力",
        "category": "Result",
        "references": {
          "section_ids": [
            "sec_2"
          ],
          "material_ids": [
            "chunk_00/slide_005"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_005",
            "primary_time_ts": "00:05:21,000",
            "primary_time_ms": 321000
          }
        },
        "parent": "p2",
        "summary": "在MySQL调优场景中，openEuler领域模型在纯CPU环境下的效果与在GPU上运行的DeepSeek-V2 67B模型基本持平。同时，在Spark、Nginx、Ceph等多种应用上的测试也验证了其强大的泛化能力。"
      },
      {
        "id": "d3_1",
        "label": "Intelligence BoM 2511 发布",
        "category": "Concept",
        "references": {
          "section_ids": [
            "sec_3"
          ],
          "material_ids": [
            "chunk_00/slide_007"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_007",
            "primary_time_ts": "00:08:00,000",
            "primary_time_ms": 480000
          }
        },
        "parent": "p3",
        "summary": "正式发布Intelligence BoM的第二个参考实现版本2511，命名为“敲鱼面”（浙江温州特色美食）。该版本在降低成本、提升效率和简化落地方面取得了显著进展。"
      },
      {
        "id": "d3_2",
        "label": "CPU大模型推理",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_3"
          ],
          "material_ids": [
            "chunk_00/slide_007"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_007",
            "primary_time_ts": "00:06:05,000",
            "primary_time_ms": 365000
          }
        },
        "parent": "p3",
        "summary": "Intelligence BoM方案的一大技术突破是首次实现了仅通过CPU进行大模型推理，无需依赖定制硬件，这使得AI技术的普及性大大提高，降低了企业落地AI的门槛。"
      },
      {
        "id": "d3_3",
        "label": "Intelligence BoM Robot",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_5"
          ],
          "material_ids": [
            "chunk_00/slide_011"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_011",
            "primary_time_ts": "00:12:59,000",
            "primary_time_ms": 779000
          }
        },
        "parent": "p3",
        "summary": "将Intelligence BoM的能力从云端扩展至端侧，推出开箱即用的具身智能机器人软件栈。通过云边端协同，融合AI软件栈的“大脑”与传统机器人软件栈的“身体”，构建全新的AI机器人框架。"
      }
    ],
    "edges": [
      {
        "source": "p1",
        "target": "p2",
        "relation_type": "sequential",
        "label": "引出演示"
      },
      {
        "source": "p2",
        "target": "p3",
        "relation_type": "sequential",
        "label": "引出方案"
      },
      {
        "source": "d1_1",
        "target": "d1_2",
        "relation_type": "compositional",
        "label": "通过...验证"
      },
      {
        "source": "d1_2",
        "target": "d1_3",
        "relation_type": "compositional",
        "label": "工作流包含"
      },
      {
        "source": "d2_1",
        "target": "d2_2",
        "relation_type": "causal",
        "label": "催生"
      },
      {
        "source": "d2_2",
        "target": "d2_3",
        "relation_type": "compositional",
        "label": "验证了"
      },
      {
        "source": "d3_1",
        "target": "d3_2",
        "relation_type": "compositional",
        "label": "关键特性"
      },
      {
        "source": "d3_1",
        "target": "d3_3",
        "relation_type": "sequential",
        "label": "未来扩展"
      }
    ]
  },
  "sections": [
    {
      "id": "sec_1",
      "index": 0,
      "title": "openEuler打造智能操作系统，加速企业AI应用开发",
      "time_range": "00:00:00,380 - 00:03:09,165",
      "summary": "讲者介绍了openEuler在AI领域的整体架构与布局，强调其作为一个智能操作系统，致力于加速企业AI应用的开发。",
      "refined_script": "## openEuler：打造智能操作系统，加速企业AI应用开发\n\n随着AI技术的飞速发展，超过90%的创新项目均与AI相关。为应对这一趋势，openEuler社区正致力于将自身打造为一款智能操作系统，通过在AI领域的持续深耕与突破，加速企业级AI应用的开发与落地。\n\n### 核心理念：面向Agent的操作系统生态\n\n我们预见到，未来的操作系统软件生态将向**Agent**形态转变。因此，openEuler的整体软件栈及开发工具链都将围绕**加速企业Agent开发**进行深度优化，致力于成为一个智能化的服务型操作系统。\n\n### 关键举措与技术实践\n\n为了实现这一目标，openEuler社区采取了以下关键举措：\n\n#### 1. AI赋能操作系统核心能力\n\n我们利用AI技术对操作系统的核心领域进行了增强与优化，主要体现在以下三个方面：\n\n*   **智能调优**：通过AI模型自动优化系统性能。\n*   **智能运维**：利用AI简化系统管理与故障排查。\n*   **智能问答**：提供基于AI的系统知识问答服务。\n\n#### 2. 扩展systemd以支持大模型管理\n\n我们对系统最基础的`systemd`（一号进程）进行了大幅度扩展，旨在让语言大模型（LLM）能够更高效地管理和控制操作系统，从而实现对系统服务的智能化调度与调整。\n\n#### 3. 推出业界首个服务器操作系统领域模型\n\nopenEuler社区通过高质量的操作系统语料进行微调，成功打造出业界首个服务器操作系统领域的专用大模型。该模型具备以下突出优势：\n\n*   **低资源需求**：仅需CPU即可进行高效推理，无需额外硬件加速。\n*   **卓越性能**：在智能调优场景下，其能力可与600亿参数级别的商业大模型相媲美。\n\n### 实践案例：基于openEuler的AI洞察工具\n\n为了验证上述理念与技术，我们构建了一个AI洞察工具，并在此次会议上进行了现场演示。该工具的工作流程与技术栈充分展示了openEuler在AI应用开发中的支撑能力。\n\n#### 1. 演示环境与准备\n\n*   **硬件环境**：同时使用了昇腾（Ascend）服务器与GPU服务器。\n*   **模型部署**：在不同硬件上分别部署并启动了多个大模型推理服务。\n*   **编排工具**：使用开源工具Dify进行Agent工作流的编排。\n\n#### 2. Agent工作流与模型调用\n\n该洞察工具通过一个预先编排好的DSL（领域特定语言）文件定义工作流，按步骤调用不同的大模型以完成复杂的分析任务：\n\n1.  **信息源定位**：\n    *   **模型**：Qwen2-7B\n    *   **部署方式**：通过openEuler官方`Llama-cpp`镜像在昇腾服务器上启动。\n    *   **任务**：根据用户需求，从海量信息中获取相关的源链接。\n\n2.  **浅层内容提取**：\n    *   **模型**：Qwen2-72B\n    *   **部署方式**：通过openEuler官方`vLLM`镜像一键启动。\n    *   **任务**：对链接内容进行初步信息提取。\n\n3.  **深度分析与总结**：\n    *   **模型**：Qwen2-57B-A14B（稀疏模型）\n    *   **部署方式**：通过openEuler官方`S-Giant`镜像一键启动。\n    *   **任务**：对提取的信息进行深度分析、归纳和总结。\n\n#### 3. 社区贡献与开源\n\n为推动生态发展，本次演示中使用的所有资源均已在openEuler社区开源，包括：\n\n*   洞察工具的DSL编排文件。\n*   所有模型的部署脚本。\n\n这充分体现了openEuler致力于降低AI应用开发门槛、提供便捷高效开发体验的承诺。",
      "original_script": "刚才联盟的成立，相信一定为异构融合系统软件释放超强算力，指明方向，也能够凝聚合力。\n刚才这一部分讲的都是openEuler在超节点、在新的硬件形态下面，我们去做的改变。\n那么下面一部分是关于openEuler在AI领域里面持续深耕、不断突破，我们做的一些新的工作。\n大家都知道AI是一个大家都很关注的问题。\n刚才熊总也提到，今年的创新项目里面，有超过90%都是和AI相关的。\n那么到底openEuler在AI上做了什么？我给大家简单地也做一个回顾。\n一方面的话就是，我们看到对于openEuler来说，我们作为一个操作系统，以后操作系统的软件生态，我们认为它会向Agent去转变。所以我们整个欧拉上的软件的开发以及相关的这个栈，我们都希望能够为加速企业Agent开发去做相应的优化。\n那么我也去尝试用Dify开发了这么一个工具。\n那么我也去尝试用Dify开发了这么一个工具。\n那么我也去尝试用Dify开发了这么一个工具。\n现在给大家演示一下。\n现在给大家演示一下。\n现在给大家演示一下。\n所以在这里的话，我们从底下的Agent开发工具链，到数据治理流水线，到上面典型的行业应用Agent，我们都去做了相应的这个准备。\n首先启动Dify服务。\n首先启动Dify服务。\n首先启动Dify服务。\nOK，它已经正常启动了。\nOK，它已经正常启动了。\nOK，它已经正常启动了。\n除了使用Dify来编排这个工具以外，我们还用到了大模型的推理能力。\n除了使用Dify来编排这个工具以外，我们还用到了大模型的推理能力。\n除了使用Dify来编排这个工具以外，我们还用到了大模型的推理能力。\n那当然更重要的一点就是，我们在操作系统自身，然后如何让它去成为一个智能的服务型操作系统，这块其实也是整个行业里面大家非常关注的话题。\n刚才我已经在昇腾的服务器上和GPU环境分别拉起了模型。大屏幕上也显示了这些推理服务用到的软件栈。\n刚才我已经在昇腾的服务器上和GPU环境分别拉起了模型。大屏幕上也显示了这些推理服务用到的软件栈。\n刚才我已经在昇腾的服务器上和GPU环境分别拉起了模型。大屏幕上也显示了这些推理服务用到的软件栈。\n现在检查一下这些服务是否OK。\n现在检查一下这些服务是否OK。\n现在检查一下这些服务是否OK。\n我们openEuler在这里面做了几件事情。\n首先就是从上往下的话，我们在操作系统最关注的一些领域里面，我们通过AI加持的方式去做了进一步的调整和优化，从智能调优到运维到问答。\n好的，昇腾服务器上已经正常启动了两个大模型。\n好的，昇腾服务器上已经正常启动了两个大模型。\n好的，那个昇腾服务器上已经正常启动了两个大模型。\n然后再来看一下GPU环境的状态。\n然后再来看一下GPU环境的状态。\n然后再来看一下GPU环境的状态。\n也没有问题。\n也没有问题。\n也没有问题。\n那这时候就可以进入到Dify的工作界面。\n那这时候就可以进入到Dify的工作界面。\n那这时候就可以进入到Dify的工作界面。\n这是操作系统对于我们的管理员、对用户来说，直观可见的它的能力提升。\n接着导入已经编排好的DSL文件。\n接着导入已经编排好的DSL文件。\n接着导入已经编排好的DSL文件。\n那第二方面的话，就是我们在操作系统里面去针对系统最基础的一号进程去做了相应的调整。我们在systemd上面也做了大幅度的扩展。我们通过对于系统智能服务的调整，我们的目标就是让大模型、语言大模型可以更好地管理和控制操作系统。\n好的，已经导入完成了。\n好的，已经导入完成了。\n好的，已经导入完成了。\n那现场让它完成一个洞察任务。\n那现场让它完成一个洞察任务。\n那现场让它完成一个洞察任务。\n趁着工具运行的时间，我们回头看一下整个执行过程中用到了哪些openEuler发布的软件。\n趁着工具运行的时间，我们回头看一下整个执行过程中用到了哪些openEuler发布的软件。\n趁着工具运行的时间，我们回头看一下整个执行过程中用到了哪些openEuler发布的软件。\n这里面最值得提出来、最值得说的是，我们通过高质量的操作系统语料微调出了一个我们认为是行业里面第一个服务器操作系统的领域模型。这样一个领域模型可以通过纯的CPU推理，不需要额外其他任何的硬件，就可以实现非常高质量的系统的智能调优，能够和600多亿的商用模型在调优能力上面形成一个可比的效果。那我们在这里的话就邀请我们第一位的演示嘉宾，给大家展示一下openEuler这样一个领域定制模型在智能调优场景里的一个实战应用。有请。\n先是从用户需求获取信息源链接的时候，用到了Qwen2-7B的模型。\n先是从用户需求获取信息源链接的时候，用到了Qwen2-7B的模型。\n先是从用户需求获取信息源链接的时候，用到了千问3-8B的模型。\n这个模型是用openEuler官方Llama-cpp镜像在昇腾服务器上启动的。\n这个模型是用openEuler官方Llama-cpp镜像在昇腾服务器上启动的。\n这个模型是用openEuler官方Llama-cpp镜像在昇腾服务器上启动的。\n然后，在分层次提取链接内容的过程中，\n然后，在分层次提取链接内容的过程中，\n然后，在分层次提取链接内容的过程中，\n浅层网页的信息提取用到的是Qwen2-72B模型。\n浅层网页的信息提取用到的是Qwen2-72B模型。\n浅层网页的信息提取用到的是千问3-32B模型。\n然后深度分析和总结的Agent用到的是Qwen2-57B-A14B稀疏模型。\n然后深度分析和总结的Agent用到的是Qwen2-57B-A14B稀疏模型。\n然后深度分析和总结的Agent用到的是千问3-nice-80B稀疏模型。\n这两个模型分别用openEuler发布的vLLM和S-Giant镜像一键启动的，非常方便。\n这两个模型分别用openEuler发布的vLLM和S-Giant镜像一键启动的，非常方便。\n这两个模型分别用openEuler发布的vLLM和S-Giant镜像一键启动的，非常方便。\n而且在本次会议之前，这个洞察工具的DSL文件和刚才模型部署的所有脚本已经在社区开源了。\n而且在本次会议之前，这个洞察工具的DSL文件和刚才模型部署的所有脚本已经在社区开源了。\n而且在本次会议之前，这个洞察工具的DSL文件和刚才模型部署的所有脚本已经在社区开源了。",
      "start_ms": 380,
      "end_ms": 189165,
      "material_ids": [
        "chunk_00/slide_001",
        "chunk_00/slide_002"
      ],
      "summary_hint": "讲者介绍了openEuler在AI领域的整体架构与布局，强调其作为一个智能操作系统，致力于加速企业AI应用的开发。",
      "notes": "The planned end sentence '而且在本次会议之前...' (line 78) overlaps with the start of the next section's content. The end time is adjusted to the end of the previous speaker's main content (line 59) to maintain a clean semantic break.",
      "lead_text": "刚才联盟的成立，相信一定为异构融合系统软件释放超强算力，指明方向，也能够凝聚合力。",
      "tail_text": "而且在本次会议之前，这个洞察工具的DSL文件和刚才模型部署的所有脚本已经在社区开源了。",
      "text_span": {
        "start": 0,
        "end": 79
      }
    },
    {
      "id": "sec_2",
      "index": 1,
      "title": "演示：openEuler智能调优",
      "time_range": "00:03:10,890 - 00:05:39,475",
      "summary": "现场演示了openEuler的智能调优能力，通过领域模型在纯CPU环境下进行部署和调优，并展示了其在多种应用上的泛化能力验证结果。",
      "refined_script": "### 1. 背景：从人工到智能的调优演进\n\n系统性能调优经历了三个主要阶段，每个阶段都旨在解决前一阶段的痛点：\n\n1.  **人工调优**：\n    *   **方法**：完全依赖调优专家的经验和知识进行手动调整。\n    *   **痛点**：人力成本高、调优周期长、成果难以复用且高度依赖专家个人能力。\n\n2.  **自动化调优 (A-Tune)**：\n    *   **方法**：openEuler 推出的 A-Tune 工具实现了调优过程的自动化。\n    *   **痛点**：虽然提升了效率，但仍然强依赖于预设的先验知识库，对于新场景或复杂问题的适应性有限。\n\n3.  **大模型智能调优**：\n    *   **方法**：在 A-Tune 基础上，引入大语言模型（LLM）的学习与分析能力。\n    *   **优势**：能够自主完成系统瓶颈分析和参数推荐，显著节约人力成本和调优时间，并摆脱了对先验知识的强依赖。\n\n### 2. 方案：内嵌于 openEuler 的领域模型\n\n为进一步降低大模型调优方案的部署门槛，我们推出了一个专为操作系统优化的领域模型。该模型具备以下核心特性：\n\n*   **轻量化设计**：模型文件总大小约为 2.2 GB（共 9 个文件）。\n*   **CPU 环境支持**：无需昂贵的 GPU 硬件，可直接在纯 CPU 环境（如鲲鹏 920B 服务器）中进行推理和部署。\n*   **开源开放**：相关的 DSL（领域特定语言）文件和模型部署脚本均已在 openEuler 社区开源。\n    *   **开源链接**：`[屏幕正上方提供的链接]`\n\n### 3. 演示：在纯 CPU 环境部署与应用\n\n以下是在鲲鹏 920B 服务器上部署并使用该领域模型的完整步骤：\n\n1.  **下载模型文件**\n    *   将总计约 2.2 GB 的模型文件下载到本地服务器环境。\n\n2.  **部署模型服务**\n    *   使用 `Llama-cpp` 等工具，在纯 CPU 环境中加载并运行领域模型，将其部署为一个推理服务。\n\n3.  **集成至智能调优应用**\n    *   在智能调优应用的配置文件中，指定以下两个关键参数，将其指向刚刚部署的模型服务：\n        *   `LLM_URL`：模型服务的访问地址。\n        *   `LLM_MODEL_NAME`：所使用的模型名称。\n\n4.  **启动智能调优任务**\n    *   完成配置后，启动智能调优应用。应用将自动调用领域模型进行分析和参数推荐。\n\n### 4. 效果验证\n\n#### 4.1. MySQL 调优效果对比\n\n我们以 MySQL 的开箱性能为基线，对比了本领域模型与业界领先的 DeepSeek-V2 67B 模型在相同场景下的调优效果。\n\n| 模型 | 部署环境 | 调优效果 | 结论 |\n| :--- | :--- | :--- | :--- |\n| **openEuler 领域模型** | 纯 CPU | 与右侧基本持平 | 在极大降低硬件门槛的同时，实现了与顶尖大模型相当的调优性能。 |\n| **DeepSeek-V2 67B** | GPU | 与左侧基本持平 | 性能强大，但依赖高端硬件。 |\n\n#### 4.2. 泛化能力验证\n\n为了验证模型的通用性，我们在多种主流应用上进行了测试。结果表明，本领域模型在不同场景下均能达到与 DeepSeek-V2 67B 基本持平的调优效果。\n\n*   **已验证应用列表**：\n    *   Spark\n    *   Nginx\n    *   Ceph\n    *   PostgreSQL\n    *   MySQL",
      "original_script": "而且在本次会议之前，这个洞察工具的DSL文件和刚才模型部署的所有脚本已经在社区开源了。\n而且在本次会议之前，这个洞察工具的DSL文件和刚才模型部署的所有脚本已经在社区开源了。\n而且在本次会议之前，这个洞察工具的DSL文件和刚才模型部署的所有脚本已经在社区开源了。\n好的，谢谢辛总。\n大家好，我是openEuler智能调优团队的王树源。\n然后开源的链接在屏幕的正上方，大家可以参考一下。\n然后开源的链接在屏幕的正上方，大家可以参考一下。\n然后开源的链接在屏幕的正上方，大家可以参考一下。\n在调优领域，最开始都是依赖我们的调优专家们进行人工调优。\n那么现在整个洞察任务已经结束了。\n那么现在整个洞察任务已经结束了。\n那么现在整个洞察任务已经结束了。\n这样带来的问题是人力成本高、调优耗时长、强依赖专家知识。\n当然为了方便我随时去查看每天的洞察结果，我也配置了邮件订阅这么一个功能。\n当然为了方便我随时去查看每天的洞察结果，我也配置了邮件订阅这么一个功能。\n当然为了方便我随时去查看每天的洞察结果，我也配置了邮件订阅这么一个功能。\n之后，我们openEuler推出了A-Tune工具，进行了自动化的调优，但是对于先验知识的强依赖性问题还是没有解决。\n然后可以看一下邮箱。\n然后可以看一下邮箱。\n然后可以看一下邮箱。\n最后，我们在A-Tune的基础上提出了大模型智能调优方案，利用大模型的学习能力与分析能力，自主完成瓶颈分析和参数推荐，节约人力成本，节省调优耗时，摆脱对先验知识的强依赖性。\n可以看到邮箱确实已经收到了刚才洞察的结果。\n可以看到邮箱确实已经收到了刚才洞察的结果。\n可以看到邮箱确实已经收到了刚才洞察的结果。\n而且在一分钟左右的时间就得到这么多细化的内容，确实效率比人工高多了。\n而且在一分钟左右的时间就得到这么多细化的内容，确实效率比人工高多了。\n而且在一分钟左右的时间就得到这么多细化的内容，确实效率比人工高多了。\n如果大家感兴趣，可以在会后也尝试一下屏幕上方的链接。\n如果大家感兴趣，可以在会后也尝试一下屏幕上方的链接。\n如果大家感兴趣，可以在会后也尝试一下屏幕上方的链接。\n基于此背景，我们进一步推出了支持内嵌在openEuler操作系统中的领域模型，它可以在纯CPU环境进行推理部署。\n好，谢谢大家。\n好，谢谢大家。\n好，谢谢大家。\n好，谢谢小伙伴的分享。\n好，谢谢小伙伴的分享。\n好，谢谢小伙伴的分享。\n下面，我将向大家演示我们领域模型在鲲鹏920B服务器上的使用，纯CPU环境进行部署。\n就我们能看到，就是我们的全栈既能够支持在不同的企业环境里面高效地获取AI软件、运行，然后也能够支持在上面高效地基于企业自己的数据去开发Agent以及定制模型。\n就我们能看到，我们的全栈既能够支持在不同的企业环境里面高效地获取AI软件、运行，然后也能够支持在上面高效地基于企业自己的数据去开发Agent以及定制模型。\n就我们能看到，我们的全栈既能够支持在不同的企业环境里面高效地获取AI软件、运行，然后也能够支持在上面高效地基于企业自己的数据去开发Agent以及定制模型。\n首先，我们将模型文件下载到本地环境。\n可以看到我们的OS领域模型模型文件共有9个，总计2.2个G左右。\n然后，我们使用Llama-cpp工具直接将我们的领域模型在纯CPU环境上进行部署。\n我们都知道openEuler是一个全场景、多样性算力支持的这样一个操作系统社区，所以刚才在讲Intelligence BoM的时候，肯定也有小伙伴在想，\n我们都知道openEuler是一个全场景、多样性算力支持的这样一个操作系统社区，所以刚才在讲Intelligence BoM的时候，肯定也有小伙伴在想，\n我们都知道openEuler是一个全场景、多样性算力支持的这样一个操作系统社区，所以刚才在讲Intelligence BoM的时候，肯定也有小伙伴在想，\n可以看到我们的领域模型已经成功在纯CPU环境完成了部署。\n就是Intelligence BoM它是不是只能够在云和服务器上来运行？\n就是Intelligence BoM它是不是只能够在云和服务器上来运行？\n就是Intelligence BoM它是不是只能够在云和服务器上来运行？\n接着，我们将我们的领域模型配置到我们的智能调优应用中，主要是LLM URL以及LLM model name这两个参数。\n那我们都理解这样一个问题。\n那我们都理解这样一个问题。\n那我们都理解这样一个问题。\n所以这是我们的回答。\n所以这是我们的回答。\n所以这是我们的回答。\n这边我已经提前配置好。\n就并不是。\n就并不是。\n就并不是。\n我们在看Intelligence BoM的话，它虽然是从服务器、从云上的AI软件栈开始，但是它一定会扩展成为一个全场景的AI的参考实现。\n我们在看Intelligence BoM的话，它虽然是从服务器、从云上的AI软件栈开始，但是它一定会扩展成为一个全场景的AI的参考实现。\n我们在看Intelligence BoM的话，它虽然是从服务器、从云上的AI软件栈开始，但是它一定会扩展成为一个全场景的AI的参考实现。\n然后我们启动我们的智能调优。\n由于现在调优还是小时级的，所以我们这里跳过我们的调优过程，直接给大家展示一下我们的调优效果。\n所以，那除了云和服务器之外的话，现在在什么场合里面大家对于AI的诉求最强烈呢？就是具身智能机器人。\n所以，那除了云和服务器之外的话，现在在什么场合里面大家对于AI的诉求最强烈呢？就是具身智能机器人。\n所以，那除了云和服务器之外的话，现在在什么场合里面大家对于AI的诉求最强烈呢？就是具身智能机器人。\n我们基于MySQL开箱性能作为基线，然后我们预先跑好了，左边是我们的领域模型的调优效果，右边是我们的DeepSeek-V2 671B模型的调优效果。可以看到，从最终的调优效果来对比，\n所以我们很高兴地把Intelligence BoM在云上的和边缘上的这样的栈，通过云边协同、端边协同的方式和具身机器人去做一个相应的对接。\n所以我们很高兴地把Intelligence BoM在云上的和边缘上的这样的栈，通过云边协同、端边协同的方式和具身机器人去做一个相应的对接。\n所以我们很高兴地把Intelligence BoM在云上的和边缘上的这样的栈，通过云边协同、端边协同的方式和具身机器人去做一个相应的对接。\n我们的领域模型在支持纯CPU环境推理部署的前提下，又能达到DeepSeek-V2 671B模型的调优效果。\n最后，我们的领域模型在其他应用的泛化能力，我们总结了一个表格。我们在Spark、Nginx、Ceph、PG-circle、MySQL等应用上均进行了调优效果的验证。最后的结果表明，我们的领域模型效果与DeepSeek-V2 671B的调优效果基本持平。\n传统的软件栈的话是以ROS，就是机器人OS这个中间件为基础的，但是它们的智能化能力不足。\n传统的软件栈的话是以ROS，就是机器人OS这个中间件为基础的，但是它们的智能化能力不足。\n传统的软件栈的话是以ROS，就是机器人OS这个中间件为基础的，但是它们的智能化能力不足。\n我们的AI软件栈虽然在数字世界里面有强大的能力，但是缺的是和物理世界交互的能力。\n我们的AI软件栈虽然在数字世界里面有强大的能力，但是缺的是和物理世界交互的能力。\n我们的AI软件栈虽然在数字世界里面有强大的能力，但是缺的是和物理世界交互的能力。\n所以通过Intelligence BoM在云边协同和端侧的具身智能的软件栈的这个对接，我们希望能够去构建一种全新的AI机器人的框架，通过数据感知层来采集数据、筛选数据，通过基础框架和AI栈在云边的协同和联动，实现高效的推理和精准的控制，并且能够针对异构加速、多模型性能调优这些场景去做针对性的优化。\n所以通过Intelligence BoM在云边协同和端侧的具身智能的软件栈的这个对接，我们希望能够去构建一种全新的AI机器人的框架，通过数据感知层来采集数据、筛选数据，通过基础框架和AI栈在云边的协同和联动，实现高效的推理和精准的控制，并且能够针对异构加速、多模型性能调优这些场景去做针对性的优化。\n所以通过Intelligence BoM在云边协同和端侧的具身智能的软件栈的这个对接，我们希望能够去构建一种全新的AI机器人的框架，通过数据感知层来采集数据、筛选数据，通过基础框架和AI栈在云边的协同和联动，实现高效的推理和精准的控制，并且能够针对异构加速、多模型性能调优这些场景去做针对性的优化。\n关于领域模型的演示到此结束，谢谢大家。",
      "start_ms": 190890,
      "end_ms": 339475,
      "material_ids": [
        "chunk_00/slide_003",
        "chunk_00/slide_004",
        "chunk_00/slide_005"
      ],
      "summary_hint": "现场演示了openEuler的智能调优能力，通过领域模型在纯CPU环境下进行部署和调优，并展示了其在多种应用上的泛化能力验证结果。",
      "notes": "第一位演示嘉宾上台，展示了openEuler智能调优工具在鲲鹏服务器上的实际操作和效果。",
      "lead_text": "而且在本次会议之前，这个洞察工具的DSL文件和刚才模型部署的所有脚本已经在社区开源了。",
      "tail_text": "关于领域模型的演示到此结束，谢谢大家。",
      "text_span": {
        "start": 77,
        "end": 162
      }
    },
    {
      "id": "sec_3",
      "index": 2,
      "title": "推出开源AI解决方案：Intelligence BoM",
      "time_range": "00:05:42,410 - 00:09:06,095",
      "summary": "讲者介绍了Intelligence BoM（AI解决方案），一个旨在通过云边协同和端侧具身智能软件栈对接，构建全新AI机器人框架的方案。",
      "refined_script": "### 1. 方案愿景与目标\n\nIntelligence BoM 是 openEuler 社区联合高校、企业及其他社区共同打造的全栈开源 AI 技术软件解决方案。其核心愿景是通过开源参考实现打破技术壁垒，加速大模型推理技术的普及，从而赋能千行百业的智能化转型。\n\n该方案旨在构建一个全新的 AI 机器人框架，其关键目标包括：\n\n- **云边端协同**：打通云、边、端之间的软件栈，实现高效协同。\n- **数据驱动**：通过数据感知层采集与筛选数据，驱动模型迭代。\n- **高效推理与控制**：借助基础框架与 AI 栈的联动，实现高效推理与精准控制。\n- **性能优化**：针对异构计算加速、多模型性能调优等场景进行深度优化。\n\n### 2. Intelligence BoM 2511 版本发布\n\n我们正式发布 Intelligence BoM 的第二个参考实现版本：**Intelligence BoM 2511**。\n\n- **版本命名**：社区约定每个参考实现版本均以中国地方特色美食命名。继首个版本“烩面”（河南）之后，2511 版本命名为“敲鱼面”（浙江温州）。\n- **核心进展**：该版本在以下方面取得了显著进展：\n  - **低成本**：降低了 AI 方案的部署与使用门槛。\n  - **高效率**：提升了模型训练与推理的效率。\n  - **易落地**：简化了部署流程，使企业级 AI 助手更易于实现。\n\n### 3. 关键技术特性与进展\n\n自 2023 年 7 月发布首个参考实现版本以来，Intelligence BoM 社区在以下几个方向上快速迭代与演进：\n\n- **生态拓展**：与智源人工智能研究院、中国科学院自动化研究所、AGIROS 等伙伴共同推进生态建设。\n- **异构协同**：增强了对不同硬件加速器的支持与协同能力。\n- **易用性**：提升了方案的开箱即用体验，让 Agentic AI 软件生态触手可及。\n- **模型微调**：增强了模型微调能力，使得在 openEuler 操作系统上，用户可以利用自有语料和数据训练特定领域的模型。这一能力是实现大模型替代专家进行系统调优等高级功能的基础。\n\n### 4. 成果与展望\n\n- **技术突破**：我们首次实现了**仅通过 CPU 进行大模型推理**，无需依赖定制硬件。这一突破显著提高了 AI 技术的普适性，降低了落地门槛。\n- **生态合作**：目前方案仍在紧锣密鼓地开发中，欢迎更多伙伴参与共建。现场展区已展示了阶段性成果，可供参观交流。\n- **未来方向**：我们相信，在操作系统中内嵌更多专用小模型的探索将成为未来开源社区和学术研究的热点方向。Intelligence BoM 为这一探索指明了道路。",
      "original_script": "所以通过Intelligence BoM在云边协同和端侧的具身智能的软件栈的这个对接，我们希望能够去构建一种全新的AI机器人的框架，通过数据感知层来采集数据、筛选数据，通过基础框架和AI栈在云边的协同和联动，实现高效的推理和精准的控制，并且能够针对异构加速、多模型性能调优这些场景去做针对性的优化。\n所以通过Intelligence BoM在云边协同和端侧的具身智能的软件栈的这个对接，我们希望能够去构建一种全新的AI机器人的框架，通过数据感知层来采集数据、筛选数据，通过基础框架和AI栈在云边的协同和联动，实现高效的推理和精准的控制，并且能够针对异构加速、多模型性能调优这些场景去做针对性的优化。\n所以通过Intelligence BoM在云边协同和端侧的具身智能的软件栈的这个对接，我们希望能够去构建一种全新的AI机器人的框架，通过数据感知层来采集数据、筛选数据，通过基础框架和AI栈在云边的协同和联动，实现高效的推理和精准的控制，并且能够针对异构加速、多模型性能调优这些场景去做针对性的优化。\n关于领域模型的演示到此结束，谢谢大家。\n谢谢树源的介绍。\n我相信大家对于这样的一个演示应该都非常的有感触。\n因为首先这是基于大模型来替代我们的专家在这里去做一个快速的系统调优，并且在刚才的演示中能看到，它不光在调优的结果，并且在泛化能力上面都有一个非常出色的呈现。\n然后另一方面的话，这也是我们第一次能够不通过定制的硬件，只通过CPU来做推理，这使得这样一项技术的可普及性大大提高。\n我们整个方案的话，当前还在紧锣密鼓地开发阶段。当前智源、中科院自动化所、AGIROS这些伙伴都以及参与进来，在共同推进整个生态的建设和发展。现场展区的话也有相应的阶段性成果，欢迎各位待会儿会议间隙的时候能够去做参观和交流。\n我们整个方案的话，当前还在紧锣密鼓地开发阶段。当前智源、中科院自动化所、AGIROS这些伙伴都以及参与进来，在共同推进整个生态的建设和发展。现场展区的话也有相应的阶段性成果，欢迎各位待会儿会议间隙的时候能够去做参观和交流。\n我们整个方案的话，当前还在紧锣密鼓地开发阶段。当前智源、中科院自动化所、AGIROS这些伙伴都以及参与进来，在共同推进整个生态的建设和发展。现场展区的话也有相应的阶段性成果，欢迎各位待会儿会议间隙的时候能够去做参观和交流。\n我们相信这样的一个探索也为后续在操作系统里内嵌更多的小的模型，也指出了一个方向。我们相信这会是一个后续操作系统领域里面大家开源探索和学术研究的一个热门的主题。\n好。\n好。\n好。\n那么对于openEuler来说，我们为什么今年能够做到这件事情？其实也是有一个很强的相关性，就是我们在今年通过刚才提到的Intelligence BoM这样一个openEuler和我们的伙伴联合的开源解决方案。\n通过这样的一个方案的话，我们在其中的模型微调能力，使得我们在openEuler上围绕自己的语料、围绕自己的数据去真训一个模型，成为了可能。\n在这里给大家再回顾一下，Intelligence BoM是openEuler和高校、企业以及各个社区联合打造的全栈开源的AI技术软件解决方案。我们在7月份的时候推出了第一个这样的一个参考实现版本，愿景就是通过这样的一个开源的参考实现来打破技术壁垒，通过全栈开源来加速大模型推理技术的普惠，来赋能行业的转型。\n在7月份之后的话，实际上整个社区还在快速地往前迭代和演进。我们在生态拓展、异构协同、在简单易用以及模型微调上都有了相应的进展。\n所以很高兴地在这里也给大家宣布一下，就是我们在当期发布Intelligence BoM 2511的第二个参考实现版本。我们在最开始设计的时候，就是社区里面基于AI工作组大家讨论，我们希望把每一个参考实现版本的话，用一种中国的地方特色美食来命名。\n所以当时第一个版本我们用的名字是河南的烩面，第二个的话是这个建议来自一位我的互联网朋友，他是浙江温州人，所以是温州当地的一种特色美食叫做敲鱼面。大家如果对这个名字不熟的话，可以下来自行那个搜索引擎或者通过豆包去查询一下。\n那在这个版本里面的话，我们在低成本、高效率、易落地这些上面其实都有了相应的这个进展，所以通过BoM这种方案的话，也使得更多的企业级AI助手可及。\n然后我们下面的话，其实就希望通过小伙伴的演示给大家更直观地了解一下，我们这样一个开源全栈到底怎么能够让Agentic AI的软件生态触手可及、开箱即用。有请。",
      "start_ms": 342410,
      "end_ms": 546095,
      "material_ids": [
        "chunk_00/slide_006",
        "chunk_00/slide_007"
      ],
      "summary_hint": "讲者介绍了Intelligence BoM（AI解决方案），一个旨在通过云边协同和端侧具身智能软件栈对接，构建全新AI机器人框架的方案。",
      "notes": "The planned start sentence '所以通过Intelligence BoM...' (line 160) is actually part of the next speaker's content. The start time is adjusted to the actual beginning of this section's speaker (line 164 '谢谢树源的介绍').",
      "lead_text": "所以通过Intelligence BoM在云边协同和端侧的具身智能的软件栈的这个对接，我们希望能够去构建一种全新的AI机器人的框架，通过数据感知层来采集数据、筛选数据，通过基础框架和AI栈在云边的协同和联动，实现高效的推理和精准的控制，并且能够针对异构加速、多模型性能调优这些场景去做针对性的优化。",
      "tail_text": "然后我们下面的话，其实就希望通过小伙伴的演示给大家更直观地了解一下，我们这样一个开源全栈到底怎么能够让Agentic AI的软件生态触手可及、开箱即用。有请。",
      "text_span": {
        "start": 159,
        "end": 181
      }
    },
    {
      "id": "sec_4",
      "index": 3,
      "title": "演示：基于Dify的Agent开发",
      "time_range": "00:09:08,260 - 00:12:51,919",
      "summary": "现场演示了如何使用Dify等开源项目，结合昇腾和GPU环境下的模型推理服务，快速搭建和开发一个AI Agent智能体。",
      "refined_script": "### 1. 背景与痛点\n\n人工智能领域技术迭代迅速，从业者需要持续关注最新的AI资讯、模型发布和开源工具。然而，信息源分散，手动追踪和学习耗时耗力。为了解决这一痛点，我们开发了一个智能洞察助手（AI Agent），旨在自动化地完成信息收集、分析和总结，从而提升效率。\n\n### 2. 解决方案概述\n\n我们利用开源项目 **Dify** 作为智能体编排与开发平台，结合在 **昇腾（Ascend）** 和 **GPU** 环境中部署的大语言模型推理服务，快速构建了一个AI洞察助手。该助手能够自动从指定信息源获取内容、进行多层次分析，并最终生成洞察报告。\n\n### 3. 技术架构与组件\n\n本方案的核心组件包括Dify编排层、多模型推理服务层以及底层硬件支持。所有服务均基于 **openEuler** 社区发布的软件栈构建。\n\n**软件栈概览：**\n\n| 组件 | 用途 | 部署环境 | 依赖的openEuler镜像 |\n| :--- | :--- | :--- | :--- |\n| **Dify** | AI Agent编排与工作流定义 | - | - |\n| **Qwen2-7B** | 从用户需求中提取信息源链接 | 昇腾服务器 | `openEuler Llama-cpp` 镜像 |\n| **Qwen2-72B** | 提取浅层网页内容 | GPU服务器 | `openEuler vLLM` 镜像 |\n| **Qwen2-57B-A14B** | 深度分析与内容总结 | GPU服务器 | `openEuler S-Giant` 镜像 |\n\n### 4. 演示步骤与工作流\n\n以下是现场演示的操作流程，展示了从服务启动到获取最终结果的全过程。\n\n1.  **启动依赖服务**\n    *   启动 Dify 服务。\n    *   在昇腾服务器上启动基于 `Llama-cpp` 的 `Qwen2-7B` 模型推理服务。\n    *   在GPU服务器上分别启动基于 `vLLM` 的 `Qwen2-72B` 和基于 `S-Giant` 的 `Qwen2-57B-A14B` 模型推理服务。\n    *   检查并确认所有服务均已正常运行。\n\n2.  **执行洞察任务**\n    *   登录 Dify 工作界面。\n    *   导入预先编排好的工作流DSL（Domain-Specific Language）文件。\n    *   触发洞察任务，Agent开始执行。\n\n3.  **Agent 工作流解析**\n    *   **步骤一：信息源获取**\n        *   Agent 调用 `Qwen2-7B` 模型，根据用户输入的需求，解析并获取相关网页链接。\n    *   **步骤二：分层内容提取**\n        *   **浅层提取**：Agent 调用 `Qwen2-72B` 模型，访问链接并提取初步信息。\n        *   **深度分析**：Agent 将初步信息交由 `Qwen2-57B-A14B` 稀疏模型进行深度的分析、归纳和总结。\n\n4.  **查看结果**\n    *   任务执行完毕后，系统自动将生成的洞察报告发送至预设邮箱。\n    *   演示中，约一分钟内即可收到包含详细分析内容的邮件，验证了方案的高效性。\n\n### 5. 资源与复现\n\n为方便社区开发者复现和使用，本项目相关的资源已全部开源：\n\n*   **开源内容**：\n    *   Dify 工作流 DSL 文件\n    *   所有模型部署的脚本\n*   **获取方式**：请参考屏幕上方展示的开源链接进行访问和尝试。\n\n通过该方案，我们展示了如何利用 Dify 和 openEuler 生态中的工具链，高效地将强大的大模型能力封装为实用的AI Agent，解决实际业务痛点。",
      "original_script": "在正式开始之前，我们可以一块想一个问题，那就是DeepSeek-V2是什么时候发布的？\n其实很多时候直觉告诉我，这是一两年前的模型了。\n但实际上是今年年初才发布的，之所以有这种错觉是因为现在AI领域的技术实际发展得太快了。\n那么作为从业者，为了能够跟上这些前沿的技术，我经常会去一些技术平台学习、总结，比如去看一下最新的AI资讯，然后学习一下最新发布的AI Agent的工具等。\n但是类似的信息发布平台非常多，这种事情花费了我很大精力。\n那这个时候如果有一个智能洞察的助手能够完成这些事情，那就轻松多了。\n恰好现在也出现了像Dify、Cozey这样非常适合新手去搭建智能体的项目。\n恰好现在也出现了像Dify、Cozey这样非常适合新手去搭建智能体的项目。\n恰好现在也出现了像Dify、Cozey这样非常适合新手去搭建智能体的项目。\n恰好现在也出现了像Dify、Cozey这样非常适合新手去搭建智能体的项目。\n那么我也去尝试用Dify开发了这么一个工具。\n现在给大家演示一下。\n首先启动Dify服务。\nOK，它已经正常启动了。\n除了使用Dify来编排这个工具以外，我们还用到了大模型的推理能力。\n刚才我已经在昇腾的服务器上和GPU环境分别拉起了模型。大屏幕上也显示了这些推理服务用到的软件栈。\n现在检查一下这些服务是否OK。\n好的，昇腾服务器上已经正常启动了两个大模型。\n然后再来看一下GPU环境的状态。\n也没有问题。\n那这时候就可以进入到Dify的工作界面。\n接着导入已经编排好的DSL文件。\n好的，已经导入完成了。\n那现场让它完成一个洞察任务。\n趁着工具运行的时间，我们回头看一下整个执行过程中用到了哪些openEuler发布的软件。\n先是从用户需求获取信息源链接的时候，用到了Qwen2-7B的模型。\n这个模型是用openEuler官方Llama-cpp镜像在昇腾服务器上启动的。\n然后，在分层次提取链接内容的过程中，\n浅层网页的信息提取用到的是Qwen2-72B模型。\n然后深度分析和总结的Agent用到的是Qwen2-57B-A14B稀疏模型。\n这两个模型分别用openEuler发布的vLLM和S-Giant镜像一键启动的，非常方便。\n而且在本次会议之前，这个洞察工具的DSL文件和刚才模型部署的所有脚本已经在社区开源了。\n然后开源的链接在屏幕的正上方，大家可以参考一下。\n那么现在整个洞察任务已经结束了。\n当然为了方便我随时去查看每天的洞察结果，我也配置了邮件订阅这么一个功能。\n然后可以看一下邮箱。\n可以看到邮箱确实已经收到了刚才洞察的结果。\n而且在一分钟左右的时间就得到这么多细化的内容，确实效率比人工高多了。\n如果大家感兴趣，可以在会后也尝试一下屏幕上方的链接。\n好，谢谢大家。",
      "start_ms": 548260,
      "end_ms": 771919,
      "material_ids": [
        "chunk_00/slide_008",
        "chunk_00/slide_009"
      ],
      "summary_hint": "现场演示了如何使用Dify等开源项目，结合昇腾和GPU环境下的模型推理服务，快速搭建和开发一个AI Agent智能体。",
      "notes": "The planned start sentence '在正式开始之前...' (line 185) is preceded by the speaker's self-introduction. The start time is adjusted to the speaker's first words (line 183 '好的，大家好') for better accuracy.",
      "lead_text": "在正式开始之前，我们可以一块想一个问题，那就是DeepSeek-V2是什么时候发布的？",
      "tail_text": "好，谢谢大家。",
      "text_span": {
        "start": 184,
        "end": 223
      }
    },
    {
      "id": "sec_5",
      "index": 4,
      "title": "Intelligence BoM Robot：具身智能机器人软件栈",
      "time_range": "00:12:55,160 - 00:15:32,549",
      "summary": "讲者介绍了Intelligence BoM Robot，一个开箱即用的具身智能机器人软件栈，展示了openEuler从云到端全场景支持AI应用的能力。",
      "refined_script": "### Intelligence BoM Robot：面向具身智能的软件栈\n\nopenEuler 社区致力于构建一个支持全场景、多样性算力的操作系统生态。基于此愿景，我们将 Intelligence BoM 的能力从云端与服务器环境，进一步拓展至具身智能机器人领域，推出了 Intelligence BoM Robot——一个开箱即用的具身智能机器人软件栈。\n\n#### 1. 背景与挑战\n\n当前机器人技术领域存在两大挑战：\n\n*   **传统机器人软件栈的局限性**：以机器人操作系统（ROS）为核心的传统软件栈，虽然奠定了机器人开发的基础，但在智能化能力方面表现不足。\n*   **AI 软件栈的物理交互缺失**：强大的云端 AI 软件栈虽然在数字世界中具备卓越的分析与决策能力，但普遍缺乏与物理世界直接交互的机制。\n\n为了弥合这两者之间的鸿沟，Intelligence BoM Robot 旨在构建一种全新的 AI 机器人框架，将 AI 的“大脑”与机器人的“身体”进行深度融合。\n\n#### 2. 核心架构与设计理念\n\nIntelligence BoM Robot 的核心是通过云边端协同，将云端和边缘的 Intelligence BoM AI 软件栈与端侧的具身智能机器人进行无缝对接。其架构旨在实现以下目标：\n\n*   **数据驱动**：通过内置的数据感知层，高效地采集、筛选和处理来自物理世界的多模态数据。\n*   **云边协同**：利用基础框架与 AI 栈在云、边两侧的协同联动，实现高效的分布式推理和精准的机器人动作控制。\n*   **性能优化**：针对异构加速硬件（如 GPU、NPU 等）和多模型并行推理等复杂场景，进行深度性能调优。\n\n#### 3. 生态合作与项目进展\n\nIntelligence BoM Robot 并非闭门造车，而是一个开放的生态合作项目。目前，我们正与业界领先的合作伙伴紧密合作，共同推进整个生态的建设与发展。\n\n*   **当前合作伙伴**：\n    *   北京智源人工智能研究院 (BAAI)\n    *   中国科学院自动化研究所 (CASIA)\n    *   AGIROS 社区\n\n*   **项目状态**：\n    *   该方案目前正处于紧锣密鼓的开发阶段。\n    *   相关的阶段性成果已在现场展区进行展示，欢迎进行参观与交流。",
      "original_script": "好，谢谢小伙伴的分享。\n就我们能看到，我们的全栈既能够支持在不同的企业环境里面高效地获取AI软件、运行，然后也能够支持在上面高效地基于企业自己的数据去开发Agent以及定制模型。\n我们都知道openEuler是一个全场景、多样性算力支持的这样一个操作系统社区，所以刚才在讲Intelligence BoM的时候，肯定也有小伙伴在想，\n就是Intelligence BoM它是不是只能够在云和服务器上来运行？\n那我们都理解这样一个问题。\n所以这是我们的回答。\n就并不是。\n我们在看Intelligence BoM的话，它虽然是从服务器、从云上的AI软件栈开始，但是它一定会扩展成为一个全场景的AI的参考实现。\n所以，那除了云和服务器之外的话，现在在什么场合里面大家对于AI的诉求最强烈呢？就是具身智能机器人。\n所以我们很高兴地把Intelligence BoM在云上的和边缘上的这样的栈，通过云边协同、端边协同的方式和具身机器人去做一个相应的对接。\n传统的软件栈的话是以ROS，就是机器人OS这个中间件为基础的，但是它们的智能化能力不足。\n我们的AI软件栈虽然在数字世界里面有强大的能力，但是缺的是和物理世界交互的能力。\n所以通过Intelligence BoM在云边协同和端侧的具身智能的软件栈的这个对接，我们希望能够去构建一种全新的AI机器人的框架，通过数据感知层来采集数据、筛选数据，通过基础框架和AI栈在云边的协同和联动，实现高效的推理和精准的控制，并且能够针对异构加速、多模型性能调优这些场景去做针对性的优化。\n我们整个方案的话，当前还在紧锣密鼓地开发阶段。当前智源、中科院自动化所、AGIROS这些伙伴都以及参与进来，在共同推进整个生态的建设和发展。现场展区的话也有相应的阶段性成果，欢迎各位待会儿会议间隙的时候能够去做参观和交流。\n好。",
      "start_ms": 775160,
      "end_ms": 932549,
      "material_ids": [
        "chunk_00/slide_010",
        "chunk_00/slide_011",
        "chunk_00/slide_012"
      ],
      "summary_hint": "讲者介绍了Intelligence BoM Robot，一个开箱即用的具身智能机器人软件栈，展示了openEuler从云到端全场景支持AI应用的能力。",
      "notes": "在第二次演示后，讲者将话题从云和服务器扩展到了端侧的具身智能机器人。",
      "lead_text": "好，谢谢小伙伴的分享。",
      "tail_text": "好。",
      "text_span": {
        "start": 224,
        "end": 238
      }
    }
  ]
}