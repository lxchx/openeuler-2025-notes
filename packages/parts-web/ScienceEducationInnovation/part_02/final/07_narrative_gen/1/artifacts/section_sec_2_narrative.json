{
  "id": "sec_2",
  "index": 1,
  "title": "研究背景：推荐模型的存储困境",
  "time_range": "00:02:01,255 - 00:05:52,999",
  "script": "回到本次演讲的主题，我们主要针对推荐模型的参数存储，即刚才提到的最底层。\n我们面临的现状是，当今互联网非常发达，每天都会产生海量的视频、微博、推特推文，以及抖音、快手的视频。\n海量信息远超个人处理能力，因此推荐模型负责筛选信息并呈现给用户。\n在Facebook的人工智能集群中，据统计，推荐模型在人工智能服务中的耗时占比已达到80%。\n因此，推荐模型已成为现代数据中心人工智能服务的主要载体。\n我们具体看一下推荐模型的结构。可以发现，它与传统的CV或NLP模型不同，其特点是拥有一个非常大的嵌入层，即Embedding层。\n其中包含许多嵌入表，例如城市嵌入表、用户嵌入表和视频嵌入表。\n这些嵌入表的作用是什么？在推荐模型中，其输入不像ResNet等模型那样是一张稠密的图，而是非常高维、稀疏的ID。\nDNN难以处理高维稀疏的ID，因此使用嵌入表将其转换为低维稠密的向量。\n在整个过程中，以视频ID为例，如果我最近观看了三个视频，就会对应地找出这三行，再输入到神经网络中。\n稀疏参数这一部分并非计算密集型，而是访存密集型。\n我们总结，当前推荐模型面临两方面的存储困境。第一，其参数量巨大。\n由于ID交叉等技术，Embedding层的参数规模可达12万亿。\n此外，广泛的工业实践也表明，模型精度依赖于参数量的提升。\n第二是带宽墙。Embedding层涉及大量访存操作，而非计算操作。\n根据阿里的一项统计，访存操作（即Embedding操作）占端到端模型时间的70%以上。\n因此，这严重限制了算力的发挥。\n受这两堵墙的叠加影响，以快手为例，其部署了上万台内存参数服务器，专门用于存储模型参数。\n其硬件成本非常高昂，达到了十亿元级别。\n综上所述，存储系统已成为制约推荐模型发展的核心因素。\n幸运的是，随着硬件的发展，出现了不同层级的存储硬件。\n例如，在性能层有HBM。HBM不仅被集成到GPU中并得到广泛应用，一些新一代CPU也集成了HBM。\n我们可以将其用作缓存，以缓解带宽墙问题。\n在容量层，则有持久性内存。其成本更低，可用于内存扩容。\n从而打破容量墙。\n那么，我们如何利用好这些硬件呢？\n我们认为需要从算法、系统和硬件三个层面进行协同设计。",
  "summary": "推荐模型因其处理高维稀疏ID的巨大Embedding层，面临参数量巨大的“容量墙”和访存密集型的“带宽墙”两大存储困境，导致硬件成本高昂。讲者指出，存储系统已成为模型发展的核心瓶颈，并提出利用HBM和持久性内存等新兴分层存储硬件，通过算法、系统和硬件的协同设计来解决该问题。"
}