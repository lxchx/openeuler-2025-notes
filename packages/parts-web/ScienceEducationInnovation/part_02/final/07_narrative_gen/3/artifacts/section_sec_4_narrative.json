{
  "id": "sec_4",
  "index": 3,
  "title": "GPU层参数存储：Fleche",
  "time_range": "00:08:04,399 - 00:24:30,739",
  "script": "可以看到，相比于LRU，OptEmbed可以将缓存的命中率提升10%以上，同时模型的精度也没有明显的下降。\n接下来，我们看一下系统层面的工作，也就是我们发表在SC 2022上的工作Fluid。\n我们知道，推荐模型的参数是存储在参数服务器上的，而参数服务器通常是采用分布式的方式来部署的。\n因此，我们需要设计一个分布式的参数存储系统。\n我们提出了一个叫做Fluid的系统。\nFluid是一个分层的参数存储系统，它将参数分为热点参数、温点参数和冷点参数。\n热点参数存储在HBM中，温点参数存储在DRAM中，冷点参数存储在SSD中。\n通过这种方式，我们可以实现一个比较好的性能和成本的折中。\n同时，Fluid还提供了一些高级的功能。\n比如说，它支持参数的动态迁移。\n当一个参数的热度发生变化时，Fluid会自动地将其迁移到合适的存储层。\n此外，Fluid还支持参数的快照和恢复。\n当系统发生故障时，我们可以快速地将参数恢复到之前的状态。\n我们在实验中也验证了Fluid的有效性。\n可以看到，相比于传统的参数服务器，Fluid可以将系统的吞吐量提升2倍以上，同时系统的成本也降低了50%以上。\n最后，我们看一下硬件层面的工作，也就是我们发表在MICRO 2022上的工作Smart-Prefetcher。\n我们知道，推荐模型的参数访问具有很强的局部性。\n例如，一个用户可能会连续访问多个相关的视频。\n因此，我们可以利用这种局部性，将相关的参数预取到缓存中，从而提升缓存的命中率。\n但是，传统的预取方法并不适用于推荐模型的场景。",
  "summary": "本节介绍了系统层面的工作 Fluid，一个分层的分布式参数存储系统。它将参数按热度分层存储于 HBM、DRAM 和 SSD 中以平衡性能与成本，并通过动态迁移、快照恢复等功能，将系统吞吐量提升2倍以上。最后，简要提及了利用参数访问局部性进行预取的硬件层工作 Smart-Prefetcher。"
}