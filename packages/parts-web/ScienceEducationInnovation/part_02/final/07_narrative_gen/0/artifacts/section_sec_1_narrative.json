{
  "id": "sec_1",
  "index": 0,
  "title": "开场与研究总览",
  "time_range": "00:00:08,385 - 00:02:00,915",
  "script": "谢谢主持人的介绍，也谢谢各位领导、老师。\n我是来自中国人民大学的谢旻辉。\n我本次汇报的题目是面向推荐大模型的参数存储系统研究。\n首先，对我的个人情况做一个简单的介绍。\n我本科在南京大学就读，去年在清华大学计算机系陆游和舒继武老师的指导下获得博士学位，毕业后就职于中国人民大学。\n也获得了一些奖项，包括ACM中国优秀博士学位论文奖、北京市青年人才托举工程，并承担了一系列企业项目。\n我本人的研究方向主要是围绕机器学习系统。\n具体而言，是存储系统和机器学习系统交叉的部分，主要从事面向Storage for AI的研究。\n我们目前的工作主要围绕参数存储、向量存储和记忆存储三个层次展开。\n我们认为，随着人工智能模型规模的增大，需要存储的参数也随之增多。\n其次，人工智能模型看待世界万物的方式，是将其表达为向量。因此，向量也是我们需要考虑的关键组件。\n第三是记忆存储。区别于聊天机器人，一个真正智能体的关键在于其是否拥有记忆。如果没有记忆，它只是一个简单的Chatbot。\n因此，我们也会面向特定场景，研究面向LLM的记忆，包括RAG或参数化的记忆方案。",
  "summary": "讲者谢旻辉首先进行自我介绍，阐述其教育背景和研究方向。随后，他概述了其在“Storage for AI”领域的研究工作，主要围绕参数存储、向量存储和记忆存储三个层次展开，并解释了这三个层次对于大规模人工智能模型和智能体的重要性。"
}