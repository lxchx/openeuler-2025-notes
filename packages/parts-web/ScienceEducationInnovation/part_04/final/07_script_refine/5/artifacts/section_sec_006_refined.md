# Expert Kit：以 Expert 为中心的异构融合推理系统

## 1. 背景与核心挑战
在大规模混合专家模型（MoE）的推理场景中，系统常面临资源受限或极端算力需求的挑战。由于 MoE 模型参数量巨大，传统的单一硬件部署难以平衡成本与性能。

## 2. 核心设计理念：以 Expert 为中心的异构调度
Expert Kit 提出了一种**以 Expert 为核心单元**的异构融合推理架构，通过软件定义的方式实现集群资源的动态优化。

### 2.1 运行时协同调度与 Offloading
- **冷热感知**：利用模型运行过程中不同 Expert 激活频率的差异（冷热性），动态识别高频与低频专家模块。
- **CPU/XPU 协同**：打破单一加速卡的限制，在运行时实现 CPU 与 XPU（各类加速芯片）之间的计算任务协同与权重卸载（Offloading），确保核心算力聚焦于热点 Expert。

### 2.2 解耦优化策略
- **计算解耦**：实现了 **Attention（注意力机制）与 Expert（专家模块）的解耦**，允许针对不同类型的计算任务独立配置存储与计算资源。
- **异构存储管理**：优化了分布式环境下的异构存储布局，提升了跨节点、跨硬件的数据读取与交换效率。

## 3. 系统架构优势
- **软件定义算力**：从软件定义视角出发，实现了集群范围内的高效算力分配。
- **请求适配**：系统能够根据实时请求压力，自动适配并调度最合适的异构资源组合。

## 4. 项目背景与支持
该项目由**华为与北京航空航天大学联合实验室**支持开发，旨在解决超大规模 MoE 模型在异构集群上的落地难题。