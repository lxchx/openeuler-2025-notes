# 面向 LLM 推理的异构算力调度方案：GPU Combo 资源套餐

## 1. 背景与挑战
大语言模型（LLM）的推理过程由两个特征迥异的阶段组成，这对底层算力的分配提出了挑战：
- **Prefill（预填充）阶段**：计算密集型，对算力吞吐要求高。
- **Decode（解码）阶段**：访存密集型，执行模式与 Prefill 显著不同。

由于两个阶段对资源的需求存在非对称性，传统的统一资源分配方式往往导致计算效率低下或资源浪费。

## 2. 核心设计理念：GPU Combo
为了优化推理性能，我们提出了 **GPU Combo（资源套餐）** 概念。该方案的核心在于通过精细化资源配比实现异构算力的高效调度：

- **特定 PD 配比**：根据 Prefill (P) 和 Decode (D) 的负载特性，预定义最优的资源配比套餐。
- **异构硬件解耦**：支持在 **NPU** 和 **GPU** 等不同硬件平台上部署 PD 实例，充分利用异构算力的各自优势。
- **成本精确分析**：在云原生环境下，针对不同 PD 配比进行部署成本与性能收益的量化评估，实现性价比最优。

## 3. 动态调度与 QoS 保障机制
系统通过动态调度层实现对实时请求的灵活响应：

- **多级动态部署**：
  - **Combo 间调度**：根据全局负载在不同的资源套餐间分配请求。
  - **Combo 内调度**：在套餐内部动态调整 Prefill 和 Decode 实例的资源占用。
- **实时 QoS 满足**：调度算法以服务质量（QoS）为核心约束，确保在高并发环境下推理延迟仍符合预期。

## 4. 实验结论
初步实验数据表明，采用 GPU Combo 异构调度方案后，系统整体推理性能提升了 **25% - 38%**。该方案证明了通过精确的资源配比与异构算力协同，可以显著优化 LLM 推理的成本效率比。