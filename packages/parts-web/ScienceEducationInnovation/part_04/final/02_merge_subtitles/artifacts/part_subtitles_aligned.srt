1
00:00:00,000 --> 00:00:08,140
端到端的攻击检测技术为人工智能系统筑牢了安全防线，也为相关领域的研究提供了重要参考。

2
00:00:08,840 --> 00:00:19,820
接下来，我们将有请北京航空航天大学的杨任宇老师，带来《异构融合的 AI Infra 系统软件资源管理与可靠性保障》的分享。

3
00:00:20,300 --> 00:00:27,325
AI Infra 系统的资源管理与可靠性是开源生态建设的核心议题，让我们掌声欢迎杨老师。

4
00:00:34,280 --> 00:00:52,645
各位老师、同学，大家下午好。今天很荣幸代表团队分享在大规模 AI 基础设施环境下，从系统软件视角如何进行资源管理、稳定性及可靠性保障。

5
00:00:55,780 --> 00:01:17,680
首先，云计算已发展十余年，许多应用“生于云、长于云”。AI 智能服务与应用也不例外，其开发、执行、运维均在云平台或基础设施环境下进行。

6
00:01:18,040 --> 00:01:46,795
随着 AI 进入大模型时代，从单模态到多模态，模型功能日益强大。模型训练与推理对算力的需求呈爆炸式增长，尤其是近年来推理侧的算力需求持续攀升。

7
00:01:47,690 --> 00:02:28,760
在架构方面，主流框架无论是自然语言处理、多模态视觉，还是推荐系统，均已向 MoE（混合专家系统）架构演进。MoE 通过稀疏激活和 Top-K 选择，在保证大模型服务能力的同时，维持推理效率。

8
00:02:29,160 --> 00:03:18,965
除了大语言领域，大模型在互联网搜广推等场景下的数据处理也已成为实现商业价值闭环的关键。因此，无论是稀疏场景还是稠密场景，都对软件层算力管理与设计提出了更高要求。

9
00:03:19,660 --> 00:04:01,285
从硬件来看，AI 已进入超异构时代。为满足多样化智能需求，基础设施需从底层资源管理到上层编程 API、编译框架、工具链及软件栈，全面感知并利用异构算力。

10
00:04:03,100 --> 00:04:45,400
在此背景下，AI 基础设施建设如火如荼。截至 2025 年第一季度，全国已建成 165 个智算中心，千卡、万卡集群成为标配。然而，算力资源利用率普遍较低（仅 10%-15%），亟需从软件层面进行高效管理与调度。

11
00:04:45,860 --> 00:05:50,475
借鉴操作系统思路，我们希望构建“云 OS”，向下管理各类异构资源，向上为软件 App 与服务提供统一编程接口，屏蔽底层复杂性。在 AI 时代，基础设施层需支持离线批处理训练与在线大模型 Serving，以满足用户对性能与成本的多样化需求。

12
00:05:51,700 --> 00:06:20,200
目前，我们在框架层与运行时仍面临资源利用率低、服务质量保障难、失效概率高及可观测性差等挑战。

13
00:06:20,200 --> 00:06:50,015
当系统规模扩大，故障恢复慢、损失大等现象加剧。我们希望从容错（Fault Tolerance）视角，实现及时的故障检测、精准定位、全面诊断及快速失效恢复。

14
00:06:51,020 --> 00:07:32,055
整体思路是：对异构资源进行合理、一致的抽象，在运行时对算力（尤其是国产卡）进行高效适配与优化。同时，支持多租户、多模型环境下的高效训练与推理，并实现软硬件状态的良好观测与追踪。

15
00:07:33,090 --> 00:08:34,190
探索方向一：异构融合运行时调度与配置优化。我们观测到，不同模型在不同异构卡上执行时性能差异巨大。当多个作业在同一组算力上混部时，执行表现呈现非对称性。此外，在异构环境下部署 Serving 时，满足相同 QoS 的成本也各不相同。

16
00:08:34,330 --> 00:09:11,710
当 GPU/NPU 负载较高时，CPU 侧仍有大量空闲算力。如何实现 CPU 与 NPU 的互补，是异构融合的关键。我们围绕算力运行时调度与合理配置策略展开了研究。

17
00:09:13,280 --> 00:10:17,295
工作 1：异构感知的多作业封装与混部。在训练场景下，除了考虑异构性，还需关注互联网场景下的潮汐现象。所有作业需在截止时间（Deadline）内完成。我们将执行时间与异构性共同建模，通过作业组视角实现组内并行交错执行。

18
00:10:18,100 --> 00:10:59,915
我们利用图匹配算法解决多作业调度问题，相关系统已在快手千卡集群中进行实验。结果显示，作业完成率提升了 44.7%，JCT（作业周转时间）缩短了近两倍。

19
00:11:01,000 --> 00:12:23,920
工作 2：面向 LLM 推理的异构算力调度。推理包含 Prefill 和 Decode 阶段，算力需求与执行模式差异显著。我们提出以 GPU Combo（资源套餐）形式满足特定 PD 配比，并在云原生环境下精确分析不同配比的部署成本。

20
00:12:25,000 --> 00:13:07,985
当 PD 实例在 NPU 和 GPU 上部署后，系统可动态响应请求，在 Combo 间及 Combo 内进行动态部署，以满足实时 QoS 需求。初步实验表明，性能提升了 25%-38%。

21
00:13:09,490 --> 00:14:21,330
工作 3：Expert Kit——以 Expert 为中心的异构推理系统。针对 MoE 模型，在资源受限或算力需求极高时，我们利用 Expert 的冷热差异，在运行时实现 CPU 与 XPU 的协同调度与 Offloading。

22
00:14:21,570 --> 00:15:15,665
我们进一步实现了 Attention 与 Expert 的解耦，优化了分布式异构存储与计算。该项目得到了华为与北航联合实验室的支持，通过软件定义视角，实现了集群范围内高效的算力分配与请求适配。

23
00:15:17,720 --> 00:16:12,570
探索方向二：AI 基础设施稳定性与可靠性。大模型训练中失效频发，恢复成本极高。我们建立了从追踪、故障隔离到 Checkpoint 读写及运行时恢复的完整链路。在网络层，针对 NCCL 通信实现失效后的及时恢复，并动态剔除故障节点。

24
00:16:13,000 --> 00:16:57,805
我们定义了 AI 环境下的五大类、十余种失效类型。工作 1 重点研究分布式训练与推理中的 Straggler（掉队者）检测与根因分析。

25
00:16:58,900 --> 00:18:11,460
通过跨节点数据收集与聚合，利用统计手段定位 Straggler。我们还引入图学习与 RAG 技术进行根因分析，相关系统已集成至快手平台，将诊断耗时从半小时缩短至分钟级，效率提升数十倍。

26
00:18:11,860 --> 00:18:51,650
工作 2：面向大规模推荐模型训练的 Checkpoint 优化。针对 Embedding 层的冷热特征，实现自适应 Checkpoint 策略。通过 Pipeline 编排，使 Checkpoint 过程不影响正常的训练任务。

27
00:18:52,190 --> 00:19:16,655
工作 3：基于动态重建的快速失效恢复技术。在运行时通过 Device Proxy 和 Flexible CCL 实现通信链路的动态重构，降低失效恢复成本。

28
00:19:17,950 --> 00:19:36,655
相关研究得到了多个国家级项目及工业伙伴的支持，并在训练、推理及异常检测层面发表了多篇高水平论文。

29
00:19:38,030 --> 00:19:48,870
除了技术研发，我们还实现了 AI Infra 平台级解决方案——Crater。

30
00:19:49,290 --> 00:20:10,410
Crater 系统支持多租户异构集群监控与资源管理，集成了异构算力管理、多维资源数据管理，并支持从深度学习到 DeepSeek 分布式推理的多种场景。

31
00:20:11,000 --> 00:20:31,025
Crater 简化了异构算力的操作流程，助力多种场景快速落地。目前该系统已正式上线运行一年，累计执行任务超 2 万个。

32
00:20:34,320 --> 00:20:54,425
最后，感谢各位同事与同学。我们是来自北航分布式系统可靠与智能系统团队（RAIDS Lab）。谢谢聆听，请批评指正。

33
00:20:55,830 --> 00:21:15,445
好的，谢谢杨老师。请您留步，现场有没有朋友要提问？大家可以随时举手示意我们的工作人员。

34
00:21:16,270 --> 00:21:33,410
再次感谢杨老师的精彩呈现。从资源调度到可靠性保障，杨老师的研究为异构融合 AI Infra 系统的发展提供了有力支撑。
