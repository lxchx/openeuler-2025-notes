{
  "graph_data": {
    "nodes": [
      {
        "id": "p1",
        "label": "AI Infra 现状与挑战",
        "category": "Pillar",
        "references": {
          "section_ids": [
            "sec_001",
            "sec_002",
            "sec_003"
          ],
          "material_ids": [
            "chunk_00/slide_001",
            "chunk_00/slide_002",
            "chunk_00/slide_003",
            "chunk_00/slide_004",
            "chunk_00/slide_005",
            "chunk_00/slide_006",
            "chunk_00/slide_007",
            "chunk_00/slide_008",
            "chunk_00/slide_009",
            "chunk_00/slide_010",
            "chunk_00/slide_011"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_011",
            "primary_time_ts": "00:06:51,500",
            "primary_time_ms": 411500
          }
        },
        "parent": null,
        "summary": "在超异构计算时代，AI 基础设施面临算力需求爆炸、资源利用率低（10%-15%）以及系统稳定性差等核心挑战，亟需通过系统软件层面的“云 OS”理念进行资源抽象与管理。"
      },
      {
        "id": "p2",
        "label": "异构融合资源调度优化",
        "category": "Pillar",
        "references": {
          "section_ids": [
            "sec_004",
            "sec_005",
            "sec_006"
          ],
          "material_ids": [
            "chunk_00/slide_012",
            "chunk_00/slide_013",
            "chunk_00/slide_014",
            "chunk_00/slide_015",
            "chunk_00/slide_016",
            "chunk_00/slide_017",
            "chunk_00/slide_018",
            "chunk_00/slide_019"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_012",
            "primary_time_ts": "00:07:33,500",
            "primary_time_ms": 453500
          }
        },
        "parent": null,
        "summary": "针对异构算力的非对称性，通过多作业混部、GPU Combo 资源套餐以及以 Expert 为中心的调度，实现 CPU 与 NPU 的深度融合与互补。"
      },
      {
        "id": "p3",
        "label": "系统可靠性与稳定性保障",
        "category": "Pillar",
        "references": {
          "section_ids": [
            "sec_007",
            "sec_008",
            "sec_009"
          ],
          "material_ids": [
            "chunk_00/slide_020",
            "chunk_00/slide_021",
            "chunk_00/slide_022",
            "chunk_00/slide_023",
            "chunk_00/slide_024",
            "chunk_00/slide_025",
            "chunk_00/slide_026",
            "chunk_00/slide_027",
            "chunk_00/slide_028"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_020",
            "primary_time_ts": "00:15:17,500",
            "primary_time_ms": 917500
          }
        },
        "parent": null,
        "summary": "构建全链路稳定性保障体系，涵盖异常检测、根因分析、Checkpoint 优化及快速失效恢复，并最终落地为 Crater 智能调度系统。"
      },
      {
        "id": "d1_1",
        "label": "超异构计算挑战",
        "category": "Problem",
        "references": {
          "section_ids": [
            "sec_003"
          ],
          "material_ids": [
            "chunk_00/slide_006",
            "chunk_00/slide_007"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_006",
            "primary_time_ts": "00:03:19,500",
            "primary_time_ms": 199500
          }
        },
        "parent": "p1",
        "summary": "多样化异构算力并存，但平均利用率仅为 10%-15%，软硬件全栈感知能力缺失。"
      },
      {
        "id": "d1_2",
        "label": "云 OS 设计理念",
        "category": "Concept",
        "references": {
          "section_ids": [
            "sec_003"
          ],
          "material_ids": [
            "chunk_00/slide_008"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_008",
            "primary_time_ts": "00:04:46,500",
            "primary_time_ms": 286500
          }
        },
        "parent": "p1",
        "summary": "向下管理异构资源，向上提供统一编程接口，屏蔽底层复杂性。"
      },
      {
        "id": "d2_1",
        "label": "多作业封装与混部",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_004"
          ],
          "material_ids": [
            "chunk_00/slide_013",
            "chunk_00/slide_014"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_014",
            "primary_time_ts": "00:10:18,000",
            "primary_time_ms": 618000
          }
        },
        "parent": "p2",
        "summary": "利用图匹配算法解决多作业调度，在快手集群实现 JCT 缩短近 2 倍。"
      },
      {
        "id": "d2_2",
        "label": "GPU Combo 资源套餐",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_005"
          ],
          "material_ids": [
            "chunk_00/slide_015",
            "chunk_00/slide_016",
            "chunk_00/slide_017"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_016",
            "primary_time_ts": "00:12:26,500",
            "primary_time_ms": 746500
          }
        },
        "parent": "p2",
        "summary": "针对 LLM 推理的 Prefill 和 Decode 阶段进行 PD 分离与动态配比，提升性能 25%-38%。"
      },
      {
        "id": "d2_3",
        "label": "Expert Kit 异构推理",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_006"
          ],
          "material_ids": [
            "chunk_00/slide_018",
            "chunk_00/slide_019"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_018",
            "primary_time_ts": "00:13:09,500",
            "primary_time_ms": 789500
          }
        },
        "parent": "p2",
        "summary": "以 Expert 为中心，利用冷热差异实现 CPU 与 XPU 的协同调度与权重卸载。"
      },
      {
        "id": "d3_1",
        "label": "异常检测与根因分析",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_007"
          ],
          "material_ids": [
            "chunk_00/slide_021",
            "chunk_00/slide_022"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_022",
            "primary_time_ts": "00:17:39,500",
            "primary_time_ms": 1059500
          }
        },
        "parent": "p3",
        "summary": "基于图学习与 RAG 技术识别 Straggler（掉队者），将诊断耗时从 30 分钟缩短至分钟级。"
      },
      {
        "id": "d3_2",
        "label": "快速失效恢复 (Failover)",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_008"
          ],
          "material_ids": [
            "chunk_00/slide_023",
            "chunk_00/slide_024"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_024",
            "primary_time_ts": "00:18:52,000",
            "primary_time_ms": 1132000
          }
        },
        "parent": "p3",
        "summary": "通过 Device Proxy 和 Flexible CCL 实现通信链路动态重构，降低失效恢复成本。"
      },
      {
        "id": "d3_3",
        "label": "Crater 调度系统",
        "category": "Result",
        "references": {
          "section_ids": [
            "sec_009"
          ],
          "material_ids": [
            "chunk_00/slide_027",
            "chunk_00/slide_028"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_027",
            "primary_time_ts": "00:19:49,000",
            "primary_time_ms": 1189000
          }
        },
        "parent": "p3",
        "summary": "平台级解决方案，支持多租户异构集群监控，已上线运行一年，执行任务超 2 万个。"
      }
    ],
    "edges": [
      {
        "source": "p1",
        "target": "p2",
        "relation_type": "sequential",
        "label": "演进至资源优化"
      },
      {
        "source": "p2",
        "target": "p3",
        "relation_type": "sequential",
        "label": "演进至可靠性保障"
      },
      {
        "source": "d1_1",
        "target": "d1_2",
        "relation_type": "causal",
        "label": "驱动架构设计"
      },
      {
        "source": "d2_1",
        "target": "d2_2",
        "relation_type": "parallel",
        "label": "并列技术方案"
      },
      {
        "source": "d2_2",
        "target": "d2_3",
        "relation_type": "parallel",
        "label": "并列技术方案"
      },
      {
        "source": "d3_1",
        "target": "d3_2",
        "relation_type": "parallel",
        "label": "并列保障技术"
      },
      {
        "source": "d3_2",
        "target": "d3_3",
        "relation_type": "compositional",
        "label": "集成至平台"
      }
    ]
  },
  "sections": [
    {
      "id": "sec_001",
      "index": 0,
      "title": "开场致辞与背景介绍：异构融合的 AI Infra 系统软件资源管理与可靠性保障",
      "time_range": "00:00:08,840 - 00:00:52,645",
      "summary": "",
      "refined_script": "# 异构融合 AI Infra 系统软件：资源管理与可靠性保障\n\n## 1. 背景与核心价值\n在当前大规模 AI 基础设施（AI Infra）的演进过程中，系统软件的**资源管理**与**可靠性保障**已成为开源生态建设的核心议题。随着异构计算需求的爆发，如何确保底层系统在复杂环境下的高效运行与持续稳定，是提升 AI 生产力的关键。\n\n## 2. 核心研究方向\n本报告立足于系统软件视角，重点探讨在大规模 AI 基础设施环境下的两大核心任务：\n\n*   **资源管理（Resource Management）**：针对异构融合环境，研究如何实现计算资源的高效调度与优化配置。\n*   **稳定性与可靠性（Stability & Reliability）**：构建系统级的保障机制，确保大规模集群在处理高强度 AI 任务时的鲁棒性。\n\n## 3. 报告目标\n分享北京航空航天大学团队在 AI Infra 领域的最新研究成果与实践经验，解析如何通过系统软件层的技术创新，解决异构环境下的资源瓶颈与运行风险，助力开源生态的稳健发展。",
      "original_script": "接下来，我们将有请北京航空航天大学的杨任宇老师，带来《异构融合的 AI Infra 系统软件资源管理与可靠性保障》的分享。\nAI Infra 系统的资源管理与可靠性是开源生态建设的核心议题，让我们掌声欢迎杨老师。\n各位老师、同学，大家下午好。今天很荣幸代表团队分享在大规模 AI 基础设施环境下，从系统软件视角如何进行资源管理、稳定性及可靠性保障。",
      "start_ms": 8840,
      "end_ms": 52645,
      "material_ids": [
        "chunk_00/slide_001"
      ],
      "notes": "首句对应字幕2，尾句对应字幕4。",
      "lead_text": "接下来，我们将有请北京航空航天大学的杨任宇老师，带来《异构融合的 AI Infra 系统软件资源管理与可靠性保障》的分享。",
      "tail_text": "各位老师、同学，大家下午好。今天很荣幸代表团队分享在大规模 AI 基础设施环境下，从系统软件视角如何进行资源管理、稳定性及可靠性保障。",
      "text_span": {
        "start": 1,
        "end": 3
      }
    },
    {
      "id": "sec_002",
      "index": 1,
      "title": "大模型时代的挑战：云原生演进与新型模型架构需求",
      "time_range": "00:00:55,780 - 00:03:18,965",
      "summary": "",
      "refined_script": "# 大模型时代的挑战：云原生演进与新型模型架构需求\n\n## 1. 行业背景：AI 与云原生的深度融合\n云计算经过十余年的演进，已成为现代应用的核心基础设施。当前 AI 智能服务的开发、部署与运维呈现出明显的“云原生”特征：\n- **原生构建**：AI 应用从开发初期即基于云平台环境。\n- **全生命周期管理**：模型的执行与运维深度依赖云基础设施，实现资源的弹性调度与高效利用。\n\n## 2. 核心趋势：算力需求的爆发式增长\n随着 AI 技术从单模态向多模态大模型演进，模型能力增强的同时，对底层算力提出了严苛要求：\n- **算力爆炸**：训练与推理侧的算力需求呈指数级增长。\n- **重心转移**：近年来，推理侧的算力需求攀升尤为显著，成为基础设施压力的主要来源。\n\n## 3. 架构演进：MoE（混合专家系统）的兴起\n为了在提升模型容量的同时兼顾推理效率，主流技术框架（涵盖 NLP、多模态视觉及推荐系统）正全面向 MoE 架构转型。\n\n### 3.1 MoE 核心机制\n- **稀疏激活 (Sparse Activation)**：不同于稠密模型，MoE 仅激活部分神经元参与计算。\n- **Top-K 选择策略**：通过路由机制选择最相关的专家模块进行处理。\n\n### 3.2 架构优势\n- **服务能力提升**：支持更大规模的参数量。\n- **推理效率优化**：在保证模型表现的前提下，显著降低单次推理的计算开销。\n\n## 4. 业务场景与软件层设计挑战\n大模型的技术价值最终体现在商业闭环中，特别是在互联网核心业务场景：\n- **典型场景**：搜索、广告、推荐（搜广推）等领域的数据处理。\n- **设计要求**：无论是**稀疏场景**（如 MoE）还是**稠密场景**，都对软件层的算力管理、任务调度与架构设计提出了更高维度的挑战，需实现更精细化的资源掌控。",
      "original_script": "首先，云计算已发展十余年，许多应用“生于云、长于云”。AI 智能服务与应用也不例外，其开发、执行、运维均在云平台或基础设施环境下进行。\n随着 AI 进入大模型时代，从单模态到多模态，模型功能日益强大。模型训练与推理对算力的需求呈爆炸式增长，尤其是近年来推理侧的算力需求持续攀升。\n在架构方面，主流框架无论是自然语言处理、多模态视觉，还是推荐系统，均已向 MoE（混合专家系统）架构演进。MoE 通过稀疏激活和 Top-K 选择，在保证大模型服务能力的同时，维持推理效率。\n除了大语言领域，大模型在互联网搜广推等场景下的数据处理也已成为实现商业价值闭环的关键。因此，无论是稀疏场景还是稠密场景，都对软件层算力管理与设计提出了更高要求。",
      "start_ms": 55780,
      "end_ms": 198965,
      "material_ids": [
        "chunk_00/slide_002",
        "chunk_00/slide_003",
        "chunk_00/slide_004",
        "chunk_00/slide_005"
      ],
      "notes": "首句对应字幕5，尾句对应字幕8。",
      "lead_text": "首先，云计算已发展十余年，许多应用“生于云、长于云”。AI 智能服务与应用也不例外，其开发、执行、运维均在云平台或基础设施环境下进行。",
      "tail_text": "除了大语言领域，大模型在互联网搜广推等场景下的数据处理也已成为实现商业价值闭环的关键。因此，无论是稀疏场景还是稠密场景，都对软件层算力管理与设计提出了更高要求。",
      "text_span": {
        "start": 4,
        "end": 7
      }
    },
    {
      "id": "sec_003",
      "index": 2,
      "title": "AI 基础设施现状：超异构计算时代与系统软件整体思路",
      "time_range": "00:03:19,660 - 00:07:32,055",
      "summary": "",
      "refined_script": "# AI 基础设施现状：超异构计算时代与系统软件演进思路\n\n## 一、 行业背景与现状\n\n### 1.1 超异构计算时代的到来\n当前 AI 基础设施已进入**超异构时代**。为了满足日益多样化的智能计算需求，底层硬件不再局限于单一架构，而是呈现出多种异构算力并存的局面。这要求基础设施必须具备从底层资源管理到上层编程 API、编译框架、工具链及软件栈的全栈感知与利用能力。\n\n### 1.2 建设规模与资源利用率的矛盾\n*   **建设规模**：截至 2025 年第一季度，全国已建成 **165 个**智算中心，千卡、万卡级别的超大规模集群已成为行业标配。\n*   **核心痛点**：尽管硬件投入巨大，但算力资源的**平均利用率仅为 10%-15%**。这种极低的能效比凸显了软件层面管理与调度能力的缺失。\n\n## 二、 核心设计理念：构建“云 OS”\n\n借鉴传统操作系统的设计思路，AI 基础设施的建设应以构建**“云 OS”**为核心目标，实现对复杂环境的解耦与抽象：\n\n*   **向下管理（资源抽象）**：统一管理各类异构硬件资源，屏蔽底层硬件的差异性与复杂性。\n*   **向上支撑（统一接口）**：为上层应用和服务提供标准化的编程接口，降低开发与部署门槛。\n*   **全场景覆盖**：同时支持**离线批处理训练**与**在线大模型 Serving**，在性能与成本之间取得平衡。\n\n## 三、 当前面临的技术挑战\n\n在框架层与运行时（Runtime）层面，大规模集群仍面临以下严峻挑战：\n1.  **资源效能**：资源利用率持续低迷，难以实现高效的算力释放。\n2.  **服务质量 (QoS)**：在多租户、多模型环境下，难以保障稳定的服务质量。\n3.  **系统稳定性**：随着规模扩大，系统失效概率显著增加，且缺乏有效的可观测性手段。\n4.  **运维成本**：故障发生后，存在检测滞后、定位不准、诊断困难及恢复缓慢等问题，导致严重的算力损失。\n\n## 四、 演进路径与整体思路\n\n为解决上述问题，系统软件应遵循以下技术路线进行优化：\n\n### 4.1 异构资源的高效适配\n*   **一致性抽象**：对异构资源进行合理且一致的逻辑抽象。\n*   **国产化适配**：在运行时针对国产算力卡进行深度适配与性能优化。\n\n### 4.2 强化容错机制 (Fault Tolerance)\n构建全链路的容错体系，提升大规模集群的鲁棒性：\n*   **及时检测**：实现毫秒级的故障感知。\n*   **精准定位与诊断**：通过全栈可观测性数据，快速锁定故障根因。\n*   **快速恢复**：优化失效恢复流程，最大限度减少停机时间。\n\n### 4.3 运行环境优化\n*   **多租户隔离**：支持多租户、多模型并发环境下的高效训练与推理。\n*   **全栈可观测性**：实现软硬件状态的深度追踪与监控，为自动化调度提供数据支撑。",
      "original_script": "从硬件来看，AI 已进入超异构时代。为满足多样化智能需求，基础设施需从底层资源管理到上层编程 API、编译框架、工具链及软件栈，全面感知并利用异构算力。\n在此背景下，AI 基础设施建设如火如荼。截至 2025 年第一季度，全国已建成 165 个智算中心，千卡、万卡集群成为标配。然而，算力资源利用率普遍较低（仅 10%-15%），亟需从软件层面进行高效管理与调度。\n借鉴操作系统思路，我们希望构建“云 OS”，向下管理各类异构资源，向上为软件 App 与服务提供统一编程接口，屏蔽底层复杂性。在 AI 时代，基础设施层需支持离线批处理训练与在线大模型 Serving，以满足用户对性能与成本的多样化需求。\n目前，我们在框架层与运行时仍面临资源利用率低、服务质量保障难、失效概率高及可观测性差等挑战。\n当系统规模扩大，故障恢复慢、损失大等现象加剧。我们希望从容错（Fault Tolerance）视角，实现及时的故障检测、精准定位、全面诊断及快速失效恢复。\n整体思路是：对异构资源进行合理、一致的抽象，在运行时对算力（尤其是国产卡）进行高效适配与优化。同时，支持多租户、多模型环境下的高效训练与推理，并实现软硬件状态的良好观测与追踪。",
      "start_ms": 199660,
      "end_ms": 452055,
      "material_ids": [
        "chunk_00/slide_006",
        "chunk_00/slide_007",
        "chunk_00/slide_008",
        "chunk_00/slide_009",
        "chunk_00/slide_010",
        "chunk_00/slide_011"
      ],
      "notes": "首句对应字幕9，尾句对应字幕14。",
      "lead_text": "从硬件来看，AI 已进入超异构时代。为满足多样化智能需求，基础设施需从底层资源管理到上层编程 API、编译框架、工具链及软件栈，全面感知并利用异构算力。",
      "tail_text": "整体思路是：对异构资源进行合理、一致的抽象，在运行时对算力（尤其是国产卡）进行高效适配与优化。同时，支持多租户、多模型环境下的高效训练与推理，并实现软硬件状态的良好观测与追踪。",
      "text_span": {
        "start": 8,
        "end": 13
      }
    },
    {
      "id": "sec_004",
      "index": 3,
      "title": "探索方向 1：异构融合运行时调度与多作业混部优化",
      "time_range": "00:07:33,090 - 00:10:59,915",
      "summary": "",
      "refined_script": "# 探索方向 1：异构融合运行时调度与多作业混部优化\n\n## 1. 背景与核心痛点\n在异构计算环境下，算力资源的利用与作业调度面临以下三大挑战：\n- **性能非对称性**：不同模型在不同异构硬件（如 GPU、NPU）上的执行表现存在显著差异，导致多作业混部时性能难以预测。\n- **成本效益差异**：在满足相同服务质量（QoS）的前提下，不同异构芯片的部署成本各异，缺乏统一的优化度量。\n- **资源利用失衡**：当 GPU/NPU 处于高负载状态时，CPU 侧往往存在大量空闲算力，异构资源间的互补性未得到充分挖掘。\n\n## 2. 核心研究目标\n通过**算力运行时调度**与**合理配置策略**，实现 CPU 与 NPU 的深度融合与互补，提升大规模异构集群的整体吞吐与资源利用率。\n\n## 3. 关键技术方案：异构感知的多作业封装与混部\n针对训练场景，提出了一种结合时间维度（潮汐现象）与空间维度（异构性）的联合调度模型。\n\n### 3.1 建模与策略\n- **多维建模**：将作业的执行时间（Execution Time）与硬件异构性共同纳入建模范畴。\n- **作业组视角（Job Grouping）**：打破单一作业调度的局限，从作业组维度进行资源分配，实现组内作业的并行交错执行。\n- **约束管理**：引入截止时间（Deadline）约束，确保所有作业在互联网业务场景的潮汐波动下仍能按时完成。\n\n### 3.2 算法实现\n- **图匹配算法**：利用图匹配算法解决复杂的多作业调度优化问题，寻找作业与异构算力节点之间的最优映射关系。\n\n## 4. 落地实践与效果评估\n该系统已在快手千卡级集群中完成实验验证，具体性能提升如下：\n\n| 指标 | 优化效果 |\n| :--- | :--- |\n| **作业完成率** | 提升 **44.7%** |\n| **JCT (作业周转时间)** | 缩短近 **2 倍** |\n| **资源协同** | 有效实现了 CPU 与 NPU 的算力互补 |",
      "original_script": "探索方向一：异构融合运行时调度与配置优化。我们观测到，不同模型在不同异构卡上执行时性能差异巨大。当多个作业在同一组算力上混部时，执行表现呈现非对称性。此外，在异构环境下部署 Serving 时，满足相同 QoS 的成本也各不相同。\n当 GPU/NPU 负载较高时，CPU 侧仍有大量空闲算力。如何实现 CPU 与 NPU 的互补，是异构融合的关键。我们围绕算力运行时调度与合理配置策略展开了研究。\n工作 1：异构感知的多作业封装与混部。在训练场景下，除了考虑异构性，还需关注互联网场景下的潮汐现象。所有作业需在截止时间（Deadline）内完成。我们将执行时间与异构性共同建模，通过作业组视角实现组内并行交错执行。\n我们利用图匹配算法解决多作业调度问题，相关系统已在快手千卡集群中进行实验。结果显示，作业完成率提升了 44.7%，JCT（作业周转时间）缩短了近两倍。",
      "start_ms": 453090,
      "end_ms": 659915,
      "material_ids": [
        "chunk_00/slide_012",
        "chunk_00/slide_013",
        "chunk_00/slide_014"
      ],
      "notes": "首句对应字幕15，尾句对应字幕18。",
      "lead_text": "探索方向一：异构融合运行时调度与配置优化。我们观测到，不同模型在不同异构卡上执行时性能差异巨大。当多个作业在同一组算力上混部时，执行表现呈现非对称性。此外，在异构环境下部署 Serving 时，满足相同 QoS 的成本也各不相同。",
      "tail_text": "我们利用图匹配算法解决多作业调度问题，相关系统已在快手千卡集群中进行实验。结果显示，作业完成率提升了 44.7%，JCT（作业周转时间）缩短了近两倍。",
      "text_span": {
        "start": 14,
        "end": 17
      }
    },
    {
      "id": "sec_005",
      "index": 4,
      "title": "面向 LLM 推理的异构算力调度：GPU Combo 资源套餐",
      "time_range": "00:11:01,000 - 00:13:07,985",
      "summary": "",
      "refined_script": "# 面向 LLM 推理的异构算力调度方案：GPU Combo 资源套餐\n\n## 1. 背景与挑战\n大语言模型（LLM）的推理过程由两个特征迥异的阶段组成，这对底层算力的分配提出了挑战：\n- **Prefill（预填充）阶段**：计算密集型，对算力吞吐要求高。\n- **Decode（解码）阶段**：访存密集型，执行模式与 Prefill 显著不同。\n\n由于两个阶段对资源的需求存在非对称性，传统的统一资源分配方式往往导致计算效率低下或资源浪费。\n\n## 2. 核心设计理念：GPU Combo\n为了优化推理性能，我们提出了 **GPU Combo（资源套餐）** 概念。该方案的核心在于通过精细化资源配比实现异构算力的高效调度：\n\n- **特定 PD 配比**：根据 Prefill (P) 和 Decode (D) 的负载特性，预定义最优的资源配比套餐。\n- **异构硬件解耦**：支持在 **NPU** 和 **GPU** 等不同硬件平台上部署 PD 实例，充分利用异构算力的各自优势。\n- **成本精确分析**：在云原生环境下，针对不同 PD 配比进行部署成本与性能收益的量化评估，实现性价比最优。\n\n## 3. 动态调度与 QoS 保障机制\n系统通过动态调度层实现对实时请求的灵活响应：\n\n- **多级动态部署**：\n  - **Combo 间调度**：根据全局负载在不同的资源套餐间分配请求。\n  - **Combo 内调度**：在套餐内部动态调整 Prefill 和 Decode 实例的资源占用。\n- **实时 QoS 满足**：调度算法以服务质量（QoS）为核心约束，确保在高并发环境下推理延迟仍符合预期。\n\n## 4. 实验结论\n初步实验数据表明，采用 GPU Combo 异构调度方案后，系统整体推理性能提升了 **25% - 38%**。该方案证明了通过精确的资源配比与异构算力协同，可以显著优化 LLM 推理的成本效率比。",
      "original_script": "工作 2：面向 LLM 推理的异构算力调度。推理包含 Prefill 和 Decode 阶段，算力需求与执行模式差异显著。我们提出以 GPU Combo（资源套餐）形式满足特定 PD 配比，并在云原生环境下精确分析不同配比的部署成本。\n当 PD 实例在 NPU 和 GPU 上部署后，系统可动态响应请求，在 Combo 间及 Combo 内进行动态部署，以满足实时 QoS 需求。初步实验表明，性能提升了 25%-38%。",
      "start_ms": 661000,
      "end_ms": 787985,
      "material_ids": [
        "chunk_00/slide_015",
        "chunk_00/slide_016",
        "chunk_00/slide_017"
      ],
      "notes": "首句对应字幕19，尾句对应字幕20。",
      "lead_text": "工作 2：面向 LLM 推理的异构算力调度。推理包含 Prefill 和 Decode 阶段，算力需求与执行模式差异显著。我们提出以 GPU Combo（资源套餐）形式满足特定 PD 配比，并在云原生环境下精确分析不同配比的部署成本。",
      "tail_text": "当 PD 实例在 NPU 和 GPU 上部署后，系统可动态响应请求，在 Combo 间及 Combo 内进行动态部署，以满足实时 QoS 需求。初步实验表明，性能提升了 25%-38%。",
      "text_span": {
        "start": 18,
        "end": 19
      }
    },
    {
      "id": "sec_006",
      "index": 5,
      "title": "Expert Kit：以 Expert 为中心的异构融合推理系统",
      "time_range": "00:13:09,490 - 00:15:15,665",
      "summary": "",
      "refined_script": "# Expert Kit：以 Expert 为中心的异构融合推理系统\n\n## 1. 背景与核心挑战\n在大规模混合专家模型（MoE）的推理场景中，系统常面临资源受限或极端算力需求的挑战。由于 MoE 模型参数量巨大，传统的单一硬件部署难以平衡成本与性能。\n\n## 2. 核心设计理念：以 Expert 为中心的异构调度\nExpert Kit 提出了一种**以 Expert 为核心单元**的异构融合推理架构，通过软件定义的方式实现集群资源的动态优化。\n\n### 2.1 运行时协同调度与 Offloading\n- **冷热感知**：利用模型运行过程中不同 Expert 激活频率的差异（冷热性），动态识别高频与低频专家模块。\n- **CPU/XPU 协同**：打破单一加速卡的限制，在运行时实现 CPU 与 XPU（各类加速芯片）之间的计算任务协同与权重卸载（Offloading），确保核心算力聚焦于热点 Expert。\n\n### 2.2 解耦优化策略\n- **计算解耦**：实现了 **Attention（注意力机制）与 Expert（专家模块）的解耦**，允许针对不同类型的计算任务独立配置存储与计算资源。\n- **异构存储管理**：优化了分布式环境下的异构存储布局，提升了跨节点、跨硬件的数据读取与交换效率。\n\n## 3. 系统架构优势\n- **软件定义算力**：从软件定义视角出发，实现了集群范围内的高效算力分配。\n- **请求适配**：系统能够根据实时请求压力，自动适配并调度最合适的异构资源组合。\n\n## 4. 项目背景与支持\n该项目由**华为与北京航空航天大学联合实验室**支持开发，旨在解决超大规模 MoE 模型在异构集群上的落地难题。",
      "original_script": "工作 3：Expert Kit——以 Expert 为中心的异构推理系统。针对 MoE 模型，在资源受限或算力需求极高时，我们利用 Expert 的冷热差异，在运行时实现 CPU 与 XPU 的协同调度与 Offloading。\n我们进一步实现了 Attention 与 Expert 的解耦，优化了分布式异构存储与计算。该项目得到了华为与北航联合实验室的支持，通过软件定义视角，实现了集群范围内高效的算力分配与请求适配。",
      "start_ms": 789490,
      "end_ms": 915665,
      "material_ids": [
        "chunk_00/slide_018",
        "chunk_00/slide_019"
      ],
      "notes": "首句对应字幕21，尾句对应字幕22。",
      "lead_text": "工作 3：Expert Kit——以 Expert 为中心的异构推理系统。针对 MoE 模型，在资源受限或算力需求极高时，我们利用 Expert 的冷热差异，在运行时实现 CPU 与 XPU 的协同调度与 Offloading。",
      "tail_text": "我们进一步实现了 Attention 与 Expert 的解耦，优化了分布式异构存储与计算。该项目得到了华为与北航联合实验室的支持，通过软件定义视角，实现了集群范围内高效的算力分配与请求适配。",
      "text_span": {
        "start": 20,
        "end": 21
      }
    },
    {
      "id": "sec_007",
      "index": 6,
      "title": "探索方向 2：AI 基础设施稳定性、异常检测与根因分析",
      "time_range": "00:15:17,720 - 00:18:11,460",
      "summary": "",
      "refined_script": "# 探索方向 2：AI 基础设施稳定性、异常检测与根因分析\n\n## 1. 背景与挑战\n在大规模 AI 模型训练过程中，系统失效（Failure）具有**高频发性**与**极高恢复成本**的特点。如何降低故障对算力资源的损耗，实现快速检测与自动化恢复，是提升 AI 基础设施效能的关键。\n\n## 2. 稳定性保障全链路架构\n针对 AI 训练任务，构建了从底层监控到运行时恢复的闭环链路：\n\n- **全链路追踪与隔离**：实时监控系统状态，实现故障节点的快速定位与物理隔离。\n- **高效 Checkpoint 机制**：优化读写性能，缩短状态保存与加载的耗时。\n- **网络层容错（NCCL 优化）**：针对分布式通信库 NCCL 进行深度定制，实现通信失效后的及时恢复，并支持动态剔除故障节点以维持训练连续性。\n\n## 3. 核心技术：Straggler（掉队者）检测与根因分析\n\n### 3.1 失效类型定义\n系统定义了 AI 环境下特有的 **5 大类、10 余种**失效类型，为精准治理提供标准分类。\n\n### 3.2 掉队者检测方案\n针对分布式训练与推理中常见的 Straggler 问题，采用以下技术路径：\n- **数据采集**：跨节点收集多维度的运行指标。\n- **聚合分析**：通过数据聚合与统计学手段，识别执行进度显著滞后的节点。\n\n### 3.3 智能化根因分析 (RCA)\n引入前沿 AI 技术提升诊断深度：\n- **图学习 (Graph Learning)**：建模节点间的依赖关系，追踪异常传播路径。\n- **RAG (检索增强生成)**：结合历史故障知识库，辅助生成根因解释与修复建议。\n\n## 4. 落地效果与价值\n相关技术方案已正式集成至**快手 AI 平台**，取得了显著的效率提升：\n\n| 指标 | 优化前 | 优化后 | 提升幅度 |\n| :--- | :--- | :--- | :--- |\n| **诊断耗时** | ~30 分钟 | 分钟级 | 数十倍效率提升 |\n| **系统稳定性** | 故障恢复慢，人工干预多 | 自动化隔离与恢复 | 显著降低恢复成本 |",
      "original_script": "探索方向二：AI 基础设施稳定性与可靠性。大模型训练中失效频发，恢复成本极高。我们建立了从追踪、故障隔离到 Checkpoint 读写及运行时恢复的完整链路。在网络层，针对 NCCL 通信实现失效后的及时恢复，并动态剔除故障节点。\n我们定义了 AI 环境下的五大类、十余种失效类型。工作 1 重点研究分布式训练与推理中的 Straggler（掉队者）检测与根因分析。\n通过跨节点数据收集与聚合，利用统计手段定位 Straggler。我们还引入图学习与 RAG 技术进行根因分析，相关系统已集成至快手平台，将诊断耗时从半小时缩短至分钟级，效率提升数十倍。",
      "start_ms": 917720,
      "end_ms": 1091460,
      "material_ids": [
        "chunk_00/slide_020",
        "chunk_00/slide_021",
        "chunk_00/slide_022"
      ],
      "notes": "首句对应字幕23，尾句对应字幕25。",
      "lead_text": "探索方向二：AI 基础设施稳定性与可靠性。大模型训练中失效频发，恢复成本极高。我们建立了从追踪、故障隔离到 Checkpoint 读写及运行时恢复的完整链路。在网络层，针对 NCCL 通信实现失效后的及时恢复，并动态剔除故障节点。",
      "tail_text": "通过跨节点数据收集与聚合，利用统计手段定位 Straggler。我们还引入图学习与 RAG 技术进行根因分析，相关系统已集成至快手平台，将诊断耗时从半小时缩短至分钟级，效率提升数十倍。",
      "text_span": {
        "start": 22,
        "end": 24
      }
    },
    {
      "id": "sec_008",
      "index": 7,
      "title": "可靠性保障技术：Checkpoint 优化与快速失效恢复",
      "time_range": "00:18:11,860 - 00:19:16,655",
      "summary": "",
      "refined_script": "# 可靠性保障技术：Checkpoint 优化与快速失效恢复\n\n在大规模推荐模型训练场景下，系统的可靠性与训练效率往往存在冲突。本文重点介绍通过自适应 Checkpoint 策略与动态链路重构技术，在保障模型安全性的同时，最小化运维开销并提升恢复速度。\n\n## 1. 面向大规模推荐模型的 Checkpoint 优化\n\n针对推荐模型 Embedding 层参数量巨大且访问分布不均的特点，通过以下技术手段解决传统 Checkpoint 导致的训练中断问题：\n\n*   **自适应 Checkpoint 策略**：\n    *   **冷热特征分离**：识别 Embedding 层中的冷热特征数据。\n    *   **差异化持久化**：根据特征访问频率动态调整存储频率与优先级，减少冗余 IO。\n*   **非侵入式 Pipeline 编排**：\n    *   通过流水线（Pipeline）化处理 Checkpoint 流程。\n    *   实现计算任务与 IO 任务的并行，确保 Checkpoint 过程对正常训练任务“零干扰”。\n\n## 2. 基于动态重建的快速失效恢复（Failover）\n\n当集群发生硬件故障或通信中断时，通过底层通信链路的动态重构，实现低成本的快速恢复：\n\n*   **核心组件**：\n    *   **Device Proxy**：引入设备代理机制，解耦物理设备与逻辑训练单元。\n    *   **Flexible CCL (Flexible Collective Communication Library)**：构建灵活的集合通信库，支持运行时的拓扑调整。\n*   **技术实现**：\n    *   **动态链路重构**：在不停止整个集群的情况下，通过代理机制重新映射通信路径。\n    *   **效果**：显著降低了失效恢复（Failover）的时间成本，避免了传统模式下的大规模重启。",
      "original_script": "工作 2：面向大规模推荐模型训练的 Checkpoint 优化。针对 Embedding 层的冷热特征，实现自适应 Checkpoint 策略。通过 Pipeline 编排，使 Checkpoint 过程不影响正常的训练任务。\n工作 3：基于动态重建的快速失效恢复技术。在运行时通过 Device Proxy 和 Flexible CCL 实现通信链路的动态重构，降低失效恢复成本。",
      "start_ms": 1091860,
      "end_ms": 1156655,
      "material_ids": [
        "chunk_00/slide_023",
        "chunk_00/slide_024"
      ],
      "notes": "首句对应字幕26，尾句对应字幕27。",
      "lead_text": "工作 2：面向大规模推荐模型训练的 Checkpoint 优化。针对 Embedding 层的冷热特征，实现自适应 Checkpoint 策略。通过 Pipeline 编排，使 Checkpoint 过程不影响正常的训练任务。",
      "tail_text": "工作 3：基于动态重建的快速失效恢复技术。在运行时通过 Device Proxy 和 Flexible CCL 实现通信链路的动态重构，降低失效恢复成本。",
      "text_span": {
        "start": 25,
        "end": 26
      }
    },
    {
      "id": "sec_009",
      "index": 8,
      "title": "平台化落地：Crater 多租户异构集群智能调度系统",
      "time_range": "00:19:17,950 - 00:20:31,025",
      "summary": "",
      "refined_script": "# Crater：多租户异构集群智能调度系统\n\n## 1. 系统概述\n**Crater** 是一款面向 AI Infra 的平台级解决方案，旨在解决多租户环境下异构算力资源的监控、管理与高效调度问题。该系统通过简化异构算力的操作流程，为从基础深度学习到大规模分布式推理的多种业务场景提供底层支撑。\n\n## 2. 核心能力与技术架构\nCrater 集成了多维度的资源管理能力，确保在复杂硬件环境下的高效运行：\n\n- **异构算力管理**：统一调度不同架构的计算资源，屏蔽底层硬件差异。\n- **多租户资源隔离**：支持多租户环境下的资源配额管理与监控，确保任务间的安全与独立。\n- **多维数据管理**：实时监控集群状态，提供精细化的资源使用数据分析。\n- **全场景支持**：覆盖从常规深度学习模型训练到 **DeepSeek 分布式推理**等高负载、高复杂度的应用场景。\n\n## 3. 学术与工业背景\n系统的研发基于深厚的学术积累与工业实践：\n- **科研支撑**：获得多个国家级项目及工业合作伙伴的支持。\n- **学术产出**：在模型训练、推理优化及异常检测等领域发表了多篇高水平学术论文，为系统算法提供了理论保障。\n\n## 4. 落地成果与运行现状\n目前，Crater 系统已进入成熟运行阶段，其稳定性与效能已得到实际验证：\n- **运行周期**：系统已正式上线运行超过 **1 年**。\n- **任务规模**：累计处理并执行任务数已突破 **20,000 个**。\n- **核心价值**：显著简化了异构资源的操作复杂度，加速了 AI 业务场景的落地进程。",
      "original_script": "相关研究得到了多个国家级项目及工业伙伴的支持，并在训练、推理及异常检测层面发表了多篇高水平论文。\n除了技术研发，我们还实现了 AI Infra 平台级解决方案——Crater。\nCrater 系统支持多租户异构集群监控与资源管理，集成了异构算力管理、多维资源数据管理，并支持从深度学习到 DeepSeek 分布式推理的多种场景。\nCrater 简化了异构算力的操作流程，助力多种场景快速落地。目前该系统已正式上线运行一年，累计执行任务超 2 万个。",
      "start_ms": 1157950,
      "end_ms": 1231025,
      "material_ids": [
        "chunk_00/slide_025",
        "chunk_00/slide_026",
        "chunk_00/slide_027",
        "chunk_00/slide_028"
      ],
      "notes": "首句对应字幕28，尾句对应字幕31。",
      "lead_text": "相关研究得到了多个国家级项目及工业伙伴的支持，并在训练、推理及异常检测层面发表了多篇高水平论文。",
      "tail_text": "Crater 简化了异构算力的操作流程，助力多种场景快速落地。目前该系统已正式上线运行一年，累计执行任务超 2 万个。",
      "text_span": {
        "start": 27,
        "end": 30
      }
    },
    {
      "id": "sec_010",
      "index": 9,
      "title": "总结与致谢",
      "time_range": "00:20:34,320 - 00:21:33,409",
      "summary": "",
      "refined_script": "# 总结与致谢\n\n## 1. 核心研究方向总结\n本次分享重点探讨了**异构融合 AI Infra 系统**的关键技术挑战与解决方案，主要涵盖以下两个核心维度：\n\n*   **资源调度优化**：针对异构计算资源的高效分配与管理机制。\n*   **可靠性保障**：在复杂系统环境下，确保 AI 基础设施稳定运行的支撑技术。\n\n## 2. 团队背景\n本研究由**北京航空航天大学分布式系统可靠与智能系统实验室（RAIDS Lab）**完成。团队致力于通过系统化的方法论，为现代 AI 基础设施的发展提供理论支撑与实践指导。\n\n## 3. 互动与反馈\n*   **致谢**：感谢所有参与研究的同事与同学，以及现场观众的聆听。\n*   **交流**：欢迎针对报告内容提出批评与指正。现场观众可通过举手示意工作人员进行提问交流。",
      "original_script": "最后，感谢各位同事与同学。我们是来自北航分布式系统可靠与智能系统团队（RAIDS Lab）。谢谢聆听，请批评指正。\n好的，谢谢杨老师。请您留步，现场有没有朋友要提问？大家可以随时举手示意我们的工作人员。\n再次感谢杨老师的精彩呈现。从资源调度到可靠性保障，杨老师的研究为异构融合 AI Infra 系统的发展提供了有力支撑。",
      "start_ms": 1234320,
      "end_ms": 1293409,
      "material_ids": [
        "chunk_00/slide_029",
        "chunk_00/slide_030"
      ],
      "notes": "首句对应字幕32，尾句对应字幕34。",
      "lead_text": "最后，感谢各位同事与同学。我们是来自北航分布式系统可靠与智能系统团队（RAIDS Lab）。谢谢聆听，请批评指正。",
      "tail_text": "再次感谢杨老师的精彩呈现。从资源调度到可靠性保障，杨老师的研究为异构融合 AI Infra 系统的发展提供了有力支撑。",
      "text_span": {
        "start": 31,
        "end": 33
      }
    }
  ]
}