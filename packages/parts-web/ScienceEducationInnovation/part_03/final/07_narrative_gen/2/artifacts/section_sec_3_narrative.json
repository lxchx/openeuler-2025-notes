{
  "id": "sec_3",
  "index": 2,
  "title": "科学问题与关键挑战",
  "time_range": "00:03:04,755 - 00:07:01,680",
  "script": "20年前可能是一些比较业余的选手，大家很分散，做一些很有趣的攻击。\n我们完全把对人工的依赖、对规则的依赖给它排除掉，来实现一个这种端到端，现在很火的端到端、AI端到端。\n我AI把这个原始的系统运行日志把它吃进去，那么我AI经过一系列算法的分析，我自动生成这边这种人可读的攻击报告。\n自动地把那个很复杂的APT攻击的那些场景，给它用自然语言给它描述出来。\n大家会想在大语言模型现在那么厉害的今天，这个是不是可以做到？是不是还是比较容易？我直接把我的日志喂给大模型，它是不是能做呢？\n实际上很遗憾，这个做的效果没有那么好。\n为什么？其实这里边有三个问题。第一个是我数据质量差。\n对于AI模型来说，其实我所有的能力都来自我的数据。\n但是很遗憾，在这个攻击这个数据里边，它的数据质量因为各种原因，\n它是很难的。第一个是训练数据量不够。\n我们这个整个安全的数数据，实际上很多是企业的内部的运维数据。\n这种数据它是有一定隐私性的，它这个企业是不会、不太可能公开给你做训练。\n而学术界呢，我们大量的数据，像大家看我们这顶会的数据，它都是模拟数据。那么这种模拟数据给这个模型带来的能力提升就很有线。\n第二个呢是我们这个没有标注。\n就是说，对安全的数据进行标注，实际上是成本非常非常地高，它不像比如说那个CV、那个计算机图形学或者自然语言，它可以找一些很普通的人，就是一般的人做标注。\n我们这个标注呢，实际上是需要很多的专业人士，需要很多的博士生来做标注。那么它的效率很低，而且现在我们看到标注的质量也不是很好。\n即使很专业的博士生来分析那些日志，他分析也不会很好，他很可能只能是一些简单的动作，而不能精确地匹配到某个数据上。\n第三个呢，我们发现这个数据它的分布是非常不均匀的。\n就是说，在现实社会里边我们找到的数据，攻击数据远远远远地比正常数据要少。\n可能这个数据是1比1000万的这种稀疏度。\n那么这种极端不平均的数据，就给我们整个机器学习模型带来很大的困难。\n那么第二个挑战是什么？我们语义理解有问题。\n就是说，我们希望让大模型能够理解在底层日志发生的这些攻击，并且用人的语言把它解释出来。\n但这里边就有一个语义鸿沟。\n就是我底层的这些日志，可能是一些操作系统日志、网络的日志，比如说我访问了哪个文件、访问了什么哈希。\n这个文件的语义和我人自然语言能理解的语义是，中间是有个鸿沟的。那这个语义怎么弥合？现在没有办法。\n第二个呢，这个理解存在二义性。\n就是同样的一个行为，它可能是正常的，可能是不正常的。\n它这个正常不正常、攻击不攻击，取决于它的上下文。比如说我同样访问一个文件，正常人平常打开，它就是一个正常访问。那如果是一个病毒引起的这样一个访问，它就是恶意的。\n所以我这个访问我要看上下文。\n第三个呢，还有一个就是我这个数据维度非常高。\n就是我要消化的日志，实际上是，如果现在我们流行大模型的窗口，现在大概1 million token，已经很了不起了。但是对于安全日志来说，100万、1 million token实际上是一个很小的窗口。\n你大概也就不能捕捉大概半天的数据。\n而我们这个攻击往往会持续几个月，你根本就没有办法捕捉。\n第三个还有一个成本限制很大。就是很遗憾，我们安全这个产业，特别在国内，是一个受到成本限制很大的这么一个行业。\n大家并不并不愿意像大模型一样投那么多钱进去。你不会有很多的显卡让你去做这个分析。\n但是我们对我们算法的要求很高，一个是我们的检测要很及时。\n我们发现了攻击，我们很快得检测出来。\n而我们整个输入进的数据量，因为我们要做端到端的这个检测，我们这个数据量也很大。\n所以我们供应数据规模也很大，我们要很及时地检测，我们还成本受限，这个挑战就很大。",
  "summary": "讲者提出了利用AI实现端到端网络攻击检测的科学问题，即让AI自动分析原始日志并生成人类可读的攻击报告。然而，直接使用大语言模型效果不佳，主要面临三大挑战。首先是数据质量差，体现在训练数据量少、标注成本高且质量低、以及攻击与正常数据分布极端不均。其次是语义理解困难，存在底层日志与自然语言的语义鸿沟、行为判断的二义性以及数据维度过高的问题。最后是成本限制，安全行业投入有限，难以支撑大规模、高时效性的计算需求。"
}