{
  "id": "sec_6",
  "index": 5,
  "title": "关键技术二：基于大语言模型的攻击检测和日志理解",
  "time_range": "00:11:31,615 - 00:14:50,448",
  "script": "20年前可能是一些比较业余的选手，大家很分散，做一些很有趣的攻击。\n好，那么第二个呢，就是我们要做下一步要做理解。我们刚才把攻击检测出来。\n但是我们拿到的那个攻击呢，是一个很很底层的这样一个，一种一个图，这样一个很大一个图。这个图呢，人看起来不好看，人理解不了，还是要很专业的人才能理解。\n那我们下一步工作，我们怎么把这种很专业的理解呢，进一步把它检测，进一步细化，然后把它变成一个自然语言，我们看到的人能理解的报告。\n但是这里边就有一个问题，就是我这里边是有鸿沟的。你看，我比如说我们人能理解的报告，比如说对一个攻击的描述，上面这个点，大概是这种，是这些这种自然语言。但底层的日志呢，是这种具体的对文件的访问和端口的访问。\n那么我怎么样弥补这个鸿沟，把这种这种事件给它映射到这种文字上呢？\n那么现有的方法实际上是做不到的。现有方法大家做的就是这种硬匹配，就是我这发现一个文件名，我就在这个文本里边去找，然后把它硬匹配过去。\n这样肯定是不行的。\n那么，他们没有泛化能力。我们就看，到底要怎么样有泛化能力呢？我们怎么样让这个这种匹配呢，就拥有泛化能力，让大模型能够学到它的知识。\n而且是有泛化能力的知识。那我们就提了一种gIoC的中间表述。\n当然这个我们理论上讲，我们可以如果有足够多的数据，我们把它放进去以后，大模型是可以理解的，但是很遗憾，我们没有足够多的数据。\n而且呢成本也很高。所以呢，我们就做了这样一个中间表述，就是我们这个中间表述呢，它形式上更接近这个底层的事件。\n但是里边的参数我们进行了泛化。这样呢，我们就可以利用一些\n大模型，不那么大的模型的一些理解能力，把我们这种底层的事件和上层的这种威胁情报里面的知识进行匹配。\n这样呢，我大模型就拥有了这种对底层日志的理解能力。\n所以我大模型就可以输出这样的，输出这种具有泛化能力的文本。那么基于我们这个输出呢，我们还进行了这种优化，就是我们这个之前自动标注可能会有很多的误报，\n可能有很多错误。\n那么呢，我们又利用这种攻击技术或者攻击之间的逻辑关系，每一个步骤的逻辑关系，比如说我要攻击你一个系统，我肯定要先\n获得你的登录权限，然后才能安装病毒。\n那么如果倒过来，它就逻辑上不成立的。那么依赖这种前后的逻辑能力呢，我们又做了一套这种\n攻击的这种推理系统。那么根据推理，我们把大量的误报消除掉。\n所以呢，最后呢，我们把这种最后推理出来的结果，跟这个这个图跟上一个图比，就是我们这个图每个节点上其实已经标注了，这个攻击它对应的攻击技术是什么，它采用了什么技术，用了什么手法，是谁来打的。\n然后呢，我们把它放到一个安全Agent里边去，然后就自动生成这个攻击报告。\n所以我们整个流程可以看到，我们虽然用了大模型，但并不是一个端到端的大模型，而是先通过一些我们一些算法、一些小模型的算法对它进行过滤和处理，然后把这个最后的结果，它可能就我们在几千万个事件里边，在这种挑出来那么几十个精选的这种跟攻击有关的事件，\n再放到大模型，由大模型处理呢，就自动生成了这样的语言的报告。\n那么我们在这个，我们华为的内部数据里边，openEuler的运维数据里边进行了处理。\n我们发现实际上，我们整个误报，不仅我们不仅能够第一个生成这样自然语言处理的报告，自动生成这样的报告，而且我们整个误报率比现有的方法下降一个数量级。",
  "summary": "为了弥合底层日志与自然语言报告之间的鸿沟，我们提出了一种名为 gIoC 的中间表述，它能让大语言模型理解底层事件并具备泛化能力。通过结合攻击步骤的逻辑推理系统来消除误报，最终由安全 Agent 自动生成可读的攻击报告，该方法在华为内部数据测试中显著降低了误报率。"
}