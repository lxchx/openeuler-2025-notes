### 关键技术一：无监督快速日志过滤

#### 1. 背景与挑战

在海量日志数据中，攻击相关事件的分布极为稀疏。例如，在包含数千万事件的图中，与攻击相关的事件可能不足200个。在这种极端不均衡的数据分布下，如何准确、高效地识别出这些少数的攻击事件，是核心挑战。

#### 2. 核心思路：两阶段过滤

为应对海量数据的算力开销，我们提出了一种两阶段过滤策略：

1.  **快速过滤**：首先，利用无监督学习方法，快速过滤掉大量明显与攻击无关的正常事件。
2.  **深度分析**：然后，将剩余的、难以判断的可疑事件交由一个更强的模型进行深度分析。

通过这种方式，可以显著节省整个分析流程的计算资源。

#### 3. 关键规律与算法设计

我们的方法基于对攻击行为的两个核心洞察：

*   **统计异常性**：与攻击相关的事件在统计上更可能表现出异常性或稀疏性。反之，常见的、不具备统计异常性的日志事件基本可以判定为非攻击。
*   **拓扑聚合性**：攻击行为（如横向渗透）通常从一个点向外扩散，导致其在日志拓扑图上产生的异常事件在空间上相互邻近，形成聚集效应。

基于以上规律，我们设计了一套改进的在线搜索算法，该算法基于斯坦纳树（Steiner Tree）模型。通过算法优化，我们将时间复杂度从 O(N²) 降低到 O(N)，同时在理论上保持了与原近似算法相同的竞争比（Competitive Ratio）。

#### 4. 系统优化：缓存机制

为了进一步提升系统性能，我们设计并实现了一套高效的缓存系统：

*   **热数据**：将识别出的可疑事件（被视为热数据）缓存到内存中，以实现快速访问。
*   **冷数据**：将其他非关键的日志数据（被视为冷数据）卸载到硬盘上。

这种冷热数据分离的策略，既保证了数据的完整性，又在系统层面显著降低了分析开销。

#### 5. 评估与应用成果

该技术在评估中取得了显著效果：

*   **误报率**：与现有方法相比，误报节点数量降低了两个数量级。
*   **检出率**：在保持高检出率方面，表现优于现有方法。

该技术已通过与深信服的合作在实际环境中得到应用，并成功发现了7个真实的攻击事件。