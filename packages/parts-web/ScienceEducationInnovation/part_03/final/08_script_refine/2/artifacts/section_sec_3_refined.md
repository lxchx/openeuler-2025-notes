# 科学问题与关键挑战：利用 AI 实现端到端网络攻击检测

## 1. 科学问题定义

我们的目标是构建一个端到端的 AI 系统，该系统能够直接处理原始的系统运行日志，通过算法分析，自动生成人类可读的、描述复杂攻击场景（如 APT 攻击）的报告。这个过程旨在完全替代对人工经验和规则的依赖。

尽管大语言模型（LLM）发展迅速，但将原始日志直接输入大模型进行分析的效果并不理想。这主要源于以下三大关键挑战。

## 2. 关键挑战

### 2.1 数据质量差

AI 模型的能力根植于数据，但在网络攻击检测领域，高质量数据的获取极为困难。

- **训练数据量不足**
  - 安全数据（如企业内部运维日志）具有隐私性，企业通常不会公开用于模型训练。
  - 学术界使用的数据多为模拟数据，其对模型能力的提升非常有限。

- **标注成本高、质量低**
  - 安全数据的标注需要具备深厚专业知识的人员（如安全领域的博士生），成本远高于普通的数据标注任务。
  - 即便是专业人士，面对海量复杂的日志，标注效率低下且质量难以保证，往往只能识别简单动作，无法精确关联到具体数据点。

- **数据分布极端不均衡**
  - 在真实环境中，攻击数据相对于正常数据的比例极其悬殊，可能达到 1:10,000,000 的级别。
  - 这种极端稀疏的数据分布给机器学习模型的训练带来了巨大困难。

### 2.2 语义理解困难

让 AI 理解底层日志并用自然语言解释攻击行为，面临着巨大的语义鸿沟。

- **底层日志与自然语言的语义鸿沟**
  - 底层日志（如操作系统日志、网络日志）记录的是机器层面的操作（如文件访问、哈希值），与人类能够理解的自然语言语义之间存在巨大差异，目前缺乏有效的弥合方法。

- **行为判断的二义性**
  - 同一个行为（如访问文件）的性质（正常或恶意）高度依赖于其上下文。正常用户的操作是合规的，而由病毒触发的相同操作则是恶意的。模型必须具备强大的上下文理解能力才能做出准确判断。

- **数据维度过高**
  - 一次完整的攻击行为可能持续数月，产生海量的日志数据。
  - 当前大模型的上下文窗口（Context Window），即使达到百万级 Token，也仅能覆盖极短时间（如半天）的日志量，远不足以捕捉长期、复杂的攻击全貌。

### 2.3 成本限制

安全行业的特性决定了其在资源投入上受到严格限制，这与 AI 模型训练和推理所需的高昂成本形成矛盾。

- **有限的算力投入**
  - 安全行业，特别是在国内，普遍不愿意像通用大模型领域那样投入巨额资金购买大量计算资源（如 GPU）。

- **严苛的性能要求**
  - **时效性**：攻击检测必须足够及时，以便快速响应。
  - **数据规模**：端到端的检测方法需要处理海量的输入数据。

因此，在成本受限的前提下，要实现对大规模数据的及时检测，构成了严峻的工程挑战。