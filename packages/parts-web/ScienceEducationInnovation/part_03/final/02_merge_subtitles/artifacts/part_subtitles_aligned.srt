1
00:00:00,000 --> 00:00:08,540
接下来让我们有请北京大学的李锭老师，为我们带来《人工智能端到端的复杂攻击检测技术研究》的主题分享。

2
00:00:08,840 --> 00:00:15,595
在人工智能广泛应用的今天，安全防护至关重要。让我们掌声欢迎李老师。

3
00:00:21,070 --> 00:00:28,730
谢谢主持人的介绍。非常感谢华为的邀请。

4
00:00:28,730 --> 00:00:32,310
我们今天介绍的这个项目，实际上已经与 openEuler 合作了很长时间。

5
00:00:32,310 --> 00:00:56,395
从2023年开始，我们就在这里进行过分享。2024年，我们非常荣幸能再次分享该项目的最新进展。

6
00:00:57,700 --> 00:01:01,505
今天的主题是《人工智能端到端的复杂攻击检测技术研究》。

7
00:01:02,270 --> 00:01:07,330
我们的研究背景是防御目前非常复杂的 APT（高级持续性威胁）攻击。

8
00:01:07,330 --> 00:01:11,890
现在的安全环境与二十年前相比已经发生了巨大变化。

9
00:01:12,450 --> 00:01:32,190
二十年前，攻击者多为业余选手，分布较为分散。而现在的攻击往往由国家级专业团队发起。

10
00:01:32,630 --> 00:01:38,095
APT 攻击已成为全球范围内面临的重大安全威胁。

11
00:01:39,090 --> 00:01:46,390
与传统攻击相比，防御 APT 攻击是安全领域的一个重大难题。

12
00:01:47,230 --> 00:01:51,800
原因在于 APT 攻击具有三个显著特征：第一是逻辑复杂。

13
00:01:51,800 --> 00:01:59,860
APT 攻击不再是单点式的，而是多套技术、多个攻击步骤的组合。

14
00:02:00,200 --> 00:02:09,445
这就要求防御技术具备多点关联能力，能够将一系列看似无关的战役关联起来，恢复出攻击逻辑。

15
00:02:10,020 --> 00:02:21,100
第二是特征隐蔽。专业人员会采用大量无文件攻击、脚本攻击等手段，极其隐蔽。

16
00:02:21,100 --> 00:02:25,265
因此，防御手段需要具备自动化挖掘隐蔽特征的能力。

17
00:02:26,995 --> 00:02:38,220
第三是技术多变。APT 攻击经常利用 0-day 漏洞或未知的临时攻击，要求防御技术能主动适应未知威胁。

18
00:02:38,940 --> 00:02:45,060
遗憾的是，目前这三个要求在技术上仍难以完全满足。

19
00:02:45,380 --> 00:02:55,840
在产业界，目前的技术仍主要基于规则，无论是最初的病毒检测、后来的行为检测，还是现在的 EDR。

20
00:02:55,840 --> 00:03:05,110
这些技术大量依赖人工专家编写规则，静态地识别和检测攻击。

21
00:03:05,690 --> 00:03:14,590
随后再手动进行关联并生成报告。这种方式的人力成本极高，且可观测性较弱。

22
00:03:14,950 --> 00:03:26,710
因此，我们的研究试图回答一个问题：能否排除人工干预，实现端到端的 AI 检测？

23
00:03:32,960 --> 00:03:40,500
即让 AI 直接读取原始的系统运行日志，经过算法分析，自动生成可读的攻击报告。

24
00:03:40,500 --> 00:03:44,965
自动将复杂的 APT 攻击场景用自然语言描述出来。

25
00:03:46,400 --> 00:04:00,180
在大语言模型如此强大的今天，这看似容易，但实际效果并不理想。

26
00:04:00,480 --> 00:04:04,870
究其原因，主要存在三个关键挑战。首先是数据质量差。

27
00:04:04,870 --> 00:04:09,190
对于 AI 模型而言，其能力完全源于数据。

28
00:04:09,190 --> 00:04:26,025
但在攻击检测领域，训练数据量严重不足。安全数据多为企业内部运维数据，具有隐私性，难以公开。

29
00:04:26,700 --> 00:04:35,125
学术界的大量数据多为模拟数据，对模型能力的提升非常有限。

30
00:04:35,990 --> 00:04:43,220
其次是缺乏标注。对安全数据进行标注的成本极高。

31
00:04:43,380 --> 00:04:51,560
它不像计算机视觉或自然语言处理可以由普通人标注，安全数据标注需要大量专业人士参与。

32
00:04:51,960 --> 00:05:07,515
这导致效率低下，且标注质量难以保证。即使是专业的博士生，也难以精确匹配每一条日志数据。

33
00:05:08,320 --> 00:05:17,020
第三是数据分布极不均匀。在现实中，攻击数据远少于正常数据。

34
00:05:17,580 --> 00:05:28,940
这种极度稀疏的数据分布给机器学习模型带来了巨大困难。

35
00:05:28,940 --> 00:05:30,285
第二个挑战是语义理解困难。

36
00:05:31,150 --> 00:05:38,610
我们希望大模型能理解底层日志中的攻击，并用人类语言解释。

37
00:05:38,610 --> 00:05:52,840
但底层日志（如操作系统日志、网络日志）与人类自然语言之间存在巨大的语义鸿沟。

38
00:05:55,140 --> 00:06:03,170
此外，理解还存在歧义性。同样的行为，在不同上下文中可能是正常的，也可能是恶意的。

39
00:06:03,190 --> 00:06:11,810
例如访问某个文件，正常用户打开是正常操作，而病毒引起则是恶意行为。

40
00:06:12,030 --> 00:06:33,170
最后是数据维度极高。大模型的上下文窗口（如 1M token）对于安全日志来说仍然太小。

41
00:06:33,470 --> 00:06:39,930
100万个 token 可能只能覆盖半天的日志，而 APT 攻击往往持续数月，模型根本无法捕捉全貌。

42
00:06:39,930 --> 00:06:52,395
第三个挑战是成本限制。安全产业，尤其是国内，受成本限制非常大。

43
00:06:52,900 --> 00:06:57,325
企业不愿像投入大模型那样投入巨额资金，也没有那么多显卡资源进行分析。

44
00:06:58,080 --> 00:07:10,670
但我们对算法的要求却很高：检测要及时，且要处理海量的端到端数据。

45
00:07:11,050 --> 00:07:17,275
在数据规模巨大、成本受限的情况下，实现及时检测面临巨大挑战。

46
00:07:18,040 --> 00:07:28,610
针对这些问题，我们在过去三年中进行了一系列系统、算法和硬件的协同优化。

47
00:07:29,090 --> 00:07:39,090
面对数据量少的问题，我们感谢华为提供了大量企业级真实数据，帮助我们提升算法。

48
00:07:39,290 --> 00:07:44,745
同时，我们研究了无监督算法，以消除对标签的依赖。

49
00:07:45,300 --> 00:07:53,200
在语义理解上，我们基于溯源图关联算法来消除歧义性。

50
00:07:53,200 --> 00:08:04,500
在成本优化上，我们从系统层面优化了数据处理和采集，提升了系统性能。

51
00:08:05,000 --> 00:08:14,380
算法上，我们借鉴了缓冲机制，通过由简到繁的层层过滤来降低复杂度。

52
00:08:15,310 --> 00:08:20,930
这些成果已发表在多篇顶级论文中，其中不少也有华为同事的贡献。

53
00:08:21,710 --> 00:08:30,450
算法的核心思路是溯源分析。我们采集操作系统的日志。

54
00:08:30,450 --> 00:08:38,230
包括网络端口访问、文件访问以及进程的创建和依赖关系。

55
00:08:38,690 --> 00:08:49,315
我们将这些数据构建成一张图，节点代表进程、文件或端口，边代表数据流向。

56
00:08:50,030 --> 00:09:02,050
在这张图上，我们利用无监督学习主动挖掘异常特征，自动找出与攻击相关的部分。

57
00:09:02,050 --> 00:09:12,060
这里涉及三个关键技术。首先是如何利用无监督学习快速过滤核心日志。

58
00:09:12,060 --> 00:09:25,180
在数千万个事件中，与攻击相关的可能不足两百个。

59
00:09:30,420 --> 00:09:44,410
我们的思路是先过滤掉明显无关的事件，再用更强大的模型判断难以确定的部分。

60
00:09:44,410 --> 00:09:51,030
这样可以大幅节省算力。我们发现了两个规律。

61
00:09:53,390 --> 00:10:05,460
第一是统计异常性。攻击相关的节点在统计上通常表现出更高的异常性或稀疏性。

62
00:10:06,200 --> 00:10:11,400
反之，如果统计上不具备异常性，则通常不是攻击。

63
00:10:14,130 --> 00:10:18,330
第二是拓扑聚集性。攻击产生的异常在拓扑结构上往往比较接近。

64
00:10:18,710 --> 00:10:31,050
因为渗透通常从一个后门开始，逐步向外扩散。在这个过程中，每一步引入的异常都会在拓扑上聚集。

65
00:10:31,530 --> 00:10:38,730
利用这些性质，我们设计了一系列算法，包括 Steiner Tree 在线搜索算法。

66
00:10:38,730 --> 00:10:42,805
我们将复杂度从 O(V^2) 降低到了 O(N)，且理论上的竞争比保持不变。

67
00:10:51,080 --> 00:10:58,580
在此基础上，我们还进行了系统优化，构建了一个分析系统。

68
00:10:58,640 --> 00:11:07,700
该系统的关键是一个缓存系统。我们将可疑事件缓存在内存中。

69
00:11:07,700 --> 00:11:13,910
对于这些“热数据”，访问速度极快。而“冷数据”则卸载到硬盘上。

70
00:11:13,910 --> 00:11:19,610
这样既保证了数据的完整性，又通过系统优化降低了开销。

71
00:11:19,710 --> 00:11:26,290
评估结果显示，我们的误报率比现有方法降低了两个数量级。

72
00:11:26,290 --> 00:11:33,410
检出率也更高。现有方法多侧重于检出率，而忽视了误报率的优化。

73
00:11:39,590 --> 00:11:46,610
我们还与深信服合作，在其实际系统中发现了七个真实的攻击。

74
00:11:47,530 --> 00:12:03,760
第二步是理解。虽然检测出了攻击，但底层图结构对人类来说并不直观。

75
00:12:04,080 --> 00:12:13,250
我们需要将其进一步细化，转化为人类可读的自然语言报告。

76
00:12:13,550 --> 00:12:42,880
针对语义鸿沟问题，现有方法多采用硬匹配，即在文本中寻找特定的文件名。

77
00:12:43,520 --> 00:12:56,080
这种方式缺乏泛化能力。为了让大模型具备泛化能力并学习相关知识。

78
00:12:56,380 --> 00:12:59,540
我们提出了一种名为 gIoC 的中间表示。

79
00:13:01,340 --> 00:13:15,930
由于缺乏足够的数据且成本高昂，我们设计的这种中间表示在形式上更接近底层事件。

80
00:13:15,950 --> 00:13:18,450
但其中的参数进行了泛化处理。

81
00:13:18,930 --> 00:13:29,490
这样我们就可以利用规模较小的模型，将其语言理解能力与底层事件及威胁情报中的知识进行匹配。

82
00:13:29,810 --> 00:13:38,730
从而使大模型具备对底层日志的理解能力，输出具有泛化能力的文本。

83
00:13:38,850 --> 00:14:06,570
基于此输出，我们还利用攻击技术间的逻辑关系（如必须先获取权限才能安装病毒）构建了推理系统。

84
00:14:07,050 --> 00:14:22,875
通过逻辑推理进一步消除误报。最终结果在图节点上标注了对应的攻击技术和手法。

85
00:14:23,450 --> 00:14:27,630
最后通过安全 Agent 自动生成攻击报告。

86
00:14:27,630 --> 00:14:36,730
整个流程并非纯粹的端到端大模型，而是先通过小模型算法进行过滤和处理。

87
00:14:37,050 --> 00:14:48,730
从数千万个事件中精选出几十个关键事件交给大模型，从而生成最终报告。

88
00:14:49,150 --> 00:14:54,840
我们在 openEuler 的运维数据中进行了验证。

89
00:14:54,840 --> 00:15:07,760
结果显示，我们不仅能自动生成自然语言报告，且误报率比现有方法降低了一个数量级。

90
00:15:07,760 --> 00:15:15,200
第三部分是系统层面的工作。监控系统通常开销巨大。

91
00:15:15,200 --> 00:15:27,550
我们需要采集大量数据并监控操作系统运行，这会给系统带来额外负担。

92
00:15:29,190 --> 00:15:35,930
我们提出了软件和硬件两种优化方案。

93
00:15:35,930 --> 00:16:00,690
软件方面，我们发现现有工具开销大的原因是由于担心探针受攻击而加入了过重的保护机制，破坏了进程隔离。

94
00:16:00,690 --> 00:16:22,310
因此，我们提出了新的架构，让每个进程独立利用自身资源进行隔离和日志处理，防止相互干扰。

95
00:16:22,310 --> 00:16:29,305
硬件方面，我们将监控负载卸载到 DPU 上。

96
00:16:29,640 --> 00:16:46,200
利用 DPU 强大的处理能力和拉取能力，以近乎零代价的方式将运行日志拉取到主机端。

97
00:16:46,820 --> 00:16:57,580
实验表明，即使在采集非常细粒度的系统调用日志时，我们的开销也能控制在 3% 以内。

98
00:16:58,040 --> 00:17:07,940
相比 Sysdig 或 Linux Audit 等主流工具，开销降低了一个数量级。

99
00:17:07,940 --> 00:17:21,230
我们实现了一个原型系统 SysArmor，并已在 openEuler 社区开源。

100
00:17:21,230 --> 00:17:39,090
它可以实现端到端的攻击检测，并支持通过大模型询问攻击详情。

101
00:17:42,140 --> 00:18:05,035
此外，我们还有其他相关工作，如针对 Wasm 的符号执行工具 WASEM、二进制模糊测试工具 SPfuzz 等。

102
00:18:05,720 --> 00:18:16,760
未来工作方面，我们计划在 openEuler 社区持续迭代 SysArmor 系统。

103
00:18:16,760 --> 00:18:35,930
并希望以合适的方式（如隐私保护系统）公开数据集，支持社区算法迭代。

104
00:18:36,370 --> 00:19:03,560
我们也欢迎各位老师和同学参与建设。系统安全是目前非常热门的研究方向。

105
00:19:03,820 --> 00:19:41,995
最后，我们正尝试将核心算法扩展到大模型安全和金融反欺诈等更广泛的领域。

106
00:19:43,120 --> 00:20:02,580
以上就是我们的工作。再次感谢华为和 openEuler 的支持。谢谢大家。

107
00:20:02,780 --> 00:20:16,385
感谢李老师的专业分享。接下来是提问环节，现场的朋友如有疑问请举手示意。

108
00:20:18,160 --> 00:20:22,495
如果没有，再次感谢李老师带来的精彩分享。谢谢。

109
00:20:22,495 --> 00:20:25,000
[掌声]
