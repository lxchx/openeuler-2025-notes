{
  "id": "sec_2",
  "index": 1,
  "title": "为何在CPU上进行AI推理？",
  "time_range": "00:00:41,290 - 00:02:35,662",
  "script": "首先让我们从一个简单的问题作为导入。\n可能很多人都很好奇，在GPU、NPU等异构算力蓬勃发展的今天，我们为什么还要在CPU上进行AI推理？\n那我们从性能和成本的两个方面给出了我们的一个分析。\n首先在性能层面，\nCPU在处理某些特定场景时，它相较于AI专用加速器是没有性能劣劣势的，甚至会有一些它的性能优势。\n像在搜推、广告场景中比较常用的一些操作，像embedding查表、序列解码等等，那这些操作的特点就是比较稀疏，然后它的数据访问的规则是不规则的，也是计算密度比较低。\n那CPU的一个多层级cache的优势，就可以让它在处理这类数据时，它的表现会比GPU更为出色。\n然后另一类的话就是对端到端时延要求比较高的场景，比如说广告、实时推荐等，那纯CPU推理的话就减少了模型下发、数据拷贝等操作，并且也不需要在CPU和xPU之间进行一个通信，减少了这样一个通信开销。\n特别是当模型比较小、计算量比较小的时候，这种优势就会更加的明显。\n那从成本的角度上面可以看到，就是说在低算力要求的一个情况下，CPU的它的硬件成本会更低。\n以及它在软件栈的角度来说，它会比较成熟，在后续的一个开发和维护的成本也相对要更低。\n然后基于此，我们也发现，很多的互联网公司，尤其是在搜推、粗排以及广告等这些核心的业务中，普遍都有一些非常可观的纯CPU的算力部署。",
  "summary": "该部分从性能和成本两个角度，分析了在CPU上进行AI推理的必要性。性能上，CPU的多层级缓存使其在处理搜推、广告等场景的稀疏、不规则数据访问时更具优势，且能为小模型提供更低的端到端时延。成本上，CPU在低算力需求下硬件成本更低，软件栈更成熟，从而降低了开发和维护成本。"
}