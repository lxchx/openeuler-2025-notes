{
  "id": "sec_4",
  "index": 3,
  "title": "客户模型调优案例分享",
  "time_range": "00:07:32,950 - 00:10:44,255",
  "script": "然后接下来我将结合具体的一个场景，就是分享几个我们在客户场景中成功落地的两个案例。\n那首先是针对这个embedding层的一个图算融合的优化。\n我们发现embedding层在我们客户的广告模型当中，占比高达30%到40%，这个优化空间还是比较大的。\n然后embedding层的这个特点就是说，它有包含大量的小算子以及频繁的内存操作，它的性能的瓶颈不在于它的计算，而在于它的那个调度和访存。\n然后由于它的那个逻辑结构会比较复杂，所以通用的图优化难度会比较大，那这里的话我们就是采用了一个人工的一个图融合的一个方案。\n我们会基于就是profiling采集的一些信息，去定位到embedding层的embedding层的性能瓶颈的一个部分，然后，再去基于算法原理去拆解出可融合并且高频可复用的一些pattern。\n然后具体的实现上来说的话，主要是分为两个关键的步骤。\n首先是在图层面，我们会对节点进行一个融合，在原生的TF框架中我们去插入一个自定义的图重写模块，让去让图去匹配我们设定的一些融合pattern，并将其改写成一个大的一个融合算子。\n然后第二个的话就是去为每一个融合pattern去手写一个高性能的一个融合算子kernel，通过鲲鹏CPU的一些特殊的向量化指令去优化，去充分发挥我们的鲲鹏CPU的一个硬件性能。\n那这项优化的话也在客户模型当层面去提升了一个5%的推理性能。\n第二个案例是针对这个MatMul加BiasAdd和BatchNorm的一个常量折叠优化。\n我们发现，由于就是客户模型的构图问题，BatchNorm它这个算子被拆分成了多个细粒度的算子，那原生TF它是无法识别到这类就是拆分后的一些细粒度算子的一个整体语义，所以就无法去使能它的一个原生一个融合特性。\n那我们从算，我们从数学原理上可以分析到，就是当矩阵乘的权重、BiasAdd的偏置以及BatchNorm的参数都是常量的时候，这些操作其实可以通过一个数学的线性变换去做一个等效变换，融合后的话就会等价成一个MatMul加BiasAdd的一个操作。\n这个当中就相当于去省掉了一个BatchNorm的一个操作，这个操作的话实际就包含了有七个细碎的小op。\n然后在具体实现过程中的话，我们是对TF做了一个轻量式的一个修改。\n我们需要在去在模型加载阶段去获取到所有的我们需要的张量数据，然后在后续的图优化阶段去读取并完成我们的折叠操作。\n那这个优化的话是最终在单个模型上的推理时延降低了10%左右。",
  "summary": "本节分享了两个客户模型调优案例。一是针对广告模型中占比高的Embedding层，通过人工图融合与手写高性能Kernel，将大量小算子融合成一个大算子，提升了5%的推理性能。二是通过常量折叠优化，将MatMul、BiasAdd及被拆分的BatchNorm操作等效变换为一个MatMul加BiasAdd操作，使单个模型推理时延降低了10%。"
}