# 客户模型调优案例分享

本文分享两个在客户场景中成功落地的模型调优案例，分别针对 Embedding 层优化和常量折叠优化。

## 案例一：Embedding 层图算融合优化

### 1. 问题背景

在客户的广告推荐模型中，Embedding 层的计算占比高达 30% 至 40%，存在较大的优化空间。其性能瓶颈主要表现为：

- **包含大量小算子**：导致调度开销大。
- **频繁的内存操作**：性能瓶颈在于访存而非计算。
- **逻辑结构复杂**：通用的图优化方法难以生效。

### 2. 解决方案

我们采用了一种人工图融合的方案，结合手写高性能 Kernel 进行优化。具体步骤如下：

1.  **瓶颈定位与模式识别**
    -   通过 Profiling 工具采集的信息，精确定位 Embedding 层的性能瓶颈。
    -   基于算法原理，拆解并识别出可融合、高频复用的计算模式（Pattern）。

2.  **图层面融合**
    -   在原生 TensorFlow 框架中插入一个自定义的图重写模块。
    -   该模块负责匹配预设的融合 Pattern，并将其改写成一个大的融合算子。

3.  **手写高性能 Kernel**
    -   为每个融合 Pattern 手动编写一个高性能的融合算子 Kernel。
    -   利用鲲鹏 CPU 的向量化指令进行深度优化，以充分发挥硬件性能。

### 3. 优化效果

此项优化使客户模型的**推理性能提升了 5%**。

---

## 案例二：MatMul、BiasAdd 与 BatchNorm 的常量折叠优化

### 1. 问题背景

由于客户模型的构图方式，`BatchNorm` 算子被拆分成了多个细粒度的算子。原生 TensorFlow 无法识别这些拆分后算子的整体语义，导致其自带的融合特性失效。

### 2. 解决方案

我们从数学原理出发，实现了常量折叠优化。

-   **数学原理**：当矩阵乘（`MatMul`）的权重、`BiasAdd` 的偏置以及 `BatchNorm` 的参数均为常量时，这些连续的操作可以通过一个线性的数学变换，等效为一个 `MatMul` 加 `BiasAdd` 操作。此举相当于省去了一个 `BatchNorm` 操作（实际包含了 7 个细碎的小算子）。

-   **实现方式**：对 TensorFlow 框架进行了轻量级修改。
    1.  在模型加载阶段，获取并缓存所有需要的常量张量数据。
    2.  在后续的图优化阶段，读取缓存数据并完成算子的折叠变换。

### 3. 优化效果

该优化使单个模型的**推理时延降低了约 10%**。