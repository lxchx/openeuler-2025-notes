{
  "id": "sec_2",
  "index": 1,
  "title": "AI通信技术趋势演进和通信诉求",
  "time_range": "00:01:00,740 - 00:04:32,445",
  "script": "我们可以看到，AI通信技术与AI负载强相关，\n并随着AI负载的变化而变化。\n从趋势中可以看到，以文本为主的LLM场景，正在向多模态以及Agent场景演进。\n同时，模型也在不断地优化和更新当中。\n这两者会导致流量负载的变化，对底层通信提出不同的挑战。\n例如，超低时延推理场景。\n原本的TPOT是50毫秒。\n现在以豆包、Kimi为主的国内模型，已经下探到10毫秒级别，\n甚至国外的模型会到5毫秒以下。\n同时，随着AI Agent以及多模态的发展，\nAI业务的负载呈现出高度多样化和动态化的特性。\n超长序列已成为常态。\n序列长度甚至达到兆级别。\n针对这些变化，我们看一下AI通信是如何演进的。\n参数量较小时，我们以单机通信为主。\n模型变大后，会产生不同的并行策略，如TP、DP、EP。\n这时以多机的集合通信为主。\n在PD分离的场景下，P和D节点之间要传输KV Cache，这时就产生了P2P通信。\n在AFD场景，Decode的Attention和FFN之间进一步分离，\n产生了M2N这种通信范式，这还是一种比较固定的关系。\n我们认为，未来AI系统会是一个全分离的系统，\n它必须具备弹性、异步这样一种特征。\n对于通信而言，也是这种异步、任意的点对点通信，即M2N的通信范式。\n南向的变化，从Server形态到超异构形态。\n超异构又有ED Mesh、2D Mesh等，这种变化对通信也有不同的诉求。\n我们结合来看，从南向的基础设施变化到北向的AI负载变化，总结出对通信的三种不同诉求。\n首先是高性能方面，要基于内存语义做极致的性能优化，应对超低时延的推理场景。\n同时要做计算与通信的深度融合。\n针对超异构大规模互联的场景，要做拓扑亲和的通信，将超异构的大带宽优势发挥出来。\n在生态与应用性上，我们强调开箱即用，让vLLM、SGLang等主流社区可以无缝使用我们的通信加速库。",
  "summary": "AI通信技术与AI负载强相关，随着AI从文本LLM向多模态及Agent场景演进，对底层通信提出了超低时延、高动态性等新挑战。为应对此趋势，通信范式从单机、集合通信演进到更弹性的M2N异步通信，并对高性能优化、生态易用性和超异构拓扑亲和性提出了更高要求。"
}