{
  "id": "sec_4",
  "index": 3,
  "title": "昇腾亲和的通信加速库CAM关键技术介绍",
  "time_range": "00:05:26,710 - 00:15:10,625",
  "script": "通信加速库CAM的定位是做昇腾亲和的通信加速库，构建不同场景的通信加速能力。\n包括MoE场景下的大EP通信库、大通算融合加速库、M2N场景以及KV Cache传输的加速库。\n对于大EP通信库，我们提供了Prefill和Decode阶段的MoE通信算子，包括Dispatch和Combine。\n同时支持不同的代际。\n虽然我们针对MoE通信做了极致的性能优化，但通信和计算仍是串行的。\n所以我们做了MoE大融合加速库FusedDeepMoE，通过Token的动态分组和细粒度流水并行，实现计算和通信的掩盖。\nM2N场景下，通信库需具备弹性可靠的通信能力。\n同时我们也在探索异步的M2N通信范式。\n在KV Cache传输场景下，我们通过自动聚合技术，提升PD分离下KV Cache的传输加速。\n我们看一下在大EP通信库下做了哪些技术手段的优化。\n可以看到，MoE通信占比将近30%，包括Dispatch和Combine。\n通信时延主要包括传输时延和静态时延，即静态下发的控制面开销和算子启动开销。\n我们以Dispatch算子为例进行打点，分析各流程的时延，可以看到主要包含三部分时延。\n一是通信数据准备。因为Dispatch阶段要把Token分发到不同专家，\n而昇腾NPU是多核的，多核并行分发Token时，如果都发给同一专家，为避免冲突，需要计算地址偏移。\n计算时Scalar能力较弱，计算时间长。\n所以我们的优化措施是让它以Vector方式计算，从而加速数据准备过程。\n二是传输数据时间较长，主要是带宽利用率低，原因是网络冲突或端口负载不均。\n我们通过通信时序编排，让共享专家Token通信时，从2/6打1变成8打1，\n减少网络冲突。\n同时通过地址偏移计算，让哈希分布更均匀，散列在不同NPU端口上，使负载更均衡。\n最后是同步耗时较长。通信有同步等待过程，\n特别是在大EP通信下，各卡间需做一次全量同步。\n这里的优化技术包括EPLB负载均衡，以及构建大通算融合算子，进一步融合通信和计算，降低同步的影响。\n我们如何做大EP的通算融合加速库呢？\n可以看到，通信和计算是串行执行的，所以通信耗时没有被掩盖。\n另外，在做Cube矩阵运算时，Vector算子是串行执行的，算力有浪费。\n而且MoE层算子个数多，下发次数多，Kernel Launch耗时也较长。\n我们的思路是，将Decode中的整个MoE层融合成一个大算子，通过细粒度流水并行，实现通信与计算的掩盖。\n融合的范围包括红框内。\n从Dispatch开始，到两次GEMM计算（一次升维、一次降维），再到Combine，整个阶段融合成一个大算子。\n如何实现呢？包含两部分的深度融合。\n首先是Dispatch和第一个GEMM的融合。\n我们可以对Token进行动态分组，收到一组Token就做一组的计算，同时接收下一组Token，实现流水线作业。\n第二部分是第二个GEMM与Combine的深度融合。\n即计算出一部分Token，就可以对这部分Token进行通信和聚合（Combine），同时计算第二组Token，实现计算与通信的流水线掩盖。\n当前这个能力已接入SGLang社区，同时也在和vLLM社区合作。\n这个场景是AFD分离场景的M2N通信加速。\n前面讲过，大家都说Decode是访存bound的。\n那究竟是哪里bound呢？主要是在Attention阶段，它要读取Prefill阶段产生的KV Cache。\n实际上，由于FFN阶段的BS较小，其算力利用率较低。\n这时我们能否加大FFN阶段的BS？因为加大BS就能提升整个系统的吞吐。\n所以这就是AFD的核心思想：将Attention与FFN分离，\n让它们可以独立组batch。这样FFN就可以组一个较大的batch，从而提升整个系统的吞吞吐。\n但是，A和F分离后，产生了额外的M2N通信，即Attention和FFN之间。\n这时，AI框架上就需要做多batch流水，将通信掩盖掉。\n在该场景下，我们也构建了自己的M2N通信加速库。\n首先，通过NPU直驱通信，减少控制面的时间开销。\nNPU直驱是指在NPU侧发起AI集合通信，而非从CPU侧发起，这样可以减少控制面开销。\n同时，做通信融合与编排调度，将A2F及F2A通信与本地计算融合，消除冗余通信。同时，A和F分离要求整个系统是弹性的。\nAttention和FFN节点各有其弹性机制。这时通信库也需具备弹性能力。\n随意增减节点，通信域都能弹性地进行通信，而无需销毁整个通信域，后者是无法接受的。\n最后介绍一下PD分离场景。在PD分离下，KV Cache的传输是重要环节。\n通过我们构建的推理传输加速库MIXL，相比现有能力可提升30%。\nMIXL是一个中间件，南向屏蔽不同传输通道，北向对接不同AI服务平台及框架。\n我们通过两种技术实现。一是分片消息聚合。\n通过对多层KV Cache数据进行聚合（这里有不同聚合策略），再一起传输数据，提升带宽，从而提升系统吞吐。\n二是异构多径聚合。\n昇腾架构中，RoCE网卡嵌入NPU侧，NPU侧能看到多种传输通道，包括UB和RoCE。\n当前我们只使用单一类型的传输通道。\n通过多径聚合技术，我们可以使用多个传输通道，包括其他空闲卡的通道。\n基于这种多路径传输，提升整体传输效率。",
  "summary": "本节介绍了昇腾亲和的通信加速库CAM，它旨在为MoE、AFD分离、PD分离等不同场景构建通信加速能力。CAM通过大EP通信库、通算融合加速库FusedDeepMoE、M2N通信加速库及KV Cache传输加速库MIXL，采用通信时序编排、细粒度流水并行、NPU直驱通信、分片消息聚合等关键技术，解决通信开销大、计算通信串行等问题，从而显著提升系统性能。"
}