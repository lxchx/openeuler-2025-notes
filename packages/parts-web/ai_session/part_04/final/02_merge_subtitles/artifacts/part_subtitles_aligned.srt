1
00:00:00,000 --> 00:00:07,860
有请宝德计算机系统股份有限公司解决方案销售总监金龙先生，

2
00:00:08,080 --> 00:00:14,620
给我们带来《宝德基于intelligence boom推理优化及智能应用的实践分享》。

3
00:00:14,700 --> 00:00:21,480
大家欢迎。

4
00:00:21,520 --> 00:00:25,740
各位好，我是来自宝德计算机的金龙。

5
00:00:25,740 --> 00:00:32,740
今天很荣幸给各位汇报一下我们与欧拉合作的一些实践，以及我们在这方面的一些思考。

6
00:00:33,790 --> 00:00:39,950
首先讲一下宝德。宝德本身是在国内最早做Intel服务器的厂家。

7
00:00:40,730 --> 00:00:48,810
2019年我们也是第一批做华为鲲鹏服务器的厂家，后来我们又做了昇腾。这是宝德的概况。

8
00:00:49,170 --> 00:00:56,370
我在公司除了负责公司解决方案以外，我还有一个身份，就是我现在也在管公司的IT部。

9
00:00:56,770 --> 00:01:01,350
所以，我们为什么跟欧拉合作呢？第一，我们看好推理市场。

10
00:01:01,570 --> 00:01:05,260
大模型推理市场，我们在这方面研究，觉得要去拓展市场。

11
00:01:05,260 --> 00:01:10,660
第二，作为IT来讲，我们自己公司内部有很多重要的诉求。

12
00:01:10,860 --> 00:01:18,120
宝德本身是一个传统的制造型企业，我们在内部推广的过程中也碰到了很多问题。

13
00:01:18,440 --> 00:01:25,265
所以在这方面跟欧拉交流完之后，我们决定拥抱欧拉，跟它展开合作。

14
00:01:25,910 --> 00:01:35,290
对于现在的宝德而言，虽然我们年销售额可能在几十到上百亿，但我们的员工大概在1300多个人。

15
00:01:35,650 --> 00:01:38,630
实际上我们内部在推这块也碰到很多问题。

16
00:01:38,630 --> 00:01:47,010
简单说，第一，在算力需求这块，不算苛刻，但要求也不低。

17
00:01:47,410 --> 00:01:57,000
第二，在IT投入这块，跟华为是没法比的。实际上对成本我们是有比较高的要求的。

18
00:01:57,040 --> 00:01:58,960
我们还是要讲一些性价比。

19
00:01:59,380 --> 00:02:07,980
第三，在投入这块，我相信像类似于宝德这样的很多IT投入都是一样的。

20
00:02:08,200 --> 00:02:12,300
无论从人员、能力、经验这块，都是有限的。

21
00:02:12,500 --> 00:02:18,040
如果一个系统太复杂，其实对我们部署来讲，可持续性是有很大问题的。

22
00:02:18,320 --> 00:02:22,930
简单归纳三点，就是从我们选择上就这三点。

23
00:02:23,170 --> 00:02:27,650
第一，我们如果选型一个东西，第一要足够好，这是讲技术先进性。

24
00:02:28,090 --> 00:02:30,890
第二，要有性价比，成本不能太高。

25
00:02:31,599 --> 00:02:32,589
第三，要好用。

26
00:02:32,949 --> 00:02:41,010
如果这个事情太复杂，对技术人员的要求太高，实际上在一个制造型企业落地时会碰到非常多的困难，走不下去的。

27
00:02:41,010 --> 00:02:41,810
就是这个。

28
00:02:41,810 --> 00:02:49,590
所以，我们跟欧拉交流完之后，我们觉得欧拉的选择更符合我们。

29
00:02:49,590 --> 00:02:57,370
因为在这之前，其实我们像跟国内其他几个厂家，我们其实都交流过，我们自己内部也搭了系统，也在实践。

30
00:02:57,690 --> 00:02:59,390
但是我们也碰到了很多问题。

31
00:02:59,930 --> 00:03:13,820
今天我们在这里跟欧拉一直推出我们叫“宝智灵”的RAG一体机，这个会作为宝德后续在我们推理领域的一个解决方案品牌一直往前在走。

32
00:03:14,180 --> 00:03:23,575
那么跟欧拉在这做完之后，我们是整个基于我们的一个4U、一机十卡的机器，这个卡是昇腾310 Duo。

33
00:03:24,270 --> 00:03:28,190
可以把我们整个硬件的成本降到30万级别。

34
00:03:28,650 --> 00:03:36,610
第二，我们是可以整个预装，预装完之后把整个一套软件全部直接预装，给客户一体机进行交付。

35
00:03:36,610 --> 00:03:42,410
然后，我们现在所有的软件在我们的实验室都是经过测试过的。

36
00:03:42,930 --> 00:03:51,250
我们对它的定位是什么？就是我们定位是追求中小型的客户，完了之后有一定并发量，几十路，不会要求高并发。

37
00:03:51,570 --> 00:03:54,035
我们不跟训练去比高并发。

38
00:03:54,530 --> 00:04:04,790
我们在8路、32路情况下，实际上是跟910B基本上在并发的数据量上可以达到一个相当的水平，但是我们的硬件成本就做到大幅降低。

39
00:04:05,530 --> 00:04:06,975
主要追求是这个东西。

40
00:04:07,710 --> 00:04:14,890
我们追求极致的性价比，在针对我们这种几十路并发下，我们的性能足够好，成本足够低。

41
00:04:15,310 --> 00:04:18,170
然后我们运维、交付足够简单。

42
00:04:18,590 --> 00:04:22,389
这个是我们整个方案在追求的目标。

43
00:04:23,560 --> 00:04:36,620
所以在这里的话，我们直面成本和性能的挑战，从整个系统的角度，某种程度上我们打破过去的软硬件解耦，我们想纵向去进行耦合，去实现整体系统性能的最佳平衡。

44
00:04:37,040 --> 00:04:48,235
我还记得当时我们跟欧拉第一次交流的时候，欧拉在给我们演示的时候，是用三台910B，大家可以估算出来，这个是在300万级别的做多模态。

45
00:04:48,980 --> 00:04:57,535
但是通过几个月工作下来，我们今天是用的一台机器、十张310 Duo的卡，整个硬件平台降到了30万级别。

46
00:04:58,300 --> 00:05:00,000
这个进步是非常大的。

47
00:05:00,000 --> 00:05:11,100
在这里面，通过我们的软硬件协同调优，通过异构并行融合，通过组合量化策略，通过AI辅助敏捷开发等多种手段。

48
00:05:11,420 --> 00:05:25,840
可以看到这几个月我们进步非常快，整个完了之后，我们在一个相对来说，一个相对廉价的平台上，达到了一个足够好的性能，做了这件事情。

49
00:05:25,920 --> 00:05:40,400
最近，其实我们把LMCache在我们的硬件平台上已经做了一些测试，测完之后，其实对多轮交互情况下，对我们的时延降低20%到30%，效果非常明显。

50
00:05:40,700 --> 00:05:45,300
后续的话，我们还会把expert，包括后面这个DeepInsight到我们平台上去验证。

51
00:05:45,640 --> 00:05:50,900
整个一套，我们会作为打包成一个完整的方案，给客户进行提供。

52
00:05:51,420 --> 00:06:00,790
所以这块的话，我们整个经过我们这几个月实验下来之后，我们从我们自己推理来讲，我们觉得第一个，我们选择欧拉这条路是对的。

53
00:06:01,110 --> 00:06:16,430
第二个，我们整个团队的选择的方向没什么问题，后续的话我们会加强这个跟欧拉的合作，包括到明年Q1，新的350P的芯片出来之后，我们也会跟欧拉一起第一时间去做适配。

54
00:06:16,770 --> 00:06:26,740
完了之后，结合我们的DeepInsight能力，我们会在推出我们的多模态的一些产品和方案，完了之后更好地去给客户提供一些服务。

55
00:06:27,080 --> 00:06:27,445
好。

56
00:06:28,890 --> 00:06:37,230
这个是我们今天想给各位领导汇报的就是我们在跟欧拉合作这块，在推理这块的方案情况，大致情况就这样。

57
00:06:37,230 --> 00:06:38,645
好，感谢，谢谢。

58
00:06:39,770 --> 00:06:42,495
谢谢。

59
00:06:44,400 --> 00:06:57,960
好，那个非常感谢金老师给我们带来的这个“宝智灵”RAG一体机的这个解决方案，极具高性、低成本、易使用的这个推理解决方案。

60
00:06:58,240 --> 00:07:16,150
我们可以看到刚才跟社区的intelligence boom结合之后，它从一个推理的解决方案从百万级降低到十万级的这样一个水平，将近带来十来倍的一个成本的下降，是一个很好的这个案例啊。

61
00:07:16,330 --> 00:07:17,000
好。
