{
  "id": "sec_3",
  "index": 2,
  "title": "实践案例一：补丁合并（Patch Merging）",
  "time_range": "00:08:43,660 - 00:15:35,359",
  "script": "我们先以第一个 MCP Servers 来落地我们 Patch Merging 这个, 我一个例子, 我一个一个起点来做一下简单的介绍。从用户的角度来说的话, 我们如果说以前在合代码, 以前合代码的旅程的话, 就是人工地去做大量的分析。\n把每个 patch 都做一个详细的分析, 结合它的 commit 以及代码的上下文。\n然后呢, 我们落地这个之后呢, 大概的流程就是通过用户以自然语言的方式进行输入, 比如说我需要拉取 Linux 主线上面的某个节点的一个代码, 然后跟我当前的内核主线的代码做一个对比分析。\n那么它们就会去把这两个内核之间的一个差异, commit 的一个差异以及 patch 的差异, 做一个详细的分析之后, 然后它就会输出一个分析报告。\nAgent 就会帮我们输出一个分析报告, 这个分析报告呢是可以给到我们人工去做一个校准的。因为我们其实现在并不能完全100%地相信 AI 分析的一个结果。\n很多时候它可能会出现一些误判, 有的时候我们可能会调用多个 Agent 去, 比如说不同的模型对它做一个分析, 然后我们人工需要对这个结果做一个综合性的一个评估之后, 然后呢, 做出人工确认的一个调整, 我们确认它需要合入, 或者确认它对我们的业务产生影响, 那它是有价值的, 那我们再做一个回写, 把这个结果回写到它给我们的一个报告里面去。\n然后再次把这个报告传递给它, 然后呢, 它再会调用下一个 Agent 去帮我们把这个代码的合入进行一个完成, 或者说是它会对中间出现一些冲突啊, 做一些自动的一些分析和做一个代码的合入。\n那么这样一个过程呢, 其实就让我们能够能够能够释放出来非常多精力了。\n比如说我们再输入一条命令, 就是比如说我要它分析 openEuler 24.03 SP1 现在某某 commit 到我们现在内核的一个分析之后, 那这个这个同事他就可以同时去做别的事情。\n那么等过上可能一晚上或者说是一天的时间, 那我们拿到一个分析报告之后, 这个时候再花上1到2个小时的时间去把这个代码 merge, 做一下代码 patch, 做一下分析报告的一个确认, 那这样它的工作就基本是完成了, 完成90%了。\n以前呢, 它可能是每个 patch 分析, 每个 patch 分析都是耗时两周以上的, 那现在可能1到2个小时的时间, 实际投入时间1到2个小时的时间, 那它就能完成这个工作了。\n好。\n这个视频是能播放的吗? 这个地方有一个, 有一个视频。\n没关系。\n其实那个过程的话, 那也大概讲过了, 我们就继续往下。\n那么基于那个白盒这个视角来看的话, 给大家介绍一下就是内部是怎么去实现的这个地方。\n就内部怎么通过 Agent 的方式来实现的。首先第一个的话, 我们是规范了一个工作流, 这个工作流的话就是我们人为来进行补丁分析合入的时候的一个大概的过程。\n然后呢, 这个 workflow 就是会, 会让它具备一个那个自动规划的能力, 就是也是通过大语言, 大语言模型来实现的, 大模型来实现的。为什么要要这样来方式呢? 因为我们人工输入的时候都是一些自然语言, 所以需要用到大语言模型来实现。\n然后呢, 这个 workflow 的话呢, 它的设计的话其实就是它, 我们会给它输入下面的几个我们不同的 Agent, 比如说典型的补丁分析 Agent 和代码整理 Agent, 会告诉它这些 Agent 是完成什么工作的, 然后呢, 它在这个调度过程当中, 它的这个 workflow 过程当中, 它会去自动编排, 比如说它可能要要分批做分析, 比如说它需要先挑某些模块来分析, 分析完了之后做一下整理, 然后呢, 然后呢进行下一个模块的分析, 然后再做个整理。\n它可能会自己去做这样的一个一个任务的编排, 比如说我先分析 IO 栈的, 再分析网络栈的, 什么的。\n它这样会在这个 workflow 里面, 规划里面去做一个编排。然后第二块呢就是补丁分析的这个具体的 Agent, 就是对代码理解会稍微深刻一些的一个 Agent。\n然后呢, 它也会结合我们的一个提示词, 比如说从起点是什么, 终点是什么, 然后中间可能涉及到某些 commit 信息, 然后呢, 它会去挑选这个 commit 信息里面会包含一些重点内容, 比如说它是会影响宕机的, 会影响网络异常的, 协议栈的, 什么的。那么这样的话, 它就会结合 commit 信息的内容, 然后分析出来这个的影响面是什么, 是高、中、低, 还是什么, 是宕机还是什么, 还是什么样的一些问题, 以及 CVE 之类的, 它会给出这个漏洞的严重等级。\n然后呢, 代码整理的话, 就是在我们给它确认好这个补丁需要做合入之后, 这个 Agent 的话, 它会帮我们去把代码做一个自动的 merge, 就是 merge 到我们的代码主线。\n然后呢, 比如说出现冲突的时候, 它会帮我们自动地去解决这样的一些冲突, 当然也会失败, 失败的话就会让我们再去人工确认这个地方, 然后它会把 merge 的那个链接反馈给我们, 我们去人工确认之后, 再把人工代码, 人工把代码提交上去, 然后呢, 让它去帮我们把这个代码做最终的合入。\n那这是典型的三个 Agent, 那么可能背后还有很多其实小的 Agent, 这是典型的比较关键的三个。\n整个的流程的话就是由 workflow 先做一个那个整个的任务的一个规划, 它会先输出一个基础的一个过程出来, 然后让我们做一个人工的确认。确认好之后, 它就会做一个具体的分析, 分析好之后会给我们一个反馈, 反馈完了之后, 我们会让我们给它提交一个反馈之后, 它就会做代码的补丁的整理和合入。\n然后合入完成之后, 它会给我们一个报告, 就是它合入了多少, 它合入了多少的那个补丁, 然后呢每个补丁合入的那个结果是什么样子的, 然后呢它的提交链接是什么。\n那这样的话, 你在人工就可以让你做一个记录的归档, 或者说是再进行一次确认就 OK 了。\n好。\n然后最终的话, 我们落地的一个效果大概是还是比较突出的, 对我们来说, 就是我们每个, 每个月、每个季度都会做一次定量的代码的分析, 就是跟社区去做一个代码的分析。\n因为我们需要把那个一些典型的或者说是高危的一些漏洞, 或者说是我们常用到的一些内核模块的一些文件系统啊, IO 啊, 然后呢这些模块的严重问题需要做修复。那其实对我们来说就是一个比较重复性的一个工作, 并且它的那个价值也是比较大的一个工作。\n然后分析过程也存在一些不确定性, 然后呢, 它帮我们完成之后的效果的提升的话, 大概有这么几个。一个的话就是它的分析准确率, 其实我们也做了一下回溯, 就是采用一个模型, 就是千万三的时候那个模型, 然后我们分析完了之后, 它的准确率在75%到93%。\n然后我们最后综合了几个模型的, 多个模型之后, 它的它的那个覆盖率基本能到, 基本准确率的话基本能到90%以上。然后呢, 第二块的话是效率的一个提升, 效率提升以前的话, 其实每次分析合入的话, 至少就是开发侧一周以上。\n然后呢, 在这个落地之后呢, 我们就实现了一到两个小时之内就可以完成实际的工作。\n整个的那个合入的效率其实得到了一个数量级的一个提升。",
  "summary": "本节以补丁合并（Patch Merging）为例，介绍了如何通过自然语言输入，让 AI Agent 自动完成内核代码的差异分析、生成报告并等待人工确认。其内部实现基于一个由大模型驱动的工作流，该工作流会自动编排补丁分析、代码整理等多个 Agent，以处理代码合并与冲突解决。该实践将原先耗时数周的分析工作缩短至一到两个小时，分析准确率达到90%以上，极大地提升了效率。"
}