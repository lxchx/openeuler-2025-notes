1
00:00:00,500 --> 00:00:04,080
女士们,先生们,大家下午好。

2
00:00:04,400 --> 00:00:13,690
欢迎大家来到操作系统峰会暨 openEuler Summit 2025 AI分论坛的现场。

3
00:00:13,690 --> 00:00:15,820
论坛现在开始。

4
00:00:17,340 --> 00:00:26,980
请允许我介绍一下自己, 我是来自 openEuler 社区 AI 方向的 SIG 组的 Maintainer, 我叫杜海田。

5
00:00:27,540 --> 00:00:35,730
本次我是作为出品人以及主持人。

6
00:00:35,970 --> 00:00:40,090
我先给大家介绍一下, 谈谈我自己对这块的一些想法。

7
00:00:40,090 --> 00:00:51,730
openEuler 开源六年, 经历了三个阶段。第一个阶段是多样性, 第二个阶段是全场景, 第三个是 AI。现在我们正处于第三个阶段。

8
00:00:52,130 --> 00:01:06,840
从 openEuler 2023年提出 OS for AI 以及 AI for OS 这个理念以来, 一直围绕 AI 软件栈的生态、推理加速、训练的可用性、整机资源利用率、智能化几个方向构建能力。

9
00:01:07,020 --> 00:01:21,260
目前已经有四个 SIG 组, SIG-AI、SIG-intelligence、SIG-LLM, 还有 MCP-Tools-Ecosystem SIG 组, 同时与 devstation SIG 组以及编译器这个 SIG 组做好了比较好的协同。

10
00:01:21,620 --> 00:01:31,550
都一起加入了这个工作组里面去。我们也看到了今天上午的 Intelligence BoM 第二个版本纳入到这个工作组里面去。

11
00:01:32,130 --> 00:01:39,190
我们在关注技术发展的同时, 也获得了各行各业的大力支持, 也看到了一些商业落地的一些实践。

12
00:01:40,290 --> 00:01:45,610
在此, 我们非常感谢关注 openEuler AI 发展的各位开发者及伙伴的到来。

13
00:01:45,970 --> 00:02:03,000
下面, 我们隆重地邀请我们第一个演讲嘉宾, 他是来自于深信服科技股份有限公司的研发主管, 孙政华先生, 给我们带来《基于 openEuler intelligence 组建一支 OS 开发团队》的分享。大家欢迎。

14
00:02:23,810 --> 00:02:25,710
各位来宾,各位老师,大家下午好。

15
00:02:25,950 --> 00:02:35,850
非常荣幸能有机会到这里, 与大家分享我们团队在操作系统与 AI 结合领域的一些关键实践和阶段性成果。

16
00:02:36,470 --> 00:02:46,450
首先, 我们回顾一下, 在2024年, 可以称为是 AI Agent 的应用元年。

17
00:02:46,650 --> 00:03:04,420
包括 MCP 协议, 其实给我们带来了非常多的改变, 比如可以将一些多任务、复杂性程度比较高、不确定性程度比较高的一些长链条的处理任务, 给它拆解成不同的专家角色, 让它们能够实现人机协同的方式, 帮我们完成工作。

18
00:03:04,980 --> 00:03:18,380
那么在这个背景之下, openEuler intelligence 团队与我们做了一些联创, 把它这一套基础设施通过集成到我们产品开发的过程中去, 然后把我们的整个的基础设施实现了一个打通。

19
00:03:18,860 --> 00:03:33,735
提供了一些 MCP 的关键的服务节点, 以及一些 Agent 的对接的方式, 然后我们的开发的流程也比较顺畅地往下跑, 包括集成到我们公司的自研的一些 Codelet 之类的开发工具里面去。

20
00:03:34,450 --> 00:03:36,625
接下来我给大家做一些简单介绍。

21
00:03:37,580 --> 00:03:44,540
在我们的 OS 团队中, 其实有几个非常大的命题, 就是关于操作系统维护的。

22
00:03:44,540 --> 00:03:51,820
首先第一个就是我们的操作系统需要非常大量地跟社区进行紧密配合, 其中一个点就是我们的 Patch Merging。

23
00:03:51,820 --> 00:04:08,050
Patch Merging 就是我们需要频繁地从社区合入一些补丁或者 Bug Fix。每次的合入规模可能是千级别, 甚至是如果我们大批量组件合入的时候, 都是成千上万的补丁分析的规模。

24
00:04:08,210 --> 00:04:26,310
每次分析, 工程师的耗时每千条补丁可能会耗时80+到100+小时, 也就是我们投入一个资深的内核开发工程师以及对应的组件开发工程师, 每个组件它的分析工作量大概就是两周以上。

25
00:04:26,310 --> 00:04:29,670
这只是单纯做分析, 还没有说代码的合入。

26
00:04:30,090 --> 00:04:44,400
然后在我们合入代码的过程中, 还会出现非常多的代码冲突报错, 这个时候就需要我们人为地介入, 做一个代码补丁的分析和合入, 这个地方可能占比在10%以上。

27
00:04:45,040 --> 00:04:58,230
最后就是还有一个关键的点, 就是我们给客户提供操作系统的时候, 还需要给客户承诺一个高危漏洞的响应周期, 就是在14天以内可能要完成中高危漏洞的修复, 并且推送到客户端。

28
00:04:58,230 --> 00:05:00,550
这是一个典型的 Patch Merging 的一个场景。

29
00:05:00,550 --> 00:05:04,750
然后第二个场景的话, 就是我们在合入代码过程中还需要做一些集成测试。

30
00:05:04,750 --> 00:05:12,110
集成测试也是一样的, 就是我们可能根据社区的合入建议, 我们需要自己自身去做一个分析和测试合入。

31
00:05:12,230 --> 00:05:22,770
第一个就是分析的量级跟补丁的规模其实是比较对应的, 那我们可能会做一些融合, 比如说按模块去区分, 但是其实并没有一个明显的降低, 也是数千级别的一次每次的合入。

32
00:05:23,150 --> 00:05:38,320
第二块就是对测试能力的要求, 其实相对来说是比较高的, 因为我们内核代码的合入或者说一些关键中间件的合入, 它需要对我们的系统测试非常非常精通, 可能是一个比较高、比较精通这里的一个测试专家。

33
00:05:38,320 --> 00:06:00,590
最终的覆盖效果, 其实我们认为, 我们从我们的实际的产出来看, 如果社区测不出来这个问题, 那我们其实自己去测, 即使是我们做了非常多的 Patch Merging 之后的一个合入的话, 它的那个测试效果其实也是聊胜于无的, 可以认为就是测试的效果并不是非常的好, 因为因为它比较依赖于我们那个测试的专家以及他的经验。

34
00:06:00,819 --> 00:06:01,500
好。

35
00:06:01,500 --> 00:06:16,550
那第三个场景的话, 就是在我们的开发运维的一个过程当中, 可能需要对我们非常多的设备去做一个实时的监控, 然后当它出现一些问题的时候, 我们需要把这些问题上报到我们的巡检平台, 或者是进行一个 Bug 的记录。

36
00:06:16,910 --> 00:06:38,320
那这个地方我们内部的操作系统团队这边维护了上百套的自动化的设备, 包括那个虚拟化部署的、物理机部署的, 以及运行到一些可能小、小规模的一些嵌入式设备之类的, 这里面搭载了上百套的一个设备在上面去。那么我们的运维人员每天就需要对这个设备进行一个定期的检查和巡检。

37
00:06:38,320 --> 00:06:43,360
如果说它出现问题的话, 那就需要记录, 然后找开发工程师去做一个分析。

38
00:06:43,360 --> 00:07:09,850
那这里的那个设备数量的话就是上百套, 然后但是出现问题的时候, 那对于这个测试专家来说, 或者说这个运维专家来说, 他需要对这些信息做初步的分析和 Bug 的上报, 这个 Bug 上报过程就会需要很多的信息的记录。那其实我们发现, 在这个他们提交的缺陷里面, 然后我们去回溯它的是否有效的一个情况来看的话, 可能有15%以上都是无效的 Bug, 或者是信息不全的一些 Bug。

39
00:07:09,850 --> 00:07:18,950
那这样的话对于我们的操作系统团队去维护这些 Bug, 或者说修复这些 Bug 来说, 它其实并没有起到正向的作用, 反而产生了非常多的无效的工作量。

40
00:07:18,950 --> 00:07:36,660
然后呢, 重复问题的占比也是非常非常高的, 就是因为非常多的设备, 它可能具备一定的相似性, 或者说它很多问题会在不同的设备上面出现。那出现这样问题的时候呢, 我们也做了一个分析, 大概是30%以上的问题都是重复性的, 也就是不是第一次首次提交的一些问题, 这里也会消耗非常多的工作量。

41
00:07:36,660 --> 00:07:45,540
每天的重复工作几乎是接近100%, 因为这个同学他天天就需要去对设备去做巡检, 然后呢去做 Bug 的上报, 去做技术分析。

42
00:07:46,000 --> 00:08:04,290
然后最后一个场景的话, 就是我们对于一些维护内核的同事可能比较熟悉的, 就是对那个 Vmcore 做一个分析, 就是去查一些内核的 Bug, 然后修复内核的 Bug。这里要求的话是非常高的, 就是对这个技术人员的要求是非常高的, 它是一个需要一个资深的内核的研发, 并且要熟悉各个内核的子系统。

43
00:08:04,290 --> 00:08:14,750
否则的话, 就是每个 Bug 就需要拉上一个整个团队的不同方向的, 比如文件存储啊, 然后呢 IO 之类的工程师去一起分析, 所以对这个专业性要求是非常高的。

44
00:08:14,750 --> 00:08:26,990
然后解决耗时的话其实也是比较高的, 因为我们经过大量测试之后发布的一个问题的话, 它相对来说比较少, 然后在这个情况出现 Bug 的话, 它的概率相对来说比较低, 然后难度就会比较高。

45
00:08:27,070 --> 00:08:29,580
修复的周期的话都会相对很长。

46
00:08:30,200 --> 00:08:42,000
但这个过程的自动化占比其实是非常非常低的, 在我们落地之前其实非常非常低的, 可以说全靠人工的经验和现有的一些 GCC、Vmcore 分析的一些工具。

47
00:08:42,000 --> 00:08:43,660
我们怎么解决的呢?

48
00:08:43,680 --> 00:08:58,960
我们先以第一个 MCP Servers 来落地我们 Patch Merging 这个, 我一个例子, 我一个一个起点来做一下简单的介绍。从用户的角度来说的话, 我们如果说以前在合代码, 以前合代码的旅程的话, 就是人工地去做大量的分析。

49
00:08:58,960 --> 00:09:02,840
把每个 patch 都做一个详细的分析, 结合它的 commit 以及代码的上下文。

50
00:09:03,200 --> 00:09:16,970
然后呢, 我们落地这个之后呢, 大概的流程就是通过用户以自然语言的方式进行输入, 比如说我需要拉取 Linux 主线上面的某个节点的一个代码, 然后跟我当前的内核主线的代码做一个对比分析。

51
00:09:17,350 --> 00:09:26,950
那么它们就会去把这两个内核之间的一个差异, commit 的一个差异以及 patch 的差异, 做一个详细的分析之后, 然后它就会输出一个分析报告。

52
00:09:27,070 --> 00:09:38,210
Agent 就会帮我们输出一个分析报告, 这个分析报告呢是可以给到我们人工去做一个校准的。因为我们其实现在并不能完全100%地相信 AI 分析的一个结果。

53
00:09:38,310 --> 00:10:02,540
很多时候它可能会出现一些误判, 有的时候我们可能会调用多个 Agent 去, 比如说不同的模型对它做一个分析, 然后我们人工需要对这个结果做一个综合性的一个评估之后, 然后呢, 做出人工确认的一个调整, 我们确认它需要合入, 或者确认它对我们的业务产生影响, 那它是有价值的, 那我们再做一个回写, 把这个结果回写到它给我们的一个报告里面去。

54
00:10:02,700 --> 00:10:15,610
然后再次把这个报告传递给它, 然后呢, 它再会调用下一个 Agent 去帮我们把这个代码的合入进行一个完成, 或者说是它会对中间出现一些冲突啊, 做一些自动的一些分析和做一个代码的合入。

55
00:10:16,650 --> 00:10:21,590
那么这样一个过程呢, 其实就让我们能够能够能够释放出来非常多精力了。

56
00:10:21,630 --> 00:10:33,630
比如说我们再输入一条命令, 就是比如说我要它分析 openEuler 24.03 SP1 现在某某 commit 到我们现在内核的一个分析之后, 那这个这个同事他就可以同时去做别的事情。

57
00:10:33,770 --> 00:10:52,500
那么等过上可能一晚上或者说是一天的时间, 那我们拿到一个分析报告之后, 这个时候再花上1到2个小时的时间去把这个代码 merge, 做一下代码 patch, 做一下分析报告的一个确认, 那这样它的工作就基本是完成了, 完成90%了。

58
00:10:52,500 --> 00:11:02,445
以前呢, 它可能是每个 patch 分析, 每个 patch 分析都是耗时两周以上的, 那现在可能1到2个小时的时间, 实际投入时间1到2个小时的时间, 那它就能完成这个工作了。

59
00:11:03,289 --> 00:11:06,189
好。

60
00:11:06,470 --> 00:11:12,170
这个视频是能播放的吗? 这个地方有一个, 有一个视频。

61
00:11:12,170 --> 00:11:12,690
没关系。

62
00:11:12,770 --> 00:11:18,940
其实那个过程的话, 那也大概讲过了, 我们就继续往下。

63
00:11:18,940 --> 00:11:24,900
那么基于那个白盒这个视角来看的话, 给大家介绍一下就是内部是怎么去实现的这个地方。

64
00:11:24,900 --> 00:11:35,580
就内部怎么通过 Agent 的方式来实现的。首先第一个的话, 我们是规范了一个工作流, 这个工作流的话就是我们人为来进行补丁分析合入的时候的一个大概的过程。

65
00:11:35,700 --> 00:11:50,610
然后呢, 这个 workflow 就是会, 会让它具备一个那个自动规划的能力, 就是也是通过大语言, 大语言模型来实现的, 大模型来实现的。为什么要要这样来方式呢? 因为我们人工输入的时候都是一些自然语言, 所以需要用到大语言模型来实现。

66
00:11:51,230 --> 00:12:17,810
然后呢, 这个 workflow 的话呢, 它的设计的话其实就是它, 我们会给它输入下面的几个我们不同的 Agent, 比如说典型的补丁分析 Agent 和代码整理 Agent, 会告诉它这些 Agent 是完成什么工作的, 然后呢, 它在这个调度过程当中, 它的这个 workflow 过程当中, 它会去自动编排, 比如说它可能要要分批做分析, 比如说它需要先挑某些模块来分析, 分析完了之后做一下整理, 然后呢, 然后呢进行下一个模块的分析, 然后再做个整理。

67
00:12:17,810 --> 00:12:20,680
它可能会自己去做这样的一个一个任务的编排, 比如说我先分析 IO 栈的, 再分析网络栈的, 什么的。

68
00:12:20,680 --> 00:12:30,480
它这样会在这个 workflow 里面, 规划里面去做一个编排。然后第二块呢就是补丁分析的这个具体的 Agent, 就是对代码理解会稍微深刻一些的一个 Agent。

69
00:12:30,480 --> 00:12:59,770
然后呢, 它也会结合我们的一个提示词, 比如说从起点是什么, 终点是什么, 然后中间可能涉及到某些 commit 信息, 然后呢, 它会去挑选这个 commit 信息里面会包含一些重点内容, 比如说它是会影响宕机的, 会影响网络异常的, 协议栈的, 什么的。那么这样的话, 它就会结合 commit 信息的内容, 然后分析出来这个的影响面是什么, 是高、中、低, 还是什么, 是宕机还是什么, 还是什么样的一些问题, 以及 CVE 之类的, 它会给出这个漏洞的严重等级。

70
00:12:59,969 --> 00:13:10,370
然后呢, 代码整理的话, 就是在我们给它确认好这个补丁需要做合入之后, 这个 Agent 的话, 它会帮我们去把代码做一个自动的 merge, 就是 merge 到我们的代码主线。

71
00:13:10,370 --> 00:13:28,640
然后呢, 比如说出现冲突的时候, 它会帮我们自动地去解决这样的一些冲突, 当然也会失败, 失败的话就会让我们再去人工确认这个地方, 然后它会把 merge 的那个链接反馈给我们, 我们去人工确认之后, 再把人工代码, 人工把代码提交上去, 然后呢, 让它去帮我们把这个代码做最终的合入。

72
00:13:28,780 --> 00:13:36,920
那这是典型的三个 Agent, 那么可能背后还有很多其实小的 Agent, 这是典型的比较关键的三个。

73
00:13:37,100 --> 00:13:55,895
整个的流程的话就是由 workflow 先做一个那个整个的任务的一个规划, 它会先输出一个基础的一个过程出来, 然后让我们做一个人工的确认。确认好之后, 它就会做一个具体的分析, 分析好之后会给我们一个反馈, 反馈完了之后, 我们会让我们给它提交一个反馈之后, 它就会做代码的补丁的整理和合入。

74
00:13:56,710 --> 00:14:08,050
然后合入完成之后, 它会给我们一个报告, 就是它合入了多少, 它合入了多少的那个补丁, 然后呢每个补丁合入的那个结果是什么样子的, 然后呢它的提交链接是什么。

75
00:14:08,610 --> 00:14:13,569
那这样的话, 你在人工就可以让你做一个记录的归档, 或者说是再进行一次确认就 OK 了。

76
00:14:14,539 --> 00:14:15,539
好。

77
00:14:15,539 --> 00:14:28,390
然后最终的话, 我们落地的一个效果大概是还是比较突出的, 对我们来说, 就是我们每个, 每个月、每个季度都会做一次定量的代码的分析, 就是跟社区去做一个代码的分析。

78
00:14:28,570 --> 00:14:46,680
因为我们需要把那个一些典型的或者说是高危的一些漏洞, 或者说是我们常用到的一些内核模块的一些文件系统啊, IO 啊, 然后呢这些模块的严重问题需要做修复。那其实对我们来说就是一个比较重复性的一个工作, 并且它的那个价值也是比较大的一个工作。

79
00:14:46,920 --> 00:15:12,820
然后分析过程也存在一些不确定性, 然后呢, 它帮我们完成之后的效果的提升的话, 大概有这么几个。一个的话就是它的分析准确率, 其实我们也做了一下回溯, 就是采用一个模型, 就是千万三的时候那个模型, 然后我们分析完了之后, 它的准确率在75%到93%。

80
00:15:12,820 --> 00:15:19,730
然后我们最后综合了几个模型的, 多个模型之后, 它的它的那个覆盖率基本能到, 基本准确率的话基本能到90%以上。然后呢, 第二块的话是效率的一个提升, 效率提升以前的话, 其实每次分析合入的话, 至少就是开发侧一周以上。

81
00:15:19,910 --> 00:15:26,510
然后呢, 在这个落地之后呢, 我们就实现了一到两个小时之内就可以完成实际的工作。

82
00:15:26,510 --> 00:15:32,020
整个的那个合入的效率其实得到了一个数量级的一个提升。

83
00:15:34,359 --> 00:15:35,359
好。

84
00:15:35,359 --> 00:15:40,820
第二块的话就是那个集成测试, 它整体的工作流其实也类似, 只是说它完成的任务会不一样。

85
00:15:40,820 --> 00:15:50,920
Agent 的话就是一个是用例生产, 它目前我们实现的主要还是基于 commit 信息来做用例的生产, 那我们接下来要做的一个事情其实是让它更能理解代码的上下文。

86
00:15:50,920 --> 00:15:56,980
然后根据上下文以及补丁的修复的改动来产生测试建议, 目前的话还是基于 commit 信息来的。

87
00:15:56,980 --> 00:16:10,165
然后用例执行的 Agent 以及用例入库的 Agent, 就是要把用例做一些基线, 以及用例的一个最终的执行, 那它也是通过自动化来完成的。让以前的我们需要人工去写自动化用例之类的这样的一些工作也释放掉了。

88
00:16:11,040 --> 00:16:31,400
第三块的话就是那个 Vmcore 的一些分析, 我们在这个 Vmcore 的分析工具里面呢, 也集成了多个 Agent, 包括一些堆栈的遍历, 包括一些寄存器的解析, 比如说一些 RSP、RIP 之类的堆栈的解析, 以及那个死锁的一些分析, 比如说典型的一些代码栈可能会出现一些死锁, 或者说是一些锁, 那个全局变量的一些静态变量的分析。

89
00:16:31,540 --> 00:16:48,310
它也会做一些这样的一个智能的检测。然后呢, 分析完之后呢, 我们会有一个研判, 会有一个研判 Agent, 研判 Agent 会综合上面的分析结果, 然后会告诉它你这个可能是什原因, 然后下一步的话你应该是以什么方式来解决, 给出一些建议。

90
00:16:48,310 --> 00:16:55,310
然后人工确认它分析对还是不对, 以及我们给它建议是什么, 它会还会做下一次的一个分析。

91
00:16:55,390 --> 00:16:59,885
主要这个过程的话还是需要强调一个人机协同。

92
00:17:01,430 --> 00:17:17,810
然后呢, 整体的话, 我们还是依托于那个 openEuler intelligence 这套架构来做的。openEuler 这套架构呢, 其实给我们带来了还是比较多的便利性的, 比如说对于交互控制层, 我们把它直接集成到了我们的基于 VS Code 实现的一个 Codelet 的那个代码编辑器里面去。

93
00:17:18,290 --> 00:17:32,080
然后呢, 第二个是智能分析层, 我们的基座大模型可以对我们内部的一些, 内部公司内部部署的一个大模型的一些平台, 直接通过 API 调用的方式能够集成进去, 那这样的话也解决了代码安全性的一个问题。

94
00:17:32,340 --> 00:17:38,840
然后最终是一个执行引擎层, 这个引擎层的话就是刚刚说到的一些 Agent 的调度, 然后 MCP 的一些服务。

95
00:17:38,929 --> 00:17:39,929
好。

96
00:17:39,929 --> 00:17:46,880
然后呢, 我们其实认为还是有几条原则可以给大家分享一下。第一个就是我们其实现在还没有追求到一个完全自动化。

97
00:17:46,880 --> 00:18:14,710
这是我们一开始立项的时候, 我们计划的要实现多少 Agent 来完成这个工作。我们其实一开始没有希望能够实现完全的自动化, 希望的是通过人工跟它协同交互的方式来解决解决这些问题。我们的目标是先通过 Agent 来打通一些关键的节点, 但是要把整个流程实现跑通, 把整个流程跑通之后, 然后再去做一些关键节点、关键 Agent 的去做一个效率的提升, 比如说准确率的提升, 或者说它识别效率的提升。

98
00:18:14,710 --> 00:18:23,430
那这样的话, 才能够让我们的整个不断往前去迭代, 流程打通之后, 就能让大家能够看到一个直观的效果, 然后再去做点对点的去做一个优化。

99
00:18:23,690 --> 00:18:31,030
所以一开始的话, 我们并不追求每个节点都完成得非常完美, 可能它有70%、80%以上, 我们就够了, 然后呢, 再通过人工介入的方式去校准它。

100
00:18:31,750 --> 00:19:01,080
然后呢, 最终的话, 我们目前呢也引入了一个角色, 就是监督 Agent 的一个角色, 就是监督 Agent 呢, 其实希望实现的效果就是对它的一些执行 Agent 完成的一些工作去做一个自动的一个校准, 这样的话会避免我们比较多的一些, 比如说刚刚说到的一个模型它可能只有70%、80%, 那我们可能要综合多个模型, 然后再做一些监督 Agent 的方式来对这个执行 Agent 的一个结果再做一轮的一个加强, 那这样的话, 我们后面的那个人工, 人工需要介入的工作的话就会越来越少。

101
00:19:01,880 --> 00:19:04,959
这是我们大概的一些实践的案例, 感谢大家。

102
00:19:16,039 --> 00:19:46,390
感谢孙老师的精彩分享。我们可以看到, 刚才孙老师他们那个团队里面, 一个方面已经用了这个 MCP 的方式应用在他们的那个补丁的 merge, 然后以及这个分析或者自动化测试的这个相关的方式, 已经取得了不错的成果。我们可以看到它的补丁覆盖效率, 这个数据让我很震惊的, 就是从周级到小时级这个概念。第二个准确率其实也有一个75到93的这个不同等级的提升。

103
00:19:46,510 --> 00:20:01,210
所以这个其实为我们这个后面的那个运维啊, 就是个方向, OS 的一个重要的运维方向提供了很好的思路。很欣喜也看到后面有很多的这个这个规划, 所以我们社区可以跟这个孙老师继续合作, 把这块做得更好。
