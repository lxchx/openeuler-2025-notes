{
  "id": "sec_3",
  "index": 2,
  "title": "大模型技术发展带来的新机遇",
  "time_range": "00:06:55,270 - 00:15:08,586",
  "script": "所以我们就想了一些办法。当然，首先还是想讲讲大模型我们用到的它的一些长处吧。\n当然，在介绍大模型之前，还是稍微做一点导入，就是整个系统调优这一块，其实业界其实已经也有很多年了，也有各种工具，不管是数据库的也好，还是Linux的也好。\n我们这边拿的一个对标的就是目前其实在应用大模型之前，应该算是一个最先进的一个优化框架，就是贝叶斯迭代模型这一套。\n它基本上其实也，它的思路其实也是希望基于贝叶斯定理来找到这个函数的一些，就是调优函数的最大值或者最小值。\n然后呢，在这个过程中，它是可以做一轮轮的迭代，上一轮迭代它拿到的这些历史的运行信息，可以指导下一次的优化，来调整你那个参数集的一些取值。\n整体的逻辑其实差不多就是这个图吧，就你将负载特征化之后，你就可以通过那个专家来做一些关键调优参数的一些选型，选了这个范围之后，就可以来训练你这个代理模型。然后代理模型训练出来之后，它就具备了智能来生成这些参数配置方案的一个能力。\n一旦通过它生成这个方案，你就可以通过Agent下发到你的应用节点去做执行，同时通过Agent来采集你这个运行数据。有这个运行数据，其实你又可以传回给后端的这个代理模型来做下一轮的一个校正。\n由此呢，就又可以做新一轮的那个参数下发，就可以形成一个持续的一个自循环，然后最终可以达到就是说你整个环境的那个性能效果比较稳定之后，你的这个调优方案相对来说就应该是比较成熟了。\n刚刚我们说了，那个是我们就是说对标的一个方案，那我们所以还是把，如果我们用这种大模型来做一个综合性的智能调优方案，跟它贝叶斯会有的一些比较性的优势。\n就我们从第二条开始，就是负载感知这一块，其实刚刚那个贝叶斯的整个循环，我们觉得其实它已经初步有一些这种系统感知的能力了，当然它可能没有自动化的能力。所以这一块也是我们想用大模型的一个最大的优势，它就可以实现这种细粒度跟多维度的一些负载的分析，然后由此来识别一些关键的一个性能瓶颈点，就不只是基于一些规则项了。\n参数识别这一块呢，刚刚其实贝叶斯这边刚刚特地提过了，就它可能还是需要专家来筛选这些关键参数，就是你还是依赖，摆脱不了人工的这个束缚。\n而大模型方案这一块其实是我们最看重的，我们希望就是把这些知识形成领域知识沉淀到大模型，不管是基于RAG库还是说基于调优、微调，然后结合这个工作负载，能够自动识别一些关键参数来形成这个参数调优的方案。\n由上面其实就决定下面这个调优范围了，就肯定贝叶斯这边呢，它只能做部分参数的这种，它没办法做到大规模的这种调优。\n而在信创这种全栈调优下面，基本上现在大概有13000多个参数了，所以你如果用人工来调优，其实是做不到的。\n所以我们就还是希望就是说，结合这种领域知识的辅助，能够用大模型来做这种模型方案的输出。\n可解释性我觉得就不太说了，因为两者其实都还是有些解释性问题。\n下面四个方面呢，就最终你会发现就是说，我们贝叶斯的模型，它调优效率，我们觉得已经其实已经算比较快了，就以天级别算吧，那最终你全生命周期算起来应该就是以周了。\n而大模型这边可能相对来说就会快很多，就基本上只要你方案出来，基本上就可以小时级，例如你跑一个晚上基本上就能出来了。\n那整个全生命周期就从你开始调到最终出方案，基本上可能天级别吧。\n下面呢，我们就稍微快速地过一下大模型，我们用到的一些比较技术长处的地方，或者觉得它能有价值的地方。RAG库这个技术应该大家就用得非常熟了，也是最早大模型技术出来想解决这个模型幻觉的一个技术。\n这一块就一方面它非常成熟简单，就各个开发框架基本上都能一件接入，所以它的那个接入成本很低，就成本效益比相对很高。\n也是和企业这种来接入它的一些私有数据嘛，就数据不会跑出去。\n可解释性跟可信度就因为它依赖本身这个知识库，所以相对来说这个是可以想到的。我们还是稍微说一下它的劣势，劣势这里面列到第四块，其实我觉得是最重要的，就是说它比较难以处理这种，还是比较难以处理这种复杂的这种跨领域的这种关联的问题的推理。\n因为它其实本质上还是一个向量检索技术嘛，它并没有太多的利用这个模型的一个推理能力。\n模型微调呢，这是我们第一卷的方案，还是想重点去抓的一个，就是说我们希望通过我们的一些知识的沉淀，能把这个微调的这个模型给训练出来，然后来真正产生这种专业化的价值。\n蒸馏这一块其实是DeepSeek带火的，我们这其实主要是成本方面的一个优势，就如果你把一个大模型通用大模型的能力，有个80%、90%的能够蒸馏到这个小模型，然后让你的部署成本，那就可以大规模的一个降低了。\n你部署成本降低了，那你应用的數量啊、场景啊，自然就可以极大地扩展了。\nMCP的话，应该就我觉得它更多的是帮助大模型来融入整个现有的我们的一些专业的领域能力也好，工具能力也好，把它形成一个整体的方案，所以其实这是一种融合性的技术。\n在第三块我们的方案这边呢，我其实画了一个回环，但这个因为时间比较少了，所以就不展开聊了，刚刚其实已经讲过了。\n基于上面那些技术的优势，我们就整体就大概做了一个多模型的一个架构方案的构想。其实我们希望就是说，整个通用大模型它只是在上面一层，我们可以叫路由解析层，它依托一些输入，你可以对简单问题或者结合RAG库，你可以把一些相对比较简单的或者解答类的问题，把它做一些输出。但是如果更深层次的一些通用的调优的这种任务，我们还是希望它能路由到我们后端的这些领域模型来。\n根据不同的领域模型，来做专业的事情。当然这个其实只是一个示例，实践的目前我们其实还只调优了一个OS的一个领域模型。\n最终方案呢，我们也放了一张图，左边呢是我们想做的一个叫AITune的一个智能的调优系统，它大概分三层，一个上层就是基于这个Copilot其实做的。\n就我们跟华为在联创，就通过它一方面就是说，做一个基准测试跟一个性能采集，然后有了性能采集之后，你的性能指标数据就可以收集给到中间这个Copilot的服务端。\n由它来做一个负载感知，还有参数的一些汇总、瓶颈的分析。但是最终呢，你会汇总这些参数之后，还是得要传到大模型这边，由大模型来生成它的专业的这个参数方案。\n当然这一块我也还是把那个RAG库的这一块也放上来了，因为这一块还是它模型的一个能力，但我们真正核心的其实还是希望大模型能跟小模型形成一个联动，由领域的小模型来输出一个调优的策略。\n右边是我们画的我们自己的一个核心交易系统简图，就除了刚刚那个Tuner Agent和跟我们这个模型层做交互之外，它本身我们也还有一个应用的一个运维的监控平台，来实现整个一个运行的监控跟应用的部署。",
  "summary": "讲者首先对比了传统贝叶斯优化与大模型调优方案，指出大模型在负载感知、参数自动识别和调优效率上具备显著优势。接着，他详细介绍了RAG、模型微调、蒸馏等关键技术，并提出一个多模型协作架构，旨在利用通用大模型路由任务至专业的领域小模型，以实现更高效、智能的全栈系统调优。"
}