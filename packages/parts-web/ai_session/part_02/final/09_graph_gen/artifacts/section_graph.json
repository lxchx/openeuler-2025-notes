{
  "graph_data": {
    "nodes": [
      {
        "id": "p1",
        "label": "架构升级的挑战",
        "category": "Pillar",
        "references": {
          "section_ids": [
            "sec_2"
          ],
          "material_ids": [
            "chunk_00/slide_003",
            "chunk_00/slide_004",
            "chunk_00/slide_005",
            "chunk_00/slide_006"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_003",
            "primary_time_ts": "00:01:53,500",
            "primary_time_ms": 113500
          }
        },
        "parent": null,
        "summary": "在国产化替代（信创）背景下，核心系统改造面临三大挑战：基础软硬件差距带来的不确定性、研发与运维分工断点导致的组织资源空洞，以及大模型技术现阶段存在的“幻觉”问题。"
      },
      {
        "id": "d1_1",
        "label": "基础软硬件差距",
        "category": "Problem",
        "references": {
          "section_ids": [
            "sec_2"
          ],
          "material_ids": [
            "chunk_00/slide_004"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_004",
            "primary_time_ts": "00:02:31,500",
            "primary_time_ms": 151500
          }
        },
        "parent": "p1",
        "summary": "硬件层面（CPU、网卡等）与国外差距显著，依赖底层工艺突破。软件层面（操作系统、JDK）差距较小，已初步形成“开源+商业”闭环，但数据库在集中式场景下仍有欠缺。"
      },
      {
        "id": "d1_2",
        "label": "组织架构挑战：调优职责缺失",
        "category": "Problem",
        "references": {
          "section_ids": [
            "sec_2"
          ],
          "material_ids": [
            "chunk_00/slide_005"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_005",
            "primary_time_ts": "00:04:42,500",
            "primary_time_ms": 282500
          }
        },
        "parent": "p1",
        "summary": "传统企业中开发与运维团队职责分离，导致在信创替代过程中，系统性能调优成为一个无人负责的中间地带，阻碍技术从“可用”向“好用”演进。"
      },
      {
        "id": "d1_3",
        "label": "大模型的“幻觉”问题",
        "category": "Problem",
        "references": {
          "section_ids": [
            "sec_2"
          ],
          "material_ids": [
            "chunk_00/slide_006"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_006",
            "primary_time_ts": "00:05:41,500",
            "primary_time_ms": 341500
          }
        },
        "parent": "p1",
        "summary": "大模型作为新技术自身存在不确定性，特别是“幻觉”问题，如逻辑关系谬误和内容重复，对方案的准确性和可靠性构成挑战。"
      },
      {
        "id": "p2",
        "label": "大模型带来的机遇",
        "category": "Pillar",
        "references": {
          "section_ids": [
            "sec_3",
            "sec_2"
          ],
          "material_ids": [
            "chunk_00/slide_007",
            "chunk_00/slide_008",
            "chunk_00/slide_009",
            "chunk_00/slide_010",
            "chunk_00/slide_011",
            "chunk_00/slide_012",
            "chunk_00/slide_013"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_007",
            "primary_time_ts": "00:06:50,500",
            "primary_time_ms": 410500
          }
        },
        "parent": null,
        "summary": "大模型技术为系统调优提供了新机遇。相较于传统贝叶斯优化，LLM在负载感知、参数自动识别和效率上优势显著。其实现依赖RAG、模型微调、蒸馏和MCP等多项关键技术。"
      },
      {
        "id": "d2_1",
        "label": "LLM调优方案优势",
        "category": "Concept",
        "references": {
          "section_ids": [
            "sec_3"
          ],
          "material_ids": [
            "chunk_00/slide_008",
            "chunk_00/slide_009"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_009",
            "primary_time_ts": "00:08:39,500",
            "primary_time_ms": 519500
          }
        },
        "parent": "p2",
        "summary": "与传统的贝叶斯优化方案相比，基于大模型的调优方案在负载感知、参数自动识别、调优范围和调优效率上均表现出显著优势，能够应对全栈环境下海量的参数，并将调优周期从周缩短至天。"
      },
      {
        "id": "d2_2",
        "label": "核心技术: RAG",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_3"
          ],
          "material_ids": [
            "chunk_00/slide_010"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_010",
            "primary_time_ts": "00:10:58,500",
            "primary_time_ms": 658500
          }
        },
        "parent": "p2",
        "summary": "检索增强生成（RAG）技术通过外挂知识库解决大模型的幻觉问题，提升回答准确性。其优势在于技术成熟、成本低、保障私有数据安全，但难以处理复杂的跨领域推理。"
      },
      {
        "id": "d2_3",
        "label": "核心技术: 模型微调",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_3"
          ],
          "material_ids": [
            "chunk_00/slide_011"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_011",
            "primary_time_ts": "00:12:04,500",
            "primary_time_ms": 724500
          }
        },
        "parent": "p2",
        "summary": "模型微调（Fine-tuning）旨在通过在特定任务数据上训练模型，将专业知识沉淀其中，使其具备特定领域的专业化能力，从而产生真正的业务价值。"
      },
      {
        "id": "d2_4",
        "label": "核心技术: 模型蒸馏",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_3"
          ],
          "material_ids": [
            "chunk_00/slide_012"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_012",
            "primary_time_ts": "00:13:03,500",
            "primary_time_ms": 783500
          }
        },
        "parent": "p2",
        "summary": "模型蒸馏（Distillation）通过将通用大模型的能力迁移到更小的模型上，显著降低部署成本，从而极大地扩展模型的应用数量和场景。"
      },
      {
        "id": "d2_5",
        "label": "核心技术: MCP",
        "category": "Technology",
        "references": {
          "section_ids": [
            "sec_3"
          ],
          "material_ids": [
            "chunk_00/slide_013"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_013",
            "primary_time_ts": "00:14:00,500",
            "primary_time_ms": 840500
          }
        },
        "parent": "p2",
        "summary": "多模型协作（MCP）是一种融合性技术，旨在帮助大模型融入现有的专业领域能力和工具集，将它们整合成一个协同工作的整体方案。"
      },
      {
        "id": "p3",
        "label": "智能调优方案与实践",
        "category": "Pillar",
        "references": {
          "section_ids": [
            "sec_3",
            "sec_4"
          ],
          "material_ids": [
            "chunk_00/slide_014",
            "chunk_00/slide_015",
            "chunk_00/slide_016",
            "chunk_00/slide_017",
            "chunk_00/slide_018",
            "chunk_00/slide_019",
            "chunk_00/slide_020",
            "chunk_00/slide_021"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_014",
            "primary_time_ts": "00:14:55,500",
            "primary_time_ms": 895500
          }
        },
        "parent": null,
        "summary": "提出了一个基于多模型协作的智能调优方案。该方案通过构建RAG资产库，并采用“通用大模型路由+领域小模型决策”的架构，赋能研发团队。初步实践在接入网关和期权系统上取得了显著的性能提升。"
      },
      {
        "id": "d3_1",
        "label": "多模型协作架构 (AITune)",
        "category": "Concept",
        "references": {
          "section_ids": [
            "sec_3"
          ],
          "material_ids": [
            "chunk_00/slide_016",
            "chunk_00/slide_017"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_016",
            "primary_time_ts": "00:15:13,500",
            "primary_time_ms": 913500
          }
        },
        "parent": "p3",
        "summary": "构想了一套名为AITune的多模型协作架构。上层由通用大模型负责任务路由和简单问答，下层由多个专业的领域小模型（如OS调优模型）负责执行具体的调优任务，实现优势互补。"
      },
      {
        "id": "d3_2",
        "label": "RAG资产库规划",
        "category": "Concept",
        "references": {
          "section_ids": [
            "sec_4"
          ],
          "material_ids": [
            "chunk_00/slide_018"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_018",
            "primary_time_ts": "00:15:58,500",
            "primary_time_ms": 958500
          }
        },
        "parent": "p3",
        "summary": "规划构建一个基于RAG的资产库，整合操作系统、数据库、中间件等核心技术资产，为智能调优提供知识支持，并赋能研发团队在开发早期介入性能调优。"
      },
      {
        "id": "d3_3",
        "label": "初步调优效果",
        "category": "Result",
        "references": {
          "section_ids": [
            "sec_4"
          ],
          "material_ids": [
            "chunk_00/slide_020",
            "chunk_00/slide_021"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_020",
            "primary_time_ts": "00:16:44,500",
            "primary_time_ms": 1004500
          }
        },
        "parent": "p3",
        "summary": "初步实践展示了显著效果：接入网关性能提升13.6%，期权系统性能相较基线有明显改善。证明通过精细化调优可以有效弥补与X86平台的性能差距。"
      },
      {
        "id": "p4",
        "label": "生态共建与展望",
        "category": "Pillar",
        "references": {
          "section_ids": [
            "sec_5"
          ],
          "material_ids": [
            "chunk_00/slide_022",
            "chunk_00/slide_023",
            "chunk_00/slide_024"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_022",
            "primary_time_ts": "00:17:43,500",
            "primary_time_ms": 1063500
          }
        },
        "parent": null,
        "summary": "展望未来，计划持续优化专有模型、提升平台易用性，并探索持续在线学习。同时，提出“云端训练、本地推理”的创新模式以解决中小企业成本与数据安全问题，并呼吁业界同仁协同合作，共建技术生态。"
      },
      {
        "id": "d4_1",
        "label": "下一阶段研究计划",
        "category": "Concept",
        "references": {
          "section_ids": [
            "sec_5"
          ],
          "material_ids": [
            "chunk_00/slide_023"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_023",
            "primary_time_ts": "00:17:47,500",
            "primary_time_ms": 1067500
          }
        },
        "parent": "p4",
        "summary": "下一阶段计划包括：持续优化专有领域模型、与华为联创提升平台易用性、探索持续在线学习以解决模型幻觉问题，以及探索云端训练与本地推理的混合模式。"
      },
      {
        "id": "d4_2",
        "label": "云端训练与本地推理模式",
        "category": "Concept",
        "references": {
          "section_ids": [
            "sec_5"
          ],
          "material_ids": [
            "chunk_00/slide_024"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_024",
            "primary_time_ts": "00:18:50,500",
            "primary_time_ms": 1130500
          }
        },
        "parent": "p4",
        "summary": "提出一种创新的混合模式，由云端平台负责计算密集的训练任务，企业端负责推理应用。通过数据脱敏、专有算力池等技术，旨在解决中小企业模型训练成本高昂和数据安全之间的矛盾。"
      },
      {
        "id": "d4_3",
        "label": "生态共建呼吁",
        "category": "Concept",
        "references": {
          "section_ids": [
            "sec_5"
          ],
          "material_ids": [
            "chunk_00/slide_024"
          ],
          "highlight": {
            "primary_material_id": "chunk_00/slide_024",
            "primary_time_ts": "00:18:50,500",
            "primary_time_ms": 1130500
          }
        },
        "parent": "p4",
        "summary": "由于国产基础软硬件平台与国外存在差距，呼吁业界同仁协同合作，共同使用和打磨国产化平台，通过广泛应用加速产品成熟，共建繁荣的技术生态。"
      }
    ],
    "edges": [
      {
        "source": "p1",
        "target": "p2",
        "relation_type": "causal",
        "label": "催生机遇"
      },
      {
        "source": "p2",
        "target": "p3",
        "relation_type": "sequential",
        "label": "指导方案设计"
      },
      {
        "source": "p3",
        "target": "p4",
        "relation_type": "sequential",
        "label": "引出未来展望"
      },
      {
        "source": "d1_1",
        "target": "d1_2",
        "relation_type": "parallel",
        "label": "并列挑战"
      },
      {
        "source": "d1_2",
        "target": "d1_3",
        "relation_type": "parallel",
        "label": "并列挑战"
      },
      {
        "source": "d2_2",
        "target": "d2_3",
        "relation_type": "parallel",
        "label": "核心技术"
      },
      {
        "source": "d2_3",
        "target": "d2_4",
        "relation_type": "parallel",
        "label": "核心技术"
      },
      {
        "source": "d2_4",
        "target": "d2_5",
        "relation_type": "parallel",
        "label": "核心技术"
      },
      {
        "source": "d3_1",
        "target": "d3_2",
        "relation_type": "parallel",
        "label": "方案组件"
      },
      {
        "source": "d3_1",
        "target": "d3_3",
        "relation_type": "causal",
        "label": "产出"
      },
      {
        "source": "d4_1",
        "target": "d4_2",
        "relation_type": "parallel",
        "label": "并列计划"
      },
      {
        "source": "d4_2",
        "target": "d4_3",
        "relation_type": "parallel",
        "label": "并列计划"
      }
    ]
  },
  "sections": [
    {
      "id": "sec_1",
      "index": 0,
      "title": "开场与自我介绍",
      "time_range": "00:00:00,870 - 00:01:52,205",
      "summary": "主持人介绍讲者黄俊及其分享主题《沙上聚塔：基于LLM的核心系统软件栈智能调优探索》。随后，黄俊进行自我介绍，阐述了本次分享的目标，即探索如何利用大模型技术在信创领域的核心系统中弥补性能差距。他详细介绍了自己的职业背景，包括在招商证券担任核心系统架构师、参与 openEuler 社区、荣获云原生MVP以及在全栈开发和DevOps方面的丰富经验。",
      "refined_script": "# 沙上聚塔：基于LLM的核心系统软件栈智能调优探索\n\n## 1. 分享目标\n\n本次分享旨在探索如何运用大语言模型（LLM）技术，针对国产化替代（信创）领域的核心系统进行性能调优，以弥补其与现有成熟方案之间的性能差距。\n\n## 2. 讲师介绍\n\n**黄俊**，招商证券股份有限公司核心系统架构师。\n\n### 核心职责\n\n- 核心系统架构师\n- 公司级 DevOps 效能教练\n\n### 技术背景与社区贡献\n\n- **开源社区**：开放原子开源基金会 openEuler 社区 AI 联合工作组（SIG AI）成员。\n- **云原生**：连续三年荣获创原会（由 CNCF、华为、信通院联合组织）年度云原生 MVP。\n- **软件研发**：具备全栈开发经验，覆盖前端（Android, iOS, H5）及后端（.NET, Java）技术栈。\n- **DevOps**：拥有超过十年的团队领导经验，实践过瀑布模型、Scrum 敏捷以及双速 IT 团队模式。\n- **技术布道**：公司内部认证培训讲师，曾受邀担任 TWT 企业 IT 社区特邀技术主持。",
      "original_script": "下面有请招商证券股份有限公司核心系统架构师黄俊先生，为我们带来《沙上聚塔：基于LLM的核心系统软件栈智能调优探索》。大家欢迎。\n大家好，我是来自招商证券的黄俊。这次我给大家带来的分享，是想基于大模型技术，在我们一些核心系统，也就是国产化替代，即信创领域，做一些性能差距的补齐探索。\n首先，照例还是来一个自我介绍。我在招商证券目前共职，担任核心系统架构师，也兼任公司的DevOps效能教练。主要技术标签列了五个：一是有幸参与开放原子开源基金会openEuler社区AI联合工作组，成为其中一员。二是过去三年，有幸在创原会当选年度云原生MVP。创原会是全球云原生计算基金会、华为和信通院组织的云原生技术交流组织。如果大家有兴趣也可以参加。在软件栈方面，我一开始是做前端开发出身，做过安卓、iOS、H5，后来也从事过.NET、Java后台开发。在DevOps方面，拥有十多年的带队经验，对过去的瀑布式模型，以及现在的Scrum敏捷双速团队，都有实践经验。最后，我是公司的内部培训认证讲师，也曾受邀担任TWT企业IT社区特邀技术主持。",
      "start_ms": 870,
      "end_ms": 112205,
      "material_ids": [
        "chunk_00/slide_001",
        "chunk_00/slide_002"
      ],
      "summary_hint": "主持人介绍讲者黄俊，随后讲者进行自我介绍，并引出本次分享的主题：基于大模型技术在信创领域做性能差距的补齐探索。",
      "lead_text": "下面有请招商证券股份有限公司核心系统架构师黄俊先生，",
      "tail_text": "最后，我是公司的内部培训认证讲师，也曾受邀担任TWT企业IT社区特邀技术主持。",
      "text_span": {
        "start": 0,
        "end": 12
      }
    },
    {
      "id": "sec_2",
      "index": 1,
      "title": "全面架构升级的痛点与挑战",
      "time_range": "00:01:54,410 - 00:06:54,970",
      "summary": "本节探讨了国产化替代（信创）过程中面临的挑战。首先，硬件层面差距较大，而软件层面已初步形成开源与商业的闭环。其次，组织架构上开发与运维的分离导致了系统调优职责的缺失。最后，虽然大模型技术为解决调优问题提供了新机遇，但其自身的“幻觉”问题（如逻辑错误和内容重复）也带来了新的不确定性。",
      "refined_script": "# 全面架构升级的痛点与挑战\n\n## 1. 国产化替代（信创）的现状与挑战\n\n在国产化替代全面落地的过程中，主要面临硬件、软件及组织层面的挑战。\n\n### 1.1. 硬件层面：基础工艺存在差距\n\n硬件层面与国外竞品相比，差距依然显著，短期内需要技术突破。这主要涉及依赖底层先进制造工艺的核心组件：\n\n- CPU\n- 网卡\n- 低时延交换机\n- 存储\n\n### 1.2. 软件层面：开源与商业闭环初步形成\n\n软件层面的差距相对较小，特别是在操作系统和JDK领域，已经初步形成了“开源社区+商业发行版”的有效闭环模式。该模式通过商业收益反哺开源社区，促进生态发展。\n\n- **操作系统**：以 openEuler 操作系统生态底座为例，统信（Tongxin）、麒麟（Kylin）等厂商在此基础上推出商业增强发行版。\n- **JDK**：以毕昇 JDK（BiSheng JDK）的开源底座为例，宝兰德（Baoland）、东方通（Oriental Tong）等 ISV 厂商提供增强型商业方案。\n\n### 1.3. 数据库层面：场景分化明显\n\n数据库领域根据应用场景的不同，技术成熟度存在差异。\n\n| 场景 | 技术水平与案例 | 挑战与差距 |\n| :--- | :--- | :--- |\n| **分布式场景** | 技术水平在国际上已并驾齐驱，甚至领先。例如，OceanBase 已在“双十一”等超高并发场景下得到多年验证。 | - |\n| **集中式场景** | 以替代 Oracle 为目标时，仍有差距。虽然性能可通过软硬件协同研调基本抹平，但在以下方面存在明显欠缺：<br>- 产品成熟度<br>- 上下游工具链<br>- 社区生态规模 | 尽管存在差距，但已具备从0到1替代的基础产品可用性。 |\n\n## 2. 组织架构的挑战：系统调优职责缺失\n\n当国产化替代从“可用”（0到1）向“好用”和“规模化推广”（1到100）演进时，组织层面的挑战凸显出来。\n\n- **传统职责分离**：在传统企业架构中，开发与运维团队严格分离。\n  - **开发团队**：侧重业务功能实现。\n  - **运维团队**：注重系统运行稳定性。\n- **职责缺口**：在信创替代过程中，系统性能调优成为一个无人负责的中间地带，阻碍了技术的深度应用和推广。\n\n## 3. 大模型带来的机遇与不确定性\n\n### 3.1. 机遇：弥补调优能力缺口\n\n大模型技术为解决上述调优职责缺失问题提供了新的机遇。其核心思路是：\n\n> 将资深专家的调优经验沉淀到模型库中，通过智能化方案加以复用，从而弥补组织架构中的能力缺口。\n\n### 3.2. 不确定性：大模型的“幻觉”问题\n\n大模型作为一项新技术，其自身的不确定性，特别是“幻觉”（Hallucination）问题，带来了新的挑战。主要表现为：\n\n- **逻辑关系谬误**：模型可能无法准确识别内容之间的逻辑从属关系，例如将子要点与主标题并列处理。这种错误超出了常规的语言逻辑范畴，难以通过标准检索算法识别。\n- **内容重复**：模型可能生成重复的文本。这类错误非常明显，即便是普通用户也能轻易识别，对方案的可用性构成致命影响。\n\n## 4. 结论与展望\n\n我们的目标是充分利用大模型在知识整合与复用方面的优势，同时必须设计有效机制来规避和消除其“幻觉”等劣势，以确保智能化方案的准确性和可靠性。",
      "original_script": "本次分享分为四块。\n首先会讲一下在国产化替代全面落地的过程中，我们遇到的一些痛点与挑战。\n第二，讲解大模型技术出现后，为我们的技术方案层面带来的新机遇。\n第三，分享我们设计的智能调优方案的细节与创新点。\n第四，基于信创技术生态，想与大家一起做一些创议和共建。\n这部分因为时间有限，我们就不细讲了，字和面都比较多。\n做信创的同学应该比较熟悉，硬件层面，如CPU、网卡、低时延交换机、存储等，与国外竞品相比，差距仍不小。\n因为涉及底层先进的制程工艺，短期内需要突破。\n在软件层面，差距相对更小，特别是操作系统、JDK等。在国内，开源与商业的有效闭环模式已经跑通。以openEuler为例，它是一个操作系统的生态底座，上面有统信、麒麟等商业发行版进行增强。\n通过商业增强发行版获得持续的商业收益后，可以反馈给开源社区，从而使整个生态全面开花。\n这在JDK领域也已初现苗头。毕昇JDK的底座是开源的，上面有ISV厂商做增强发行，比如宝兰德、东方通等，都有这方面的方案。\n下面我只讲一下数据库。我们从两个方面看，一是分布式场景。\n以OceanBase为例，它在“双十一”等超高并发场景下，已经历练多年。\n其技术水平放到国际上比较，即便不领先，也至少是并驾齐驱的。\n但在集中式场景，若以替代Oracle为目标，可能仍有差距。\n虽然性能可以通过软硬件协同研调基本抹平，但在产品成熟度、上下游工具链以及社区生态规模方面，确实还有比较大的欠缺。\n上面这些虽然有差距，但是你如果要做0到1的替代，我觉得还是至少有产品可用。\n这一块是我们发现，如果你要做全面的铺广推广，就是你要做到从1到10，甚至从10到100的效果，这一块我觉得是一个组织层面的差距。就是在传统我们的企业架构之中，开发跟运维它是严格分离的。\n所以一般看到系统开发可能侧重业务开发，运维会注重整个系统的运行稳定性。\n所以这里面，如果要做信创替代，中间就有一块调优的职责没人做。\n这其实就是我们想做这个方案的初衷。我们希望借助这种大模型的技术，能把这些专家经验沉淀到模型库中，然后来加以复用，由此来弥补中间这一块调优职责的缺失问题。\n当然，因为大模型技术也非常新，它还是有一些不确定性因素的，表现最突出的其实就是幻觉。\n我这里恰好那天我想把这个主题让豆包AI生成一个胶片。\n其实整体效果大家可以看到，应该已经达到至少我这边80%到90%的预期了。但是很不幸，就是下面这里有两个地方还是有些谬误。\n就第一个就是，它把忠实性幻觉下面一些说明内容跟这个忠实性幻觉这个一级标题做了一个并列。其实我们知道，这种是不是一个并列，是一个从属的关系。\n而这种逻辑关系，其实你通过语言模型，你那些检索算法其实是不一定能识别到的，因为它已经超出了常规的这种语言逻辑了。\n第二块呢就是说，就比较明显了，就是一个内容的一个重复。这种相对来说就对我们就比较致命了，因为这是一个非常明显，普通用户也能识别出来的错误。\n但是我们就是说，我们既想用这个大模型的一些优势，同时呢，还是得想办法要摒弃它的一些劣势。",
      "start_ms": 114410,
      "end_ms": 414970,
      "material_ids": [
        "chunk_00/slide_003",
        "chunk_00/slide_004",
        "chunk_00/slide_005",
        "chunk_00/slide_006"
      ],
      "summary_hint": "探讨国产化替代中，核心系统改造面临的软硬件差距、组织架构和模型幻觉三大挑战。",
      "notes": "讲者根据议程第一部分，阐述了在国产化替代背景下，核心系统改造面临的三大挑战：基础软硬件差距带来的不确定性、研发与运维分工断点导致的资源空洞，以及大模型现阶段的幻觉问题。",
      "lead_text": "本次分享分为四块。",
      "tail_text": "但是我们就是说，我们既想用这个大模型的一些优势，同时呢，还是得想办法要摒弃它的一些劣势。",
      "text_span": {
        "start": 13,
        "end": 40
      }
    },
    {
      "id": "sec_3",
      "index": 2,
      "title": "大模型技术发展带来的新机遇",
      "time_range": "00:06:55,270 - 00:15:08,586",
      "summary": "讲者首先对比了传统贝叶斯优化与大模型调优方案，指出大模型在负载感知、参数自动识别和调优效率上具备显著优势。接着，他详细介绍了RAG、模型微调、蒸馏等关键技术，并提出一个多模型协作架构，旨在利用通用大模型路由任务至专业的领域小模型，以实现更高效、智能的全栈系统调优。",
      "refined_script": "# 大模型技术在系统调优领域的应用与机遇\n\n## 1. 背景：传统系统调优方案回顾\n\n在引入大模型之前，系统调优领域已存在多种成熟的工具与框架。其中，贝叶斯优化（Bayesian Optimization）是业界较为先进的代表性方案。\n\n### 1.1 贝叶斯优化框架\n\n该框架的核心思想是基于贝叶斯定理，通过迭代逼近的方式寻找调优函数的最优解（最大值或最小值）。其工作流程具备一定的自循环与持续优化能力。\n\n**工作流程：**\n\n1.  **负载特征化**：对系统当前的工作负载进行分析和定义。\n2.  **参数筛选**：由领域专家手动选择关键的调优参数及其取值范围。\n3.  **训练代理模型**：基于选定的参数范围训练一个代理模型（Proxy Model）。\n4.  **生成配置**：代理模型智能生成参数配置方案。\n5.  **部署与采集**：通过 Agent 将配置方案下发至应用节点执行，并同步采集运行时的数据（如性能指标）。\n6.  **反馈与校正**：将采集到的运行数据反馈给代理模型，用于指导下一轮的迭代优化。\n7.  **持续循环**：重复步骤 4-6，形成持续的自循环调优，直至系统性能达到稳定且理想的状态。\n\n## 2. 大模型调优方案 vs. 贝叶斯优化\n\n将大模型技术应用于系统调优，与传统的贝叶斯优化方案相比，在多个维度上展现出显著优势。\n\n| 维度 | 贝叶斯优化方案 | 大模型调优方案 (核心优势) |\n| :--- | :--- | :--- |\n| **负载感知** | 初步具备系统感知能力，但自动化程度低。 | 可实现细粒度、多维度的负载分析，自动识别关键性能瓶颈，超越基于规则的限制。 |\n| **参数识别** | 强依赖领域专家手动筛选关键参数，无法摆脱人工束缚。 | **核心价值所在**。通过 RAG 或模型微调沉淀领域知识，结合工作负载**自动识别**关键参数。 |\n| **调优范围** | 仅能处理部分参数，无法应对大规模参数空间。 | 能够应对全栈环境下海量的参数（如信创环境下超 13,000 个），这是人工或传统方法无法实现的。 |\n| **调优效率** | 调优过程以天为单位，整个生命周期（从开始到出具方案）以周为单位。 | 方案生成速度快，可达小时级（如夜间运行）；全生命周期可缩短至天级。 |\n| **可解释性** | 存在一定的可解释性问题。 | 同样存在可解释性挑战，但可通过 RAG 等技术部分缓解。 |\n\n## 3. 核心技术解析\n\n大模型调优方案的实现依赖于一系列关键技术。\n\n### 3.1 检索增强生成 (RAG)\n\n-   **目的**：解决大模型的幻觉问题，提升回答的准确性。\n-   **优势**：\n    -   技术成熟，集成成本低，开发框架支持良好。\n    -   适用于企业私有数据场景，保障数据安全。\n    -   依赖知识库，具备较好的可解释性与可信度。\n-   **劣势**：\n    -   本质上是向量检索技术，难以处理复杂的、跨领域的关联推理问题。\n\n### 3.2 模型微调 (Fine-tuning)\n\n-   **目的**：通过沉淀专业知识来训练模型，使其具备特定领域的专业化能力，产生真正的业务价值。\n\n### 3.3 模型蒸馏 (Distillation)\n\n-   **目的**：显著降低成本。\n-   **方法**：将通用大模型约 80%-90% 的能力迁移（蒸馏）到一个更小的模型上。\n-   **价值**：大幅降低部署成本，从而极大地扩展了模型的应用数量和场景。\n\n### 3.4 多智能体/工具融合 (MCP)\n\n-   **定位**：一种融合性技术。\n-   **作用**：帮助大模型融入现有的专业领域能力和工具集，将其整合成一个协同工作的整体方案。\n\n## 4. 架构构想：多模型协作的全栈智能调优\n\n基于上述技术优势，我们构想了一套多模型协作的智能调优架构。\n\n### 4.1 整体架构：路由层 + 领域模型层\n\n该架构分为上下两层：\n\n1.  **上层 - 路由解析层**：\n    -   由一个**通用大模型**担当，作为任务入口和分发器。\n    -   对于简单问题，可直接结合 RAG 知识库进行解答。\n    -   对于复杂的专业调优任务，则将其**路由**到后端的领域模型。\n\n2.  **下层 - 领域模型层**：\n    -   由多个**专业的领域小模型**组成（如操作系统调优模型、数据库调优模型等）。\n    -   每个小模型负责处理自己擅长领域的专业任务。\n\n> **实践现状**：目前该架构仍处于构想和初步实践阶段，已完成一个操作系统（OS）领域的调优模型。\n\n### 4.2 AITune 智能调优系统实践\n\n我们将上述构想具体化为一个名为 `AITune` 的智能调优系统，其工作流程涉及三层协作：\n\n1.  **采集与交互层 (Copilot 前端)**：\n    -   与华为联创，提供类似 Copilot 的交互界面。\n    -   负责执行基准测试和性能数据采集。\n\n2.  **分析与汇总层 (Copilot 服务端)**：\n    -   接收前端采集的性能指标数据。\n    -   进行负载感知、参数汇总和性能瓶颈分析。\n\n3.  **决策与生成层 (大/小模型)**：\n    -   接收服务端分析后的汇总信息。\n    -   **核心联动**：通用大模型（可结合 RAG）与领域小模型协同工作。\n    -   最终由**领域小模型**输出专业的、可执行的调优策略。\n\n该系统通过 `Tuner Agent` 与模型层进行交互，并与现有的应用运维监控平台集成，实现从监控、分析到部署的闭环智能调优。",
      "original_script": "所以我们就想了一些办法。当然，首先还是想讲讲大模型我们用到的它的一些长处吧。\n当然，在介绍大模型之前，还是稍微做一点导入，就是整个系统调优这一块，其实业界其实已经也有很多年了，也有各种工具，不管是数据库的也好，还是Linux的也好。\n我们这边拿的一个对标的就是目前其实在应用大模型之前，应该算是一个最先进的一个优化框架，就是贝叶斯迭代模型这一套。\n它基本上其实也，它的思路其实也是希望基于贝叶斯定理来找到这个函数的一些，就是调优函数的最大值或者最小值。\n然后呢，在这个过程中，它是可以做一轮轮的迭代，上一轮迭代它拿到的这些历史的运行信息，可以指导下一次的优化，来调整你那个参数集的一些取值。\n整体的逻辑其实差不多就是这个图吧，就你将负载特征化之后，你就可以通过那个专家来做一些关键调优参数的一些选型，选了这个范围之后，就可以来训练你这个代理模型。然后代理模型训练出来之后，它就具备了智能来生成这些参数配置方案的一个能力。\n一旦通过它生成这个方案，你就可以通过Agent下发到你的应用节点去做执行，同时通过Agent来采集你这个运行数据。有这个运行数据，其实你又可以传回给后端的这个代理模型来做下一轮的一个校正。\n由此呢，就又可以做新一轮的那个参数下发，就可以形成一个持续的一个自循环，然后最终可以达到就是说你整个环境的那个性能效果比较稳定之后，你的这个调优方案相对来说就应该是比较成熟了。\n刚刚我们说了，那个是我们就是说对标的一个方案，那我们所以还是把，如果我们用这种大模型来做一个综合性的智能调优方案，跟它贝叶斯会有的一些比较性的优势。\n就我们从第二条开始，就是负载感知这一块，其实刚刚那个贝叶斯的整个循环，我们觉得其实它已经初步有一些这种系统感知的能力了，当然它可能没有自动化的能力。所以这一块也是我们想用大模型的一个最大的优势，它就可以实现这种细粒度跟多维度的一些负载的分析，然后由此来识别一些关键的一个性能瓶颈点，就不只是基于一些规则项了。\n参数识别这一块呢，刚刚其实贝叶斯这边刚刚特地提过了，就它可能还是需要专家来筛选这些关键参数，就是你还是依赖，摆脱不了人工的这个束缚。\n而大模型方案这一块其实是我们最看重的，我们希望就是把这些知识形成领域知识沉淀到大模型，不管是基于RAG库还是说基于调优、微调，然后结合这个工作负载，能够自动识别一些关键参数来形成这个参数调优的方案。\n由上面其实就决定下面这个调优范围了，就肯定贝叶斯这边呢，它只能做部分参数的这种，它没办法做到大规模的这种调优。\n而在信创这种全栈调优下面，基本上现在大概有13000多个参数了，所以你如果用人工来调优，其实是做不到的。\n所以我们就还是希望就是说，结合这种领域知识的辅助，能够用大模型来做这种模型方案的输出。\n可解释性我觉得就不太说了，因为两者其实都还是有些解释性问题。\n下面四个方面呢，就最终你会发现就是说，我们贝叶斯的模型，它调优效率，我们觉得已经其实已经算比较快了，就以天级别算吧，那最终你全生命周期算起来应该就是以周了。\n而大模型这边可能相对来说就会快很多，就基本上只要你方案出来，基本上就可以小时级，例如你跑一个晚上基本上就能出来了。\n那整个全生命周期就从你开始调到最终出方案，基本上可能天级别吧。\n下面呢，我们就稍微快速地过一下大模型，我们用到的一些比较技术长处的地方，或者觉得它能有价值的地方。RAG库这个技术应该大家就用得非常熟了，也是最早大模型技术出来想解决这个模型幻觉的一个技术。\n这一块就一方面它非常成熟简单，就各个开发框架基本上都能一件接入，所以它的那个接入成本很低，就成本效益比相对很高。\n也是和企业这种来接入它的一些私有数据嘛，就数据不会跑出去。\n可解释性跟可信度就因为它依赖本身这个知识库，所以相对来说这个是可以想到的。我们还是稍微说一下它的劣势，劣势这里面列到第四块，其实我觉得是最重要的，就是说它比较难以处理这种，还是比较难以处理这种复杂的这种跨领域的这种关联的问题的推理。\n因为它其实本质上还是一个向量检索技术嘛，它并没有太多的利用这个模型的一个推理能力。\n模型微调呢，这是我们第一卷的方案，还是想重点去抓的一个，就是说我们希望通过我们的一些知识的沉淀，能把这个微调的这个模型给训练出来，然后来真正产生这种专业化的价值。\n蒸馏这一块其实是DeepSeek带火的，我们这其实主要是成本方面的一个优势，就如果你把一个大模型通用大模型的能力，有个80%、90%的能够蒸馏到这个小模型，然后让你的部署成本，那就可以大规模的一个降低了。\n你部署成本降低了，那你应用的數量啊、场景啊，自然就可以极大地扩展了。\nMCP的话，应该就我觉得它更多的是帮助大模型来融入整个现有的我们的一些专业的领域能力也好，工具能力也好，把它形成一个整体的方案，所以其实这是一种融合性的技术。\n在第三块我们的方案这边呢，我其实画了一个回环，但这个因为时间比较少了，所以就不展开聊了，刚刚其实已经讲过了。\n基于上面那些技术的优势，我们就整体就大概做了一个多模型的一个架构方案的构想。其实我们希望就是说，整个通用大模型它只是在上面一层，我们可以叫路由解析层，它依托一些输入，你可以对简单问题或者结合RAG库，你可以把一些相对比较简单的或者解答类的问题，把它做一些输出。但是如果更深层次的一些通用的调优的这种任务，我们还是希望它能路由到我们后端的这些领域模型来。\n根据不同的领域模型，来做专业的事情。当然这个其实只是一个示例，实践的目前我们其实还只调优了一个OS的一个领域模型。\n最终方案呢，我们也放了一张图，左边呢是我们想做的一个叫AITune的一个智能的调优系统，它大概分三层，一个上层就是基于这个Copilot其实做的。\n就我们跟华为在联创，就通过它一方面就是说，做一个基准测试跟一个性能采集，然后有了性能采集之后，你的性能指标数据就可以收集给到中间这个Copilot的服务端。\n由它来做一个负载感知，还有参数的一些汇总、瓶颈的分析。但是最终呢，你会汇总这些参数之后，还是得要传到大模型这边，由大模型来生成它的专业的这个参数方案。\n当然这一块我也还是把那个RAG库的这一块也放上来了，因为这一块还是它模型的一个能力，但我们真正核心的其实还是希望大模型能跟小模型形成一个联动，由领域的小模型来输出一个调优的策略。\n右边是我们画的我们自己的一个核心交易系统简图，就除了刚刚那个Tuner Agent和跟我们这个模型层做交互之外，它本身我们也还有一个应用的一个运维的监控平台，来实现整个一个运行的监控跟应用的部署。",
      "start_ms": 415270,
      "end_ms": 908586,
      "material_ids": [
        "chunk_00/slide_007",
        "chunk_00/slide_008",
        "chunk_00/slide_009",
        "chunk_00/slide_010",
        "chunk_00/slide_011",
        "chunk_00/slide_012",
        "chunk_00/slide_013"
      ],
      "summary_hint": "讲者介绍了大模型技术为系统调优带来的新机遇。首先对比了传统的贝叶斯调优与LLM方案的优势，然后详细分析了RAG、模型微调、模型蒸馏等关键技术，并提出了一个博采众长的多模型协作（MCP）架构构想。",
      "notes": "The planned start sentence was the end of the previous section. The start time has been adjusted to the next sentence, which marks the beginning of the new topic.",
      "lead_text": "但是我们就是说，我们既想用这个大模型的一些优势，同时呢，还是得想办法要摒弃它的一些劣势。",
      "tail_text": "右边是我们画的我们自己的一个核心交易系统简图，就除了刚刚那个Tuner Agent和跟我们这个模型层做交互之外，它本身我们也还有一个应用的一个运维的监控平台，来实现整个一个运行的监控跟应用的部署。",
      "text_span": {
        "start": 40,
        "end": 76
      }
    },
    {
      "id": "sec_4",
      "index": 3,
      "title": "软件栈智能调优方案与创新点",
      "time_range": "00:15:58,850 - 00:17:42,355",
      "summary": "该方案规划了一个基于RAG的资产库，涵盖操作系统、数据库、MQ、Redis、JDK等核心技术资产，旨在赋能研发团队在早期阶段介入调优。初步实践展示了显著效果，例如接入网关性能提升13.6%，期权系统相比基线也有明显改善。尽管通过调优可以弥补与X86平台的性能差距，但部分接口仍有待提升。",
      "refined_script": "# 软件栈智能调优方案与创新点\n\n## 1. RAG 资产库规划\n\n方案规划构建一个基于 RAG (Retrieval-Augmented Generation) 的资产库，旨在整合核心技术资产，为智能调优提供支持。资产库涵盖范围包括：\n\n- **核心系统**：操作系统层面的运维与技术类资产\n- **数据库**\n- **计算平台**：鲲鹏计算相关资产\n- **中间件**：\n  - 消息队列 (MQ)\n  - Redis\n  - JDK\n\n未来规划将持续拓展该资产库的内容。\n\n## 2. 组织赋能与流程\n\n该方案旨在实现组织赋能，目前已有 1.0 版本产出并应用于研发团队（如恒生电子）。其核心目标是使研发团队能在开发阶段早期介入性能调优与评测工作。最终交付物不仅包含软件产品，也包含配套的完整调优资产库。\n\n## 3. 初步调优实践与效果\n\n### 3.1 案例一：接入网关\n\n- **场景**：开箱即用的调优（Out-of-the-box Tuning）\n- **效果**：性能提升约 **13.6%**，效果主要由若干关键参数贡献。\n\n### 3.2 案例二：期权系统\n\n- **调优范围**：涉及操作系统、JDK 及数据库等多个层面。\n- **效果**：与未调优的基线版本相比，系统性能有明显提升。\n\n## 4. 与 X86 平台性能对比及结论\n\n团队也进行了与 X86 平台的性能对比。需要注意的是，由于测试硬件不完全对等，相关数据仅供参考。\n\n**结论：**\n\n1.  **差距弥补**：通过精细化调优，可以有效弥补当前平台与 X86 平台之间的性能差距。\n2.  **待提升点**：尽管整体效果显著，但仍有部分接口的性能表现不及 X86 平台，尚有提升空间。",
      "original_script": "这个是我们规划的一个RAG库的一个资产库吧，资产库列表吧，反正就包括一般就是核心系统的一些运维的或者说技术类的资产，然后另外就是数据库的，还有鲲鹏的计算类的，还有MQ啊，包括一些其他中间件，就Redis、JDK，后面这一块肯定应该还是会继续拓展。\n这个是属于组织赋能上面的吧，就我们目前这个其实还是有1.0版本的输出，目前已经把它赋能到我们的研发团队，就恒生电子那边，然后让他们就是说在研发阶段呢，就参与这个调优跟评测，交给我们交付的时候就交付整个调优资产库，就这一块。\n这个就是我们近期做的一些调优的一个效果了，这个是个接入网关的，在开箱调优的场景下，大概提升13.6%的样子。\n主要起作用的参数其实就是那些。\n这个是最近我们调的，也是相对来说看效果还可以的，就是我们期权的系统的调优。当然这里面其实除了就是操作系统层的一些调优啊，也还有就是JDK跟那个数据库的。\n整体来说效果还可以，就特别是跟那个基线，就是我们不调优跟调优，它的提升还是比较明显的。\n跟X86其实我们也做了一版对比，当然这个涉及到那个硬件的性能它不完全一致，就对得起，所以数据还是仅供参考。而且也看到了，哪怕是这样，下面还是有蛮多接口，它的性能还是不及X86的，只能说我们通过调优是可以尽可能的弥补这些差距。",
      "start_ms": 958850,
      "end_ms": 1062355,
      "material_ids": [
        "chunk_00/slide_014",
        "chunk_00/slide_015",
        "chunk_00/slide_016",
        "chunk_00/slide_017",
        "chunk_00/slide_018",
        "chunk_00/slide_019",
        "chunk_00/slide_020",
        "chunk_00/slide_021"
      ],
      "summary_hint": "详细阐述智能调优方案，包括闭环设计、多级架构和RAG知识库，并展示初步实验数据。",
      "notes": "The planned start sentence was the end of the previous section. The start time has been adjusted to the next logical topic after a long pause in the speech.",
      "lead_text": "右边是我们画的我们自己的一个核心交易系统简图，就除了刚刚那个Tuner Agent和跟我们这个模型层做交互之外，它本身我们也还有一个应用的一个运维的监控平台，来实现整个一个运行的监控跟应用的部署。",
      "tail_text": "跟X86其实我们也做了一版对比，当然这个涉及到那个硬件的性能它不完全一致，就对得起，所以数据还是仅供参考。而且也看到了，哪怕是这样，下面还是有蛮多接口，它的性能还是不及X86的，只能说我们通过调优是可以尽可能的弥补这些差距。",
      "text_span": {
        "start": 76,
        "end": 84
      }
    },
    {
      "id": "sec_5",
      "index": 4,
      "title": "创新技术生态建议与共建",
      "time_range": "00:17:45,720 - 00:21:04,915",
      "summary": "讲者分享了下一阶段的研究计划，包括持续调优专有模型、提升平台易用性，并呼吁同行共建技术生态。他重点探讨了一种云端训练与企业端推理相结合的模式，旨在通过数据脱敏等方式，在保障企业信息安全的同时，解决中小企业模型训练成本高昂的难题。",
      "refined_script": "# 创新技术生态建议与共建\n\n## 一、下一阶段研究计划\n\n为推动技术发展与应用落地，我们规划了下一阶段的四个核心研究方向，并欢迎业界同仁共同参与建设。\n\n### 1. 持续优化专有领域模型\n\n我们将进一步调优公司在特定领域的专有模型，旨在输出更专业、更精准的解决方案，提升平台的核心竞争力。\n\n### 2. 提升平台产品易用性\n\n计划与华为团队联合创新，通过高频度的使用与反馈，共同提升平台的易用性，从而深度赋能研发团队，降低使用门槛。\n\n### 3. 探索持续在线学习\n\n持续在线学习是解决通用大模型在商业落地中“幻觉”问题的关键。如果模型能力无法根据落地场景持续强化，将始终停留在离线训练模式，难以满足商用需求。我们视其为一项具有战略意义的可行性方向，并希望与国内同行共同探索。\n\n### 4. 探索云端训练与本地推理相结合的模式\n\n针对中小企业在模型训练上面临的高成本问题，我们提出一种兼顾成本与数据安全的混合模式。该模式具备较高的可实现性与商业价值，是后续的重点探索方向。\n\n## 二、云端训练与本地推理模式详解\n\n### 1. 面临的挑战\n\n企业，特别是中小企业，拥有大量数据，但难以承担昂贵的算力成本（如堆叠GPU）来进行模型训练。\n\n### 2. 理想模式构想\n\n我们设想的理想模式分工如下：\n\n- **企业端**：主要负责推理（Inference）侧的算力资源积累与应用。\n- **云端**：依托远程算力平台或云平台，负责计算密集型的训练（Training）任务。\n\n### 3. 核心问题：数据安全\n\n要实现上述愿景，必须解决企业在云端训练时的数据与知识产权安全问题。\n\n### 4. 初步技术方案设想\n\n我们正与华为光猫AI团队探讨一种初步的技术方案，旨在保障数据在训练过程中不被泄露。其核心构想如下：\n\n1.  **数据处理**：在本地对企业的知识库进行数据脱敏处理，例如进行向量化转换。\n2.  **专有资源**：在远端云平台为企业提供一个专有的算力池。\n3.  **云端训练**：企业基于该专有算力池，使用脱敏后的数据进行模型训练。\n4.  **模型回传**：训练完成后，将生成的模型文件传回企业本地进行部署和推理。\n\n通过此流程，企业原始数据无需离开本地，从而在利用云端强大算力的同时，确保了信息安全。此方案目前仍处于开放性的构想阶段，但我们认为其具备巨大的商业化潜力。\n\n## 三、呼吁与展望：共建技术生态\n\n国内基础软硬件平台的建设（信创替代）是一项长期且艰难的任务。国外平台经过数十年积累，形成了显著的先发优势，短期内完全赶超存在挑战。\n\n因此，我们呼吁业界同仁能够协同合作，共同使用和打磨国产化平台。通过广泛的应用，可以更快地发现并解决潜在问题（“踩坑”），在多样的场景中锤炼产品，从而加速平台的成熟，共同构建繁荣的技术生态。",
      "original_script": "分享最后呢，其实还是想跟大家同步一下，就是我们的一些下一阶段的一些研究计划，也欢迎大家一起来共建。就一方面我们是希望就是把我们公司专有领域调优模型做进一步的输出，然后使平台它的那个方案能够输出得更专业、精准。\n同时呢，也希望这种高频度的使用这个intelligence，能够跟华为团队一起联创，把整个平台的产品易用性做起来，然后能深度赋能研发团队。\n第三块其实也是一个呼吁，就是希望看看国内同行有没有对这块感兴趣，我们希望就是持续探索一下持续在线学习这个方向。\n它整个方向我觉得它在通用大模型的落地方面应该是一个战略性的一个可行性点，如果这个点不解决的话，通用大模型你要真正做商用落地，你始终没办法解决那些幻觉问题，因为你模型能力没办法持续地适应你落地场景去持续地强化，那你始终就是一个离线训练的一种模式。\n第四块是，我觉得还是可以有比较大的落地价值，然后后续呢应该是也可以可实现性比较高的，就就是现在我们企业有大量的数据嘛，但是企业呢，你如果要去堆卡，特别是中小企业来说，毕竟它单卡那么贵，你不可能堆很多。\n但你如果要作模型的训练，资源消耗也挺大的。\n所以我觉得最终可能比较理想的状态下，你企业应该是主要就负责推理这一侧的人算力资源的积累，你训练这类的资源积累，应该还是依托远端的这种算力平台或者云平台。但是你要能达成这种愿景，你一定要解决你企业那个知识的信息安全的问题。所以我们就跟华为的光猫AI团队，也在探讨这一块的方案，就是说看是不是说它知识库，我们做一些脱敏，当然这个具体技术方案其实也还只是一个意向性想法，就例如可能做了向量化，然后做一些脱敏之后，再远端会有一个专有的算力池给到企业这边，然后企业就在基于这个专有算力池来做训练，训练完之后，你再把这个模型传回给你公司本地，这样就确保你整个数据看上去是没有泄露的。\n当然这个是其实还是个非常宽，初级跟那个开放性的一个构想。\n只是说我们觉得它应该是后续有比较大的商业运行价值。\n这张图如果跟我比较熟的同学应该看过好多次了，因为我每一次分享都会把它放到最后面。就因为整个信创替代确实做得很艰难，然后也有很很多年了，然后差距确实也在不断地缩小。\n但是毕竟国外的平台它积累了几十年嘛，所以你一下子要要赶上他们，其实我觉得也没那么快。\n所以这种情况下只能就是说大家就是说一起来做，然后步骤尽可能地保持一致，就因为你大家都来用，你那些可能的坑啊，或者场景啊方面，你就能使产品能得到更多的锤炼，那就能更快地加速它的一个成熟化。",
      "start_ms": 1065720,
      "end_ms": 1264915,
      "material_ids": [
        "chunk_00/slide_022",
        "chunk_00/slide_023",
        "chunk_00/slide_024"
      ],
      "summary_hint": "讲者分享了后续计划，包括微调专有领域模型和完善平台易用性。同时，他发出了生态共建的倡议，探讨如何通过云端训练与企业端推理相结合的模式，解决数据安全与模型训练成本之间的矛盾。",
      "lead_text": "分享最后呢，其实还是想跟大家同步一下，就是我们的一些下一阶段的一些研究计划，也欢迎大家一起来共建。就一方面我们是希望就是把我们公司专有领域调优模型做进一步的输出，然后使平台它的那个方案能够输出得更专业、精准。",
      "tail_text": "所以这种情况下只能就是说大家就是说一起来做，然后步骤尽可能地保持一致，就因为你大家都来用，你那些可能的坑啊，或者场景啊方面，你就能使产品能得到更多的锤炼，那就能更快地加速它的一个成熟化。",
      "text_span": {
        "start": 85,
        "end": 96
      }
    },
    {
      "id": "sec_6",
      "index": 5,
      "title": "问答与结束",
      "time_range": "00:21:08,890 - 00:25:00,680",
      "summary": "讲者结束了本次分享并感谢听众。随后，他主动提出想要回答之前看到的一个具体问题，并请求主持人帮助返回到相关的幻灯片页面，正式进入问答环节。",
      "refined_script": "# 问答与结束\n\n本次分享的主要内容至此结束。\n\n接下来进入问答环节。针对之前幻灯片中提到的问题（章节 4.1，第三个问题），进行补充回答。",
      "original_script": "行，我的分享就到这里，时间好像也超了一些，感谢大家。 黄老师请留步，请允许我， 我看到你刚才那个问题，我特别想，那个，可能你上面的那页的第三个问题，4.1。 老师能帮我回放一下吗？那个，就是或者没关系，也可以，耽误一分钟时间。",
      "start_ms": 1268890,
      "end_ms": 1500680,
      "material_ids": [
        "chunk_00/slide_025",
        "chunk_00/slide_026"
      ],
      "summary_hint": "讲者结束分享，进入问答环节。",
      "notes": "The planned end time was too early. The end time has been extended to include the entire Q&A session and the host's final remarks.",
      "lead_text": "行，我的分享就到这里，时间好像也超了一些，感谢大家。",
      "tail_text": "老师能帮我回放一下吗？那个，就是或者没关系，也可以，耽误一分钟时间。",
      "text_span": {
        "start": 97,
        "end": 100
      }
    }
  ]
}