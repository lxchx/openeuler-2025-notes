{
  "id": "sec_5",
  "index": 4,
  "title": "通算推理加速关键技术",
  "time_range": "00:09:17,320 - 00:12:37,085",
  "script": "关于通算推理加速，主要涉及三点：NUMA亲和、多线程并行和算子优化。首先是NUMA亲和。现在的CPU大多采用多NUMA内存架构，这种设计的一个特点是跨NUMA访存的开销可能是本NUMA内访存的2到4倍，非常昂贵。因此，当我们将Decode请求放在CPU端时，需要尽量降低跨NUMA访存的开销。我们的做法是将完整的模型权重（例如，纵向切割成四份，对应四个NUMA），以及计算所需的hidden state，分别拷贝到各个NUMA上进行本地化计算，最后再合并结果。其次是多线程并行。现代CPU多采用多核设计，提供了并行算力。为充分利用多核算力，我们采用多线程并行来处理大模型推理中的计算，例如对矩阵计算进行并行化处理。第三是算子优化。传统的CPU指令，一条乘法指令可能只能处理一次乘法。但在ARMv8架构之后，出现了许多可以加速计算的指令集。例如，NEON指令集中的一条指令可以一次完成四次浮点数乘法。而I8MM指令集扩展，其一条指令可以计算32个int8的乘法。这些都极大地加速了CPU的推理速度。通算推理加速目前主要应用于两个场景：稠密模型推理加速和MoE模型推理加速。对于稠密模型，如果我们将Decode放在CPU上执行，倾向于将注意力计算和FFN都放在CPU上完成，以避免与XPU之间频繁的数据交换产生开销。对于MoE模型，我们目前的策略是在XPU上完成注意力计算，而在CPU上进行大量的专家计算。",
  "summary": "本节介绍了通算推理加速的三项关键技术：NUMA亲和、多线程并行和算子优化。通过将计算与数据本地化、利用多核并行处理及高级指令集，可显著提升CPU推理速度，并应用于稠密模型和MoE模型等场景。"
}