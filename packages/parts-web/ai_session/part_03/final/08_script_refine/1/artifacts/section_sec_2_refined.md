## 性能测试与分析

### 测试环境与数据准备

**1. 测试环境**
- **硬件**: [未在摘要中提供]
- **软件**: openEuler 24.03 LTS SP2

**2. 数据准备**
- **数据量**: 为排除 Page Cache 对测试结果的干扰，生成的数据集总大小超过系统可用内存的 5 倍。
- **数据预热**: 利用 JuiceFS 的数据预热功能，将数据提前缓存至本地，以加速后续的数据访问过程。

### UNet3D 模型性能分析

#### 最佳性能配置 (5 GPU)

- **性能指标**:
  - GPU 利用率: 98% (满足 >90% 的目标)
  - I/O 带宽: 14.8 GB/s
- **关键参数调优**:
  - `reader.read_threads`: 从 4 增加到 16，以提高数据读取的并发度。
  - `reader.odirect`: 设置为 `True`，启用直接 I/O (Direct IO)，以减少 Buffer IO 和额外的内存拷贝开销。

#### 瓶颈分析 (6 GPU)

当 GPU 数量增加到 6 块时，利用率下降至 83%，I/O 带宽在 15.1 GB/s 处达到瓶颈。使用 FIO 工具对 JuiceFS 进行基准测试，测得其极限带宽同样约为 15.1 GB/s，确认瓶颈在于 JuiceFS 的吞吐能力。

**1. CPU 绑核场景分析**
- **现象**: 48 核 CPU 资源被完全占满。
- **诊断**: 使用 `top`、`devkit tuner numafast` 及 `devkit tuner memory/miss` 等工具分析，发现瓶颈为 **Memory Bound**。
- **根因**: 高并发读取导致大量内存拷贝操作（如 `runtime.memove`, `arch_copy_to_user`），高 LLC Miss Rate 表明 CPU 因等待内存访问而耗时，最终限制了整体性能。

**2. CPU 不绑核场景分析**
- **现象**: CPU 资源未被占满，但 JuiceFS 带宽反而更低。
- **诊断**: 使用 `top` 和 `devkit tuner numafast` 工具分析。
- **根因**: **跨 NUMA 节点的内存访问**带来了显著时延。超过 80% 的内存访问为 remote 访问，其性能受限于跨芯片的物理带宽（约 60 GB/s），成为新的瓶颈。

### ResNet50 模型性能分析

#### 最佳性能配置 (50 GPU)

- **性能指标**:
  - GPU 利用率: 95% (满足 >90% 的目标)
  - I/O 带宽: 9.2 GB/s
- **关键参数调优**:
  - `reader.read_threads`: 从 8 降为 1。由于 ResNet50 每次读取的 batch 数据量较小（58.5 MiB），单线程足以满足 I/O 需求。

#### 瓶颈分析 (55 GPU)

当 GPU 数量增加到 55 块时，利用率下降至 86%，I/O 带宽仍为 9.2 GB/s，表明瓶颈在于 JuiceFS 的后端带宽。

#### 带宽差异分析

- **问题**: 为何在 ResNet50 场景下，JuiceFS 的最大带宽（9.2 GB/s）远低于 UNet3D 场景（15.1 GB/s）？
- **根因**: **系统内存拷贝总带宽的限制**。ResNet50 采用 Buffer IO，在数据读取和处理过程中会与 JuiceFS 竞争内存带宽。使用 `stream` 工具对不同机器的内存拷贝带宽进行基准测试，证实了 JuiceFS 的吞吐带宽与系统内存拷贝带宽存在强相关性。

### 结论

- **UNet3D 瓶颈**: 在高并发 Direct IO 场景下，性能瓶颈最终归结为 CPU 处理内存拷贝操作的能力。
- **ResNet50 瓶颈**: 在 Buffer IO 场景下，JuiceFS 的吞吐能力直接受限于系统内存总带宽。
- **核心发现**: JuiceFS 的吞吐带宽与系统内存拷贝带宽强相关。这是影响 AI 训练场景 I/O 性能的关键因素，在进行性能优化时必须予以考虑。