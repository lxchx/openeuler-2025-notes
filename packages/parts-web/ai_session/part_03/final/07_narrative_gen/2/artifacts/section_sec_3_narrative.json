{
  "id": "sec_3",
  "index": 2,
  "title": "总结",
  "time_range": "00:15:56,730 - 00:18:09,190",
  "script": "最后总结一下。\nMLPerf Storage unet3d和resnet50模型支持的GPU数量取决于JuiceFS吞吐带宽。这主要考察了文件并发、大/中块顺序读能力，以及提供的总读带宽。\nBenchmark是个系统工程，需要系统各个部件配合好，以达到最优性能。\n系统内存和互联带宽和时延对系统的吞吐性能至关重要。\n内存copy比较消耗内存带宽。\n内存copy比较消耗CPU，由于互联和内存的时延导致CPU级联。\nJuiceFS吞吐带宽取决于内存带宽大小。\nGo没有numa awareness感知，对于跑大规模CPU核数，性能可能没有小规模核数好。\n对于多numa系统来说，尽量避免跨numa尤其是跨CPU socket。\n谢谢大家，我的分享完了。\n非常感谢刘老师的精彩分享。\n这个分享很有感触，除了性能评测，还给出了针对性的、专业的分析，以及对workload的建模分析，非常好。\n这套工程化的思想和思路，除了JuiceFS，应该也能用于其他场景。感谢。\n这也填补了我们社区在相关工具链上的一些空白，后续我们会联系您，获得更多相关的处理方法。好，下面...",
  "summary": "讲者总结了 MLPerf Storage 测试的关键发现，指出 JuiceFS 的吞吐带宽是决定其能支持 GPU 数量的核心因素，这主要考察了并发、顺序读和总带宽能力。他进一步强调，性能调优是系统工程，系统内存、互联带宽、NUMA 架构等都会影响最终性能，并分享了内存拷贝、Go 语言 NUMA 感知等具体观察。"
}