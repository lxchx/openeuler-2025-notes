{
  "id": "sec_1",
  "index": 0,
  "title": "背景介绍",
  "time_range": "00:00:00,000 - 00:10:23,985",
  "script": "下面有请Linaro的工程师刘新良先生，\n为我们带来JuiceFS MLPerf Storage v2.0性能评测与调优的分享。\n大家欢迎。\n大家下午好，我是来自Linaro的刘新良。\n今天给大家分享的主题是JuiceFS MLPerf Storage v2.0的性能评测与调优。\n今天分享的内容主要分为以下几部分。\n首先是介绍。\n第二部分是测试与分析。\n然后最后进行总结。\n我们首先介绍一下JuiceFS。它是什么东西呢？\n它是由JuiceData公司开源的一款高性能、基于对象存储、低成本的分布式文件系统，是现在AI领域可能用得比较多的一个文件系统。\n它的特性主要有支持POSIX、HDFS SDK、Python SDK，以及S3接口的兼容性。\n它的企业版还有更多的特性，比如分布式的Distributed Data Cache。\n它更多用于云原生的环境上。\n应用场景主要是AI训练、推理、大数据等。\n跟它有类似的些文件系统有Alluxio，还有S3FS。\n可以看一下右边这个图，它是一个典型的元数据与文件数据分离的架构。\n上面的大方框是在计算节点上。\n所以你看到它其实它的架构还是非常简单的。\n因为这个架构，数据库可以适配很多种，文件存储也可以适配很多种对象存储。\n这就说明我可以复用已有的一些数据库和对象存储，尤其你在云的环境上使用起来，你会发现它是非常好用、简单的架构。\n那么，什么是MLPerf Storage呢？\nMLPerf Storage是全球权威的AI工程联盟MLCommons开发的ML存储benchmark。\n他们开发的其他benchmark还包括自动驾驶(Automotive)、训练(Training)、推理(Inference)和安全(AILuminate)等。\nMLPerf Storage的目的是测量机器学习工作负载在存储方面的性能，包括数据摄取(中期目标)、训练(短期目标)和推理(长期目标)。目前，短期目标“训练”已经实现。\n那么为什么需要测量AI环境中的存储呢？\n因为我们要了解机器学习工作负载中的存储瓶颈是什么。\n还有就是帮助AI/ML从业者做出明智的存储决策。例如，选择何种存储系统能保证GPU利用率达到90%以上，达到资源的有效利用。\n还有帮助存储供应商、AI/ML框架优化者等针对机器学习工作负载进行优化。\n帮助AI/ML框架和系统获得更好的存储性能。\n右边的图是MLPerf Storage benchmark的一个简单框架。\nAI训练主要是从存储(Dataset)读取数据集，加载(Load)到内存(System Memory)中。在内存中可能会做一些预处理，比如转换为张量(tensors)。然后以批次(batch)的形式将数据发送到GPU/ASIC进行模型训练。\n对于存储的benchmark而言，我们主要关心左边的部分：数据如何加载、转换，并发送到GPU。GPU内部如何训练，我们不太关心。\n因此，在做benchmark时，可以简化GPU的训练过程。我们测量出实际训练所需的时间，然后用一个等时的sleep操作来模拟它。这样就大大简化了benchmark的实现工作。\n那么，这个v2.0是目前最新的一个版本。\n它支持的工作负载(Task)主要有：图像分割(Image segmentation)、图像分类(Image classification)、科学参数预测(Scientific parameter prediction)以及最新的Llama3 Checkpointing。\n这些任务模拟了AI训练中对存储系统的各种IO pattern。\n可以看到，不同的模型，其样本大小(Sample Size)和批次大小(Batch Size)各不相同。这些模拟数据的设置，都是基于对实际系统的测量得出的，因此非常贴合实际应用场景。\n它会评估存储系统的多方面能力(Evaluate Storage Capability)，比如：带宽、IOPS、时延、并发能力。训练模型主要考察读性能，而Checkpointing则考察对超大文件的并发写性能。\n接下来，我们从存储的角度看一下分布式训练的概览。\n首先，对于我们关心的存储，在分布式训练中，数据集(Dataset)会被分割成很多个分区(Partition)。每个进程(Process)，也就是每个GPU，会读取其中一个分区的数据进行训练。训练完成后，无论是同一台机器内的多块GPU，还是不同机器上的GPU，它们之间需要进行同步(Sync)。这大概就是其基本流程。\n这是MLPerf Storage的内部流程图，也是刚才流程的一个具体实现。\n右边的JuiceFS存储着被分区的Dataset。每个GPU/Accelerator worker的主线程会运行一个benchmark runner。它内部的Data Loader会从JuiceFS读取一个数据分区(Partition x)。Data Loader以多线程方式，在每个step/cycle中读取一个批次(batch)的样本数据，并转换为张量。之后，用一个sleep操作来模拟实际的计算(Accelerator compute)过程。因此，对于存储测试而言，我们主要关心Data Loader的行为，因为它决定了系统的IO pattern。\n为了分析问题，我们需要对整个系统有一个心智模型。\n这张图展示了一个简化的例子。可以看到，应用层有多个IO线程(App Threads)，比如mlp-storage dataloader threads。它们发起读写请求。JuiceFS是一个FUSE文件系统，它有处理IO请求的主goroutines。它会向后端的Meta client和ObjectStore client发送请求，这些client内部也有异步的goroutines。这个过程中涉及多个步骤，有些是同步的，有些是异步的，还有一些关键的数据拷贝(copy)操作。这些都是我们需要了解的。",
  "summary": "讲者首先介绍了JuiceFS，一个为AI领域设计的高性能分布式文件系统，及其元数据与数据分离的架构。接着，他详细阐述了MLPerf Storage v2.0基准测试的背景、目的和工作原理，该测试通过模拟AI训练中的数据加载来评估存储性能。最后，他展示了分布式训练和MLPerf Storage的内部流程，并提出了一个简化的系统心智模型以帮助分析I/O路径。"
}